{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d36b45-481b-473f-bfd6-d8656887d8dc",
   "metadata": {},
   "source": [
    "Pozn.: zde se nacházejí importy potřebné pro to, aby po restartu kernelu běžela libovolná buňka. V rámci výkladu jsou při setkání se s určitou třídou či funkcí importy samozřejmě uvedeny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db94ccfe-01ea-4e5b-8a90-f75d359dc487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:10.485947Z",
     "start_time": "2024-09-23T10:47:09.274345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "import langchain\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "from langchain.memory import ConversationTokenBufferMemory \n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "from langchain.memory import ConversationEntityMemory \n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import Language\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8e3b4",
   "metadata": {},
   "source": [
    "Zde bude jmeno modelu, ktery se bude pouzivat napric celym notebookem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b816267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:13.886750Z",
     "start_time": "2024-09-23T10:47:13.884748Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_model_name = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9b1d5-7127-490e-8ffd-b23f2e3ce37c",
   "metadata": {},
   "source": [
    "V době psaní těchto řádků je to už několik měsíců, co vzalo ChatGPT svět útokem. Člověk se tak mohl pravidelně i ve sdělovacích prostředcích setkávat s více či méně relevantními články o AI. Tento spisek nemá ambice kráčet jim po boku - absolutně netuším, zda AI (z nějakého důvodu ztotožněná s generativními modely - např. s \"doplňovači\" textu ala GPT) začne nahrazovat zaměstnance, zda nás vyhubí anebo zda život půjde dál ve starých kolejích. Namísto toho bych tu chtěl ukázat, jak pracovat s modely od OpenAI a to sice jak napřímo, tak skrze framework Langchain.  \n",
    "Na tomto místě musím doporučit [langchainové kurzy](https://www.deeplearning.ai/short-courses/), které jsou dostupné na deeplearning.ai a ze kterých jsem při tvoření tohoto textu vycházel.\n",
    "\n",
    "# Obsah\n",
    "- [OpenAI](#OpenAI)\n",
    "  - [Tokeny](#Tokeny)\n",
    "  - [API klíč](#API-klíč)\n",
    "  - [Jednoduchý příklad](#Jednoduchý-příklad)\n",
    "  - [Chatbot](#Chatbot)\n",
    "- [Langchain](#Langchain)\n",
    "  - [Šablony promptů](#Šablony-promptů)\n",
    "  - [Chains](#Chains)\n",
    "    - [LLMChain](#LLMChain)\n",
    "    - [Sekvenční chainy](#Sekvenční-chainy)\n",
    "    - [RouterChain](#RouterChain)\n",
    "    - [Transformation chain](#Transformation-chain)\n",
    "  - [Paměť](#Paměť)\n",
    "    - [ConversationBufferMemory](#ConversationBufferMemory)\n",
    "    - [ConversationBufferWindowMemory](#ConversationBufferWindowMemory)\n",
    "    - [ConversationTokenBufferMemory](#ConversationTokenBufferMemory)\n",
    "    - [ConversationSummaryMemory](#ConversationSummaryMemory)\n",
    "    - [ConversationEntityMemory](#ConversationEntityMemory)\n",
    "  - [Q&A nad dokumenty](#Q&A-nad-dokumenty)\n",
    "    - [Načtení dokunetů](#Načtení-dokumentů)\n",
    "      - [Načtení pdfka](#Načtení-pdfka)\n",
    "      - [Načtení html souboru](#Načtení-html-souboru)\n",
    "      - [Načtení webové stránky](#Načtení-webové-stránky)\n",
    "    - [Splittery](#Splittery)\n",
    "    - [Embeddings, vectorstore](#Embeddings,-vectorstore)\n",
    "    - [Similarity search](#Similarity-search)\n",
    "    - [Question answering](#Question-answering)\n",
    "    - [Automatické používání metadat](#Automatické-používání-metadat)\n",
    "    - [Prefix před fragmenty](#Prefix-před-fragmenty)\n",
    "  - [Kompletní ukázky](#Kompletní-ukázky)\n",
    "    - [Obyčejný chatbot](#Obyčejný-chatbot)\n",
    "    - [Q&A chatbot](#Q&A-chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e198da-9fac-41e2-9600-3f32ae798f47",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "### Tokeny\n",
    "Pro použití OpenAI člověk napřed musí sebe i svou kartu registrovat [zde](https://platform.openai.com/). Na stránkách je poté třeba nechat si vygenerovat API klíč, s jehož pomocí při RESTovém volání OpenAI pozná, co má komu vlastně naúčtovat. Ceník nalezneme [tady](https://openai.com/pricing). Je vhodné zdůraznit, že narozdíl od dejme tomu Midjourney si člověk nekupuje měsíční předplatné, nýbrž platí za míru používání modelů. Přesněji platí za počet modelem zpracovaných tokenů. Do toho se počítají jak tokeny do modelu vstupující, tak tokeny modelem produkované. A co že je vlastně onen token? Jedná se o skupinu písmen, která tvoří slovo anebo jeho část. V angličtině v průměru vychází 1 token na 0,75 slova, v jiných jazycích je poměr horší. Pro získání reálné představy doporučuji podívat se [sem](https://platform.openai.com/tokenizer). Krom očividného omezení peněženkou je součet vstupních a výstupních tokenů (a tak i délka textu) omezen pamětí modelu (kontextem z pricing stránky) - například pro 4K GPT-3.5 model není možné mít text (otázku a odpověď) delší než 4000 tokenů - nadbytečné tokeny budou oříznuty, resp. vůbec nevzniknou. O tom se člověk může předvědčit v \"klasickém\" webovém GUI rozhraní ChatGPT. Model sám o sobě si nepamatuje, co se dělo v předchozím hovoru. Proto se mu musí celá historie konverzace při každé interakci posílat nanovo. Po čase je historie příliš dlouhá a tak jsou staré tokeny zahozeny a model tudíž začne zapomínat začátky konverzací."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eabb417-6202-4e39-b69d-3bada92a78ab",
   "metadata": {},
   "source": [
    "### API klíč\n",
    "První tutoriálový příklad na [stránkách openai balíčku](https://pypi.org/project/openai/) začíná s \n",
    "```python\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"  # supply your API key however you choose\n",
    "```\n",
    "Jeho problém tkví ve skutečnosti, že je API klíč umístěn uprostřed kódu. Když si člověk nedá pozor a kód někam pošle (třeba na GitHub), může se jeho jménem (a jeho peněženkou) GPT modelů dotazovat celý internet. Proto bude lepší používat [python-dotenv](https://pypi.org/project/python-dotenv/) balíček. S jeho pomocí Python načte klíč z .env souboru a nastaví ho jako proměnnou prostředí. Jak to konkrétně provedeme? Nejprve si ve stejném adresáři, ve kterém se nalézá notebook (ipynb soubor), vytvoříme .env soubor (opravdu se takto jmenuje, tj. v názvu je jen přípona) a vložíme do něj\n",
    "```\n",
    "OPENAI_API_KEY=nazdar1234\n",
    "```\n",
    "Poté naimportujeme *dotenv* a provoláme funkci *load_dotenv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaf82f1-23eb-4e48-98e4-295e08019685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:15.881406Z",
     "start_time": "2024-09-23T10:47:15.878293Z"
    }
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6b05d-19c9-47fd-90c4-fd47298dbcef",
   "metadata": {},
   "source": [
    "Že se proměnná prostředí načetla ověříme s pomocí balíčku *os*:"
   ]
  },
  {
   "cell_type": "code",
   "id": "89a80cd8-c39f-48c5-8a37-512a9dc775f7",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "77c577a6-b8ec-4715-903f-027d59d8f30b",
   "metadata": {},
   "source": [
    "Pokud pracujeme s Azure OpenAI, je třeba inicializovat ještě několik dalších proměnných prostředí. Na těch už nic moc tajného není, tudíž mohou být volně v kódu. Vypadají nějak takto:\n",
    "```python\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_base = \"http://testingazureopenai.openai.azure.com\"\n",
    "```\n",
    "Api type bude asi vždy stejné, api version se bude s časem měnit a nakonec api base závisí na jméně openai resourcu. Tyto parametry se dají nejsnadněji zjistit, když v AzureAI studiu vlezeme do \"Chat Playground\" a v sekci \"Chat Session\" klepneme na \"View Code\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3d54-2db3-46e4-ba2b-6c56b8f74e9f",
   "metadata": {},
   "source": [
    "### Jednoduchý příklad\n",
    "Nyní ale přikročme k prvnímu chatovacímu příkladu. Napřed si načteme potřebné balíčky a API klíč. Ten je potřeba vložit do *OpenAI* objektu, konkrétně do parametru *api_key*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4e0c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:23.390088Z",
     "start_time": "2024-09-23T10:47:23.376945Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ed9d6-f9fd-4e26-a99e-d82e041b7d54",
   "metadata": {},
   "source": [
    "Následně si vytvoříme objekt reprezentující chat a to s pomocí [*chat.completions.create*](https://platform.openai.com/docs/api-reference/chat/create). Tomu podhodíme jednak model, který chceme používat (parametr *model*), jednak dosavadní historii konverzace (parametr *messages*). Ta má podobu listu jsonů obsahujících jednak informaci o mluvčím (klíč \"role\" s hodnotami \"user\" či \"assistant\"), jednak samotnou promluvu (klíč \"content\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba9dfb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:48:55.017416Z",
     "start_time": "2024-09-22T19:48:54.159133Z"
    }
   },
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "    ],\n",
    "    model=llm_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c581e07-af0a-4a56-ba18-719a270045c3",
   "metadata": {},
   "source": [
    "Výstupem je následující věc. Všimněte si, že na konci dostáváme i informaci o počtu použitých tokenů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae970788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:48:58.939970Z",
     "start_time": "2024-09-22T19:48:58.937465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AAb2rpyA8AVOoTmkJOu0qeqg1KPdX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Ahoj! Jak ti mohu pomoci?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727089045, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_1bb46167f9', usage=CompletionUsage(completion_tokens=11, prompt_tokens=11, total_tokens=22, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b960a-c9cc-4a33-8d97-401b5739963f",
   "metadata": {},
   "source": [
    "Pokud chceme ale jen odpověď chatbota, použijeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0724ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:49:09.611592Z",
     "start_time": "2024-09-22T19:49:09.609044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahoj! Jak ti mohu pomoci?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce50b5-a25a-466e-86a7-b8efc51ef306",
   "metadata": {},
   "source": [
    "Do *create* metody lze vložit další parametry. Například *temperature*, která s rostoucí hodnotou vede k chaotičtějším/kreativnějším odpovědím. Podle dokumentace je minimum 0, maximum 2 a default 1. Obecně ale hodnoty větší než 1 vedou obvykle k nesmyslné změti písmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc94acb-3396-4689-98af-c72f04c47de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahoj! Jak ti mohu hoje pomoci?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=llm_model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "  ],\n",
    "  temperature=2\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd0bebc-3e04-43dd-b853-7322c77d028d",
   "metadata": {},
   "source": [
    "Do *messages* lze vložit i tzv. systémový prompt, který chatbotu říká,v jaké roli má vlastně vystupovat. Takováto věc se označuje klíčem \"system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70eaf800-d080-4b1f-8e5f-456b6a6f6847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Určitě zkus oříšky! Jsou chutné a plné energie!\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=llm_model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Jsi veverka milující oříšky. Odpovídáš maximálně ve dvou větách.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Co bych si měl dát ke svačině?\"}\n",
    "  ],\n",
    "  temperature=0.7\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d415a8e",
   "metadata": {},
   "source": [
    "Pozn.: výše uvedené informace platí pro verzi balíčku openai větší nebo rovnou 1.0.0 ze září 2023. Pokud musíte pracovat s verzí starší, vypadá kód nějak takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d9945-57ce-4741-83d4-62021dbcabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=llm_model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8da9c-18af-4973-a488-0bc73f954164",
   "metadata": {},
   "source": [
    "Pokud pracujeme s Azure OpenAI, musíme napsat něco v následujícím duchu:\n",
    "```python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=openai.api_version,\n",
    "    azure_endpoint=openai.api_base,\n",
    "    api_key=openai.api_key\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"jmeno_deploymentu\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8850361-8b56-4533-8686-0a8275321f2d",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "Bohužel kód jak ho tady máme jako chatbot nefunguje - nijak se tu neukládá historie konverzací a pokaždé tak začínáme nanovo. V openai balíčku se žádná příhodná funkce ani třída nenalézá a tak si celou (byť v tomto případě ultra krátkou) logiku musíme napsat sami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfecf1c-b50b-4075-b5ac-28ea82ec94e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T22:17:29.398591Z",
     "start_time": "2024-09-21T22:17:16.455323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pro ukončení konverzace napište 'exit'\n",
      "Chatbot: Ahoj! Mám se skvěle, právě jsem našla spoustu oříšků!\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"Jsi veverka milující oříšky. Odpovídáš maximálně ve dvou větách.\"}\n",
    "  ]\n",
    "\n",
    "print(\"Pro ukončení konverzace napište 'exit'\")\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"Uživatel: \")\n",
    "    if user_message == \"exit\":\n",
    "        break\n",
    "    chat_history.append(\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    )\n",
    "    conversation = client.chat.completions.create(\n",
    "        model=llm_model_name,\n",
    "        messages=chat_history,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    chatbot_answer = conversation.choices[0].message.content\n",
    "    chat_history.append(\n",
    "        {\"role\": \"assistant\", \"content\": chatbot_answer}\n",
    "    )\n",
    "    print(f\"Chatbot: {chatbot_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d48d9",
   "metadata": {},
   "source": [
    "# Promty\n",
    "Protoze prace jde usnadnit, tak existuji promty jakozto promenne, ktere se davaji do funkce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf86bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:50:32.563031Z",
     "start_time": "2024-09-22T19:50:32.560484Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, client, model=llm_model_name):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b30e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:50:44.145499Z",
     "start_time": "2024-09-22T19:50:43.502755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc052af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:27.367308Z",
     "start_time": "2024-09-22T19:52:27.364881Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4deaa32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:27.646275Z",
     "start_time": "2024-09-22T19:52:27.644205Z"
    }
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54c1498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:28.203337Z",
     "start_time": "2024-09-22T19:52:28.201203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3acee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:31.311627Z",
     "start_time": "2024-09-22T19:52:30.192608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt, client)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8398575-3403-4630-a8ee-2b1a4ffcd106",
   "metadata": {},
   "source": [
    "# Langchain\n",
    "Sice bychom mohli pokračovat v používání čistého openai balíčku, ale museli bychom přitom programovat více, než by bylo potřeba. Existuje totiž balíček Langchain, který hromadu práce udělá za nás.  \n",
    "Pozn.: I v případě Langchainu se s postupem času objevily změny. Původní kód bude dohledatelný v historii repa, které právě čtete. Krom změn kódu se objevila i potřeba nainstalovat si integrační balíček [langchain-openai](https://pypi.org/project/langchain-openai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e3ccf-1714-436f-957c-9c9ab46ae48a",
   "metadata": {},
   "source": [
    "### Šablony promptů"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539dd7f3-d650-4bd5-b9fb-11c9b81d5233",
   "metadata": {},
   "source": [
    "S pomocí šablon lze s minimální prací navíc přepoužívat i poměrně komplexní prompty. Pro názornost nicméně začněme něčím jednoduchým.  \n",
    "Napřed si napíšeme stringový základ šablony, ve kterém vložíme dodatečné parametry do složených závorek. Vlastně to vypadá jako f-stringy, jen to f-ko na začátku chybí. Šablonu jako takovou vytvoříme s pomocí *ChatPromptTemplate.from_template*, do které jako parametr vložíme string z předchozího kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bea5c6a-b186-4a53-a593-f37b844cfd5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:42.132261Z",
     "start_time": "2024-09-22T19:52:42.129567Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_text = \"\"\"\n",
    "V jedné větě shrň text obklopený trojicí uvozovek. Odpověď musí být napsána v {language} jazyce. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65461648-59d5-48c2-8173-3b8fca1e4d4e",
   "metadata": {},
   "source": [
    "Takto vypadá jádro \"šablonového\" objektu. V první části vidíme jména do šablony dosazovaných proměnných."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814696ed-f042-446f-88e7-d5f10fccc884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:46.654007Z",
     "start_time": "2024-09-22T19:52:46.650851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'text'], template=\"\\nV jedné větě shrň text obklopený trojicí uvozovek. Odpověď musí být napsána v {language} jazyce. \\nText: '''{text}'''\\n\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd46cf10-cd9f-4818-995e-010afbca9f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:49.391902Z",
     "start_time": "2024-09-22T19:52:49.389825Z"
    }
   },
   "outputs": [],
   "source": [
    "language = \"anglickém\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcccc59-d2de-4f30-8b2a-e6e41023316c",
   "metadata": {},
   "source": [
    "Jako testovací text použijeme kousek z [wiki článku o veverkách](https://cs.wikipedia.org/wiki/Veverka_obecn%C3%A1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36b6406e-6b90-4a65-b51e-0e965e657598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:54:24.099426Z",
     "start_time": "2024-09-22T19:54:24.097333Z"
    }
   },
   "outputs": [],
   "source": [
    "squirrel_text = \"\"\"\n",
    "Veverka obecná obvykle dorůstá 19 až 23 cm a dosahuje hmotnosti mezi 250 a 340 g někdy i víc. \n",
    "Huňatý ocas, který napomáhá udržovat rovnováhu při lezení a skocích na stromech a který veverka využívá \n",
    "jako „pokrývku“ těla při spánku, je 14,5 až 20 cm dlouhý.[3] Charakteristickým znakem veverky obecné jsou střapce \n",
    "chlupů na ušních boltcích směřující do špičky a viditelné především v zimním období. \n",
    "Stejně jako většina stromových veverek má i veverka obecná ostré a zakřivené drápy, které jí pomáhají při lezení po větvích stromů. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ec0a-3618-4397-bdb7-c66685d161ba",
   "metadata": {},
   "source": [
    "Proměnné se do šablony dostanou v rámci provolání metody *format_messages*. V ní by každé proměnné měl odpovídat jeden parametr nesoucí její jméno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d370202-fdc3-477b-a9a7-d28b3c11dd4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:54:34.196838Z",
     "start_time": "2024-09-22T19:54:34.193915Z"
    }
   },
   "outputs": [],
   "source": [
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35af2a-1645-43ec-b89d-7e63450525b9",
   "metadata": {},
   "source": [
    "Výsledek vypadá následně:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff4fb8c-ac7d-4da5-a8a8-41a6d742ba8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:18.968676Z",
     "start_time": "2024-09-22T19:55:18.964449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"\\nV jedné větě shrň text obklopený trojicí uvozovek. Odpověď musí být napsána v anglickém jazyce. \\nText: '''\\nVeverka obecná obvykle dorůstá 19 až 23 cm a dosahuje hmotnosti mezi 250 a 340 g někdy i víc. \\nHuňatý ocas, který napomáhá udržovat rovnováhu při lezení a skocích na stromech a který veverka využívá \\njako „pokrývku“ těla při spánku, je 14,5 až 20 cm dlouhý.[3] Charakteristickým znakem veverky obecné jsou střapce \\nchlupů na ušních boltcích směřující do špičky a viditelné především v zimním období. \\nStejně jako většina stromových veverek má i veverka obecná ostré a zakřivené drápy, které jí pomáhají při lezení po větvích stromů. \\n'''\\n\")]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bafe03",
   "metadata": {},
   "source": [
    "Alternativni priklad s jinyma promennyma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6310a5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:31.265618Z",
     "start_time": "2024-09-22T19:55:31.263185Z"
    }
   },
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56310e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:34.685564Z",
     "start_time": "2024-09-22T19:55:34.683249Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c4b79c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:36.383516Z",
     "start_time": "2024-09-22T19:55:36.380967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088d6049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:37.918690Z",
     "start_time": "2024-09-22T19:55:37.915067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf8ca85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:39.158338Z",
     "start_time": "2024-09-22T19:55:39.156368Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85445c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:40.018713Z",
     "start_time": "2024-09-22T19:55:40.016678Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0388a597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:40.486025Z",
     "start_time": "2024-09-22T19:55:40.483728Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db882e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:41.696499Z",
     "start_time": "2024-09-22T19:55:41.694180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac619362-b998-49d0-85e2-46b76c48dc0a",
   "metadata": {},
   "source": [
    "Nyní musíme Langchainu říct, s jakým jazykovým modelem má pracovat. Pro podporované modely přitom existují separátní třídy. Seznam nalezneme [zde](https://python.langchain.com/docs/integrations/llms/). Zdůrazněme, že zatímco balíček openai dokázal obhospodařit jak OpenAI modely, tak Azure OpenAI modely, zde se jedná o separátní entity. Navíc historicky byl a asi pořád je rozdíl mezi třídami OpenAI a ChatOpenAI importovanými nyní z langchain_openai.  \n",
    "Jaké parametry můžeme do konstruktoru ChatOpenAI vložit? Jedná se primárně o teplotu (parametr *temperature* s defaultní hodnotou 0.7) a jméno LLM modelu (parametr *model_name* s defaultní hodnotou \"gpt-3.5-turbo\"). API klíč můžeme předávat parametrem *api_key* - pokud tak explicitně neuděláme, bude Langchain klíč hledat v *os.environ\\[\"OPENAI_API_KEY\"\\]*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ac12d0a-609c-4b47-93bc-4ff95da35beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:04.128477Z",
     "start_time": "2024-09-22T20:01:04.107761Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82241053-df9c-4834-85d6-ff873d1ac1f1",
   "metadata": {},
   "source": [
    "Když pak do metody *invoke* našeho chatovacího modelu vložíme jako parametr šablonu a výsledku se zeptáme na atribut *content*, získáme odpověď. Vidíme, že anglický jazyk sice model pochopil, ale shrnutí zabralo více než požadovanou jednu větu. no, shrnutí - text vypadá spíš jako překlad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18a12548-0533-4904-8abb-4d564f029715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:11.656041Z",
     "start_time": "2024-09-22T20:01:10.743228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The common squirrel typically measures 19 to 23 cm in length, weighs between 250 and 340 g, has a bushy tail for balance and warmth, and is characterized by tufted ear hair and sharp, curved claws for climbing.\n"
     ]
    }
   ],
   "source": [
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e2b9b",
   "metadata": {},
   "source": [
    "Jeste zkusime, co to udela, kdyz to zavolame na ten druhy priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19380b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:59.494726Z",
     "start_time": "2024-09-22T20:01:58.628860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8141c664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:01.924293Z",
     "start_time": "2024-09-22T20:02:01.922239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m quite frustrated that the lid of my blender came off and splattered smoothie all over my kitchen walls. To make matters worse, the warranty doesn’t cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you!\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe752345",
   "metadata": {},
   "source": [
    "Dalsi priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcd66c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:31.775784Z",
     "start_time": "2024-09-22T20:02:31.773830Z"
    }
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f280e196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:34.225727Z",
     "start_time": "2024-09-22T20:02:34.224076Z"
    }
   },
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f98bc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:51.680230Z",
     "start_time": "2024-09-22T20:02:51.678046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "639226ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:55.265201Z",
     "start_time": "2024-09-22T20:02:54.033462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, esteemed customer! I be regretful to inform ye that the warranty be not coverin' the expenses for cleanin' yer galley, as it appears ye may have misused yer blender by forgettin' to secure the lid afore settin' it to whirl. Aye, 'tis a bit of tough luck, indeed! Fair winds to ye, and may we cross paths again!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat.invoke(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499ff42-49f0-4f3c-b0e6-11e09215cdff",
   "metadata": {},
   "source": [
    "Člověka by napadlo, že se text bez ztráty informací do jedné věty možná shrnout nedá a nízká teplota zabraňuje kreativnější práci s informacemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a7f8b43-889c-480d-b36d-14664ec8606c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:03:26.497128Z",
     "start_time": "2024-09-22T20:03:25.469062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eurasian squirrel typically measures 19 to 23 cm in length and weighs between 250 and 340 g, featuring a bushy tail for balance and warmth, ear tufts, and sharp, curved claws for climbing.\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.7, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2210f-d44d-4277-8fd4-83bc67e32dd6",
   "metadata": {},
   "source": [
    "Nicméně možná si model zkrátka co se instrukcí týče jenom nerozumí s češtinou tak dobře jako s angličtinou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95b4ff0e-6ebd-4891-9da2-4878126475fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:03:45.417133Z",
     "start_time": "2024-09-22T20:03:44.041319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veverka obecná dorůstá délky 19 až 23 cm, váží mezi 250 a 340 g, má huňatý ocas dlouhý 14,5 až 20 cm, charakteristické střapce na uších a ostré drápy pro lezení po stromech.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"\"\"\n",
    "Summarize the text surrounded by three quotation marks in one sentence. The answer must be written in {language} language. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11a4d7-4275-43b9-8019-96a4fba3142b",
   "metadata": {},
   "source": [
    "Možná se nám někdy stane, že bude odpověď useknutá. To nejspíš bude dáno skutečností, že defaultní hodnota parametru *max_tokens* pro *ChatOpenAI*, která má velikost 256, na celou odpověď zkrátka nestačí. Pokud nechceme být omezováni (resp. pokud chceme být omezeni jen maximální velikostí kontextového okna), vložíme do parametru -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed485a07-ae8a-42cb-9395-e41d0567806a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:35:22.221405Z",
     "start_time": "2024-09-22T20:35:21.222518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veverka obecná dorůstá délky 19 až 23 cm, váží mezi 250\n"
     ]
    }
   ],
   "source": [
    "template_text = \"\"\"\n",
    "Summarize the text surrounded by three quotation marks in one sentence. The answer must be written in {language} language. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name,\n",
    "    max_tokens=22\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51d8f6",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399bc41-54db-44a3-b20d-8f3d17f20bcc",
   "metadata": {},
   "source": [
    "Zkusme nyní lehce komplikovanější šablonu, která se bude koukat na [popis hry Na křídlech](https://www.tlamagames.com/deskove-hry/wingspan/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75715ffa-6a2f-49ab-bf9b-d667a2d82966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:35:53.507452Z",
     "start_time": "2024-09-22T20:35:52.621896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"minimal_age\": 14,\n",
      "  \"number_of_players\": \"1-5\",\n",
      "  \"victory_condition\": \"Hráč s nejvíce body po 4 kolech\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "wingspan_text = \"\"\"\n",
    "Wingspan je kompetitivní středně těžká hra využívající karty a engine building mechanismus.\n",
    "\n",
    "Stáváte se nadšenými ornitology a sběrateli a snažíte se objevit a přilákat ty nejzajímavější ptáky da Vaší sítě rezervací. Každý pták posiluje řetěz kombinací pro daný habitat (akci). Tyto habitaty jsou zaměřeny na několik klíčových oblastí rozvoje:\n",
    "\n",
    "    Dostat žetony jídla výběrem kostky z krmítka (dice tower)\n",
    "    Kladení vajec s využitím miniaturních vajec v různých barvách\n",
    "    Dobrání ze stovek unikátních karet ptáků a zahrání těchto karet\n",
    "\n",
    "Vítězem je ten hráč, který má po 4 kolech nejvíce bodů.\n",
    "\n",
    "Pokud máte rádi hry jako Terraforming Mars a Gizmos, tak by tahle hra měla zalétnout na Váš stůl.\n",
    "\n",
    "Hra je určena pro 1-5 hráčů od 14 let.\n",
    "\n",
    "Pravidla i herní materiál je v angličtině.\n",
    "\"\"\"\n",
    "\n",
    "template_text = \"\"\"\n",
    "From text surrounded by by three quotation marks extract following information.\n",
    "\n",
    "1) Minimal age\n",
    "2) Number of players\n",
    "3) Victory condition\n",
    "\n",
    "The answer must be written in {language} language in {format} format. \n",
    "\n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "format = \"json\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    format=format,\n",
    "    text=wingspan_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20f0a950-ab0f-429d-be0f-328a59743f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:36:52.201023Z",
     "start_time": "2024-09-22T20:36:51.082197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Minimal age: 14  \n",
      "2) Number of players: 1-5  \n",
      "3) Victory condition: The player with the most points after 4 rounds wins.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"english\"\n",
    "format = \"plain text\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    format=format,\n",
    "    text=wingspan_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd17bb-7854-4268-a6e8-6e59fccbd576",
   "metadata": {},
   "source": [
    "V případě práce s Azure OpenAI budeme namísto *ChatOpenAI* používat *AzureChatOpenAI*. Rozdíl je i v parametrech - nebudeme specifikovat *model_name*, nýbrž *deployment_name*. V Azuru se totiž vytváří svého druhu instance modelů mimo (obvykle) v GUI, přičemž jsou pojmenovány právě jako deploymenty.  Vytvořené deploymenty člověk nalezne v Azure AI studiu v sekci \"deployments\" (do konstruktoru dáváme název z prvního sloupce tabulky).\n",
    "\n",
    "```python\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"api_klíč\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"endpoint ve formátu ala http://testingazureopenai.openai.azure.com\"\n",
    "chat = AzureChatOpenAI(deployment_name=\"jmeno_deploymentu\", temperature=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba1771",
   "metadata": {},
   "source": [
    "Jiny priklad, jak definovat vystup z LLM modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2c0edff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:04.032941Z",
     "start_time": "2024-09-22T20:37:04.029892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f96c43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:11.570648Z",
     "start_time": "2024-09-22T20:37:11.568337Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec298d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:31.724255Z",
     "start_time": "2024-09-22T20:37:31.721481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17c52c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:42:43.807600Z",
     "start_time": "2024-09-22T20:42:42.712503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\", \"I think it's worth it for the extra features\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model_name)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "795c6da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:38:54.364559Z",
     "start_time": "2024-09-22T20:38:54.361577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28b41a",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3d628f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:08.247899Z",
     "start_time": "2024-09-22T20:40:08.246087Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "271adbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:09.923708Z",
     "start_time": "2024-09-22T20:40:09.915957Z"
    }
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9ad5767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:40.359383Z",
     "start_time": "2024-09-22T20:40:40.356895Z"
    }
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c47b8bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:41.886667Z",
     "start_time": "2024-09-22T20:40:41.884684Z"
    }
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e1e850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:43.425820Z",
     "start_time": "2024-09-22T20:40:43.423126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b263ea71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:41:09.064903Z",
     "start_time": "2024-09-22T20:41:09.062369Z"
    }
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a8d66c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:41:12.330332Z",
     "start_time": "2024-09-22T20:41:12.328341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa7375bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:12.269579Z",
     "start_time": "2024-09-22T20:43:11.148181Z"
    }
   },
   "outputs": [],
   "source": [
    "response = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcaa5b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:16.025257Z",
     "start_time": "2024-09-22T20:43:16.022963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\", \"I think it's worth it for the extra features\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f53b8ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:20.907758Z",
     "start_time": "2024-09-22T20:43:20.904781Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36707c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:21.841755Z",
     "start_time": "2024-09-22T20:43:21.839194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': 2,\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there\",\n",
       "  \"I think it's worth it for the extra features\"]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "606ff72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:22.381465Z",
     "start_time": "2024-09-22T20:43:22.379011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52c8d9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:22.818522Z",
     "start_time": "2024-09-22T20:43:22.815554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d7fe1-aac0-4863-beeb-7e33e91bb277",
   "metadata": {},
   "source": [
    "## Chains\n",
    "Je načase přistoupit k věci, podle které nese Langchain své jméno - k chainům. Ty jsou [definovány](https://python.langchain.com/docs/modules/chains/) jako posloupnosti volání komponent, které mohou obsahovat další chainy. To by ve výsledku mělo vést k větší přehlednosti a snazší udržování kódu.\n",
    "#### LLMChain \n",
    "Viz. [LLMChain](https://python.langchain.com/docs/modules/chains/foundational/llm_chain)\n",
    "Jedná se o asi nejjednodušší chain. Člověk do něj při inicializaci nasype template a jazykový model. Při samotném použití *LLMChain* provoláme s hodnotou proměnné, která se dosadí do šablony. Výsledný textový řetězec poputuje do jazykového modelu a následně obdržíme výsledek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1bedc7db58b4d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:29.263238Z",
     "start_time": "2024-09-22T20:51:29.244431Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.95, model=llm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "565c7f63a6b559f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:30.514842Z",
     "start_time": "2024-09-22T20:51:30.512810Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "246c00ba72989906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:31.188104Z",
     "start_time": "2024-09-22T20:51:31.186062Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f30020986f1bc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:33.761988Z",
     "start_time": "2024-09-22T20:51:32.281606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Queen Size Sheet Set',\n",
       " 'text': 'Choosing a name for a company that makes queen size sheet sets can be both fun and strategic. Here are some options that convey comfort, quality, and the essence of bedding:\\n\\n1. **Queen’s Comfort**\\n2. **Regal Rest**\\n3. **Elegant Slumber**\\n4. **Majestic Sheets**\\n5. **Crown Comforts**\\n6. **Snooze Royalty**\\n7. **Sheet Serenade**\\n8. **Dreamy Dimensions**\\n9. **Royal Bed Linen**\\n10. **Elysian Sheets**\\n\\nFeel free to mix and match or modify these suggestions to find a name that resonates with your brand identity!'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0852cc-8d27-42c0-ac65-70618f0f8318",
   "metadata": {},
   "source": [
    "Obvykle ale nechceme slovníkovou omáčku okolo, ale jen samotnou odpověď. Kdysi bylo řešením použít metodu *run*. Ta ale brzo bude odstraněna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e416d9d-89cd-43af-8b7a-72638f79d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:52:12.080415Z",
     "start_time": "2024-09-22T20:52:10.773033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Choosing the best name for a company that specializes in queen-size sheet sets depends on several factors such as branding, target audience, and the overall message you want to convey. Here are some suggestions:\\n\\n1. **Queen Dreams**\\n2. **Regal Rest**\\n3. **Sheet Serenity**\\n4. **Crown Comforts**\\n5. **Majestic Linens**\\n6. **Royal Slumber**\\n7. **Queen’s Haven**\\n8. **LuxiQueen Sheets**\\n9. **Sleep Like Royalty**\\n10. **Sovereign Sheets**\\n\\nThese names emphasize luxury, comfort, and the queen-size aspect, creating an appealing branding for your company. Consider your target market and brand identity when making your final choice!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6aa76f-4912-4912-815a-6fd39fcedee6",
   "metadata": {},
   "source": [
    "Tudíž musíme explicitně \"slovníkově\" zmínit, co vlastně chceme vidět."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ffc2bbb-49cc-456a-89ad-85723bdb4848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:52:47.595952Z",
     "start_time": "2024-09-22T20:52:46.064680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Choosing a name for a company that specializes in queen size sheet sets should reflect comfort, quality, and perhaps even a touch of elegance. Here are some suggestions:\\n\\n1. **Queen's Rest**\\n2. **Elegant Sheets**\\n3. **SnoozeLux**\\n4. **Regal Bedding**\\n5. **Dreamy Queen**\\n6. **Silken Slumber**\\n7. **Royal Comfort Sheets**\\n8. **Queenly Threads**\\n9. **Sheet Serenity**\\n10. **Cozy Queen**\\n\\nFeel free to mix and match words or modify them to better suit your brand’s identity!\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.invoke(product)[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891a943-ad6e-4ce3-8c3a-1ba79ba655de",
   "metadata": {},
   "source": [
    "V případě, že má jít do šablony více proměnných, musíme tyto proměnné do metody *invoke* předávat jako slovník v parametru *input*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "576ae240-e315-4598-a8a7-3ff207879ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:33.016623Z",
     "start_time": "2024-09-22T21:00:33.011789Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_two_var = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Write the best name for {pet}. Answer should be in one sentence, in {language} language, but should contain reasoning.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19bf26fdb72f75a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:36.228370Z",
     "start_time": "2024-09-22T21:00:36.225756Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chain_two_var = LLMChain(llm=llm, prompt=prompt_template_two_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc6ccaec7fa236bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:38.914068Z",
     "start_time": "2024-09-22T21:00:38.050699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pet': 'cat',\n",
       " 'language': 'german',\n",
       " 'text': 'Der beste Name für eine Katze ist \"Schnurrli\", weil er die sanfte und verspielte Natur dieser Tiere perfekt widerspiegelt.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vars = {\"pet\": \"cat\", \"language\": \"german\"}\n",
    "llm_chain_two_var.invoke(input=input_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ce79d-75f5-433b-9c60-7ccb8b3ff790",
   "metadata": {},
   "source": [
    "Pokud člověk chce odpovědi na více separátních vstupů, není třeba popořadě manuálně provolávat model, ale lze použít metodu *apply*. Té se podhodí list slovníků s proměnnými."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb81771cd5b6aee",
   "metadata": {},
   "source": [
    "Vzhledem k rychlosti vyvoje LangChainu, je nasledujici metoda uz nefunkcni. Nevim proc, proste uz nefunguje. A kdyz \n",
    "clovek googlí, tak na strance \n",
    "[dokumentace k LLMChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain) se dozvi, ze LLMChain byl taky deprecated...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74a0d464-9309-4ff6-b130-7ba2d6bb89ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:04:07.069203Z",
     "start_time": "2024-09-22T21:04:06.985734Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'language'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[96], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m input_list \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      2\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpet\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparrot\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m      3\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpet\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mczech\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m      4\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpet\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmonkey\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgerman\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      5\u001B[0m ]\n\u001B[0;32m----> 7\u001B[0m \u001B[43mllm_chain_two_var\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:166\u001B[0m, in \u001B[0;36minvoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m      0\u001B[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001B[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:154\u001B[0m, in \u001B[0;36minvoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[1;32m    153\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 154\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[1;32m    155\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    156\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    157\u001B[0m     )\n\u001B[1;32m    159\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    160\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:284\u001B[0m, in \u001B[0;36m_validate_inputs\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m missing_keys:\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing some input keys: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_keys\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_outputs\u001B[39m(\u001B[38;5;28mself\u001B[39m, outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    285\u001B[0m     missing_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys)\u001B[38;5;241m.\u001B[39mdifference(outputs)\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m missing_keys:\n",
      "\u001B[0;31mValueError\u001B[0m: Missing some input keys: {'language'}"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"pet\": \"parrot\", \"language\":\"english\"},\n",
    "    {\"pet\": \"bear\", \"language\":\"czech\"},\n",
    "    {\"pet\": \"monkey\", \"language\":\"german\"}\n",
    "]\n",
    "\n",
    "llm_chain_two_var.apply(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5076b4-e0ba-4861-b51f-03cdcceeb4b8",
   "metadata": {},
   "source": [
    "#### Sekvenční chainy\n",
    "Viz [Sekvenční chainy](https://python.langchain.com/docs/modules/chains/foundational/sequential_chains).\n",
    "Sekvenční chainy jsou určeny pro situace, kdy výstup jednoho provolání modelu vkládáme jako vstup do provolání druhého. Existují ve dvou variantách:\n",
    "- SimpleSequentialChain, který má jen jeden vstup a jeden výstup\n",
    "- SequentialChain umožňující existenci více vstupů a výstupů\n",
    "\n",
    "Pro ukázku SimpleSequentialChain si napřed vytvoříme dva LLMChainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef45a7e8-928d-4aab-b96a-1c26fd1c6c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:08.506948Z",
     "start_time": "2024-09-22T21:17:08.488861Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.95, model=llm_model_name)\n",
    "\n",
    "prompt_template_post = ChatPromptTemplate.from_template(\n",
    "    \"Write a LinkedIn post for company {company}.\"\n",
    ")\n",
    "\n",
    "post_chain = LLMChain(llm=chat, prompt=prompt_template_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "99661f46-b4c9-4a23-b8e4-fe5dd62b506c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:08.895074Z",
     "start_time": "2024-09-22T21:17:08.893032Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_summary = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Summarize the text surrounded by three quotation marks in one sentence.\n",
    "    Text: '''{text}''''\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary_chain = LLMChain(llm=chat, prompt=prompt_template_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8f8d6-798d-460c-960b-612e8f96d6c9",
   "metadata": {},
   "source": [
    "Následně s jejich pomocí vytvoříme SimpleSequentialChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "168a9c7a-a259-4dc1-9d40-3fbd42c43ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:13.758189Z",
     "start_time": "2024-09-22T21:17:13.756016Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[post_chain, summary_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb6010-d00b-4b5d-86f8-6aea084e2fe0",
   "metadata": {},
   "source": [
    "Ten uvedeme do provozu provoláním metody *invoke*. Do té vložíme hodnotu, která bude dosazena do prvního LLMChainu (pořadí chainů dáno pořadím v listu vkládaného do parametru *chains*).  \n",
    "Jelikož jsme *SimpleSequentialChain* vytvořili s parametrem *verbose*=True, vidíme i mezivýsledky - výstup prvního a druhého LLMChainu v modré resp. žluté barvě. A ano, jsou zde warningy. Asi se jedná o nějaké volání v pozadí; zatím jsem nepřišel na to, co mám čím nahradit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "773304e6-0b89-45ff-b8b1-7f70f7913592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:19.762144Z",
     "start_time": "2024-09-22T21:17:16.322865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m🌟 Exciting News from Hamster Food Inc.! 🌟\n",
      "\n",
      "We’re thrilled to announce the launch of our newest product line, **Nutri-Pellets**, specially formulated to meet the unique nutritional needs of your furry friends! 🐹💚\n",
      "\n",
      "At Hamster Food Inc., we believe that every hamster deserves a healthy and balanced diet. Our Nutri-Pellets are packed with essential vitamins and minerals, ensuring your little companions stay happy and vibrant. \n",
      "\n",
      "Why choose Nutri-Pellets? \n",
      "\n",
      "✅ High-quality ingredients  \n",
      "✅ No artificial additives  \n",
      "✅ Tailored nutrition for all life stages  \n",
      "✅ Sustainable sourcing practices   \n",
      "\n",
      "We are committed to supporting pet owners with high-quality products that foster the well-being of their pets. Join us on this journey to promote healthier, happier hamsters!\n",
      "\n",
      "Check out our website to learn more about our new line and discover tips for hamster care: [INSERT LINK]\n",
      "\n",
      "#HamsterFoodInc #PetCare #HealthyPets #NutriPellets #FurryFriends #InnovationInPetFood\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mHamster Food Inc. has launched a new product line called Nutri-Pellets, designed to provide essential nutrition for hamsters with high-quality ingredients and no artificial additives.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "post_summary = overall_chain.invoke(\"Hamster food Inc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28539572-1485-4766-a8a0-561da430286c",
   "metadata": {},
   "source": [
    "Výsledek jsme si uložili do proměnné *post_summary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3fa8b01-4550-4703-b080-b02172f6ea2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:23.897856Z",
     "start_time": "2024-09-22T21:17:23.895292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hamster food Inc.',\n",
       " 'output': 'Hamster Food Inc. has launched a new product line called Nutri-Pellets, designed to provide essential nutrition for hamsters with high-quality ingredients and no artificial additives.'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce02a8-202b-4b59-a8df-7e27797a53fe",
   "metadata": {},
   "source": [
    "S *verbose*=False žádné barevné výsledky neuvidíme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1b20d7f-1730-44b3-baac-f225716fb796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:29.084160Z",
     "start_time": "2024-09-22T21:17:25.995994Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[post_chain, summary_chain], verbose=False)\n",
    "post_summary = overall_chain.invoke(\"Hamster food Inc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94a4ea36-a96b-4b49-a89f-8eab00df43d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:29.159895Z",
     "start_time": "2024-09-22T21:17:29.157319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hamster food Inc.',\n",
       " 'output': 'Hamster Food Inc. is excited to launch a new line of organic, nutritious food products designed to enhance the health and happiness of hamsters, while encouraging community engagement among pet lovers.'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720438d-e6b6-49b4-a1f0-80b3101edaba",
   "metadata": {},
   "source": [
    "Nyní se podívejme na *SequentialChain*. Zde první LLMChain bude mít dva vstupy. Navíc tu v parametru *output_key* říkáme, do jak pojmenované proměnné zpracované dalšími LLMChainy se má výstup tohoto chainu uložit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db3cd209-f82b-41d0-a576-139bade3c728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:18:34.592177Z",
     "start_time": "2024-09-22T21:18:34.577937Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.95, model=llm_model_name)\n",
    "\n",
    "prompt_template_post = ChatPromptTemplate.from_template(\n",
    "    \"Write a LinkedIn post for company {company} with length of {sentences_count} sentences.\"\n",
    ")\n",
    "\n",
    "post_chain = LLMChain(llm=chat, prompt=prompt_template_post, output_key=\"linkendin_post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e026ead-6c99-4c00-be14-35a0cad3b3dc",
   "metadata": {},
   "source": [
    "Dva vstupy a jeden *output_key* má i druhý *LLMChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aaf3aa57-2e0b-4d80-a525-4abefb236af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:19:02.347188Z",
     "start_time": "2024-09-22T21:19:02.344248Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_summary = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Summarize the text surrounded by three quotation marks in one sentence. Use {language} language.\n",
    "    Text: '''{linkendin_post}''''\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary_chain = LLMChain(llm=chat, prompt=prompt_template_summary, output_key=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c3b22-6581-47ea-a086-e9fe6d3c5267",
   "metadata": {},
   "source": [
    "Nyní si vytvoříme *SequentialChain*. Oproti *SimpleSequentialChain* tu navíc máme parametry *input_variables* a *output_variables*. Všimněme si, že i když se proměnná *language* používá až v druhém LLMChainu, je v *input_variables*. První LLMChain ji prostě ignoruje.  \n",
    "V SequentialChainu bychom mohli mít více chainů a ty by ani nemusely mít uspořádány čistě sériově. Langchain už by si je postupně pospouštěl podle potřebných input a output proměnných. Dokonce ani konec nemusí být v jednom chainu - zakončení může být více a pak je output_key každého koncového chainu umístěn do listu v *output_variables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f39688af-ed80-438c-bcac-2f6a36785551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:23:57.308281Z",
     "start_time": "2024-09-22T21:23:57.305889Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[post_chain, summary_chain],\n",
    "    input_variables=[\"company\", \"sentences_count\", \"language\"],\n",
    "    output_variables=[\"summarization\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c26168-ee50-48e2-ac37-961384329a6b",
   "metadata": {},
   "source": [
    "Aktivovat *SequentialChain* můžeme vložením slovníku se záznamem pro každou *input_variable* do instance chainu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a2deee5c-cbb1-4640-bf69-9780abddff15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:08.263765Z",
     "start_time": "2024-09-22T21:24:06.202376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'language': 'czech',\n",
       " 'sentences_count': 3,\n",
       " 'company': 'Turtles speedtravel',\n",
       " 'summarization': 'Turtles SpeedTravel se zavazuje k vylepšení cestovních zážitků prostřednictvím inovativních a udržitelných řešení, která mění způsob, jakým objevujeme svět.'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain.invoke({\"language\":\"czech\", \"sentences_count\":3, \"company\":\"Turtles speedtravel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3d0dd-989a-4e8c-bb29-9fa6fd61bd77",
   "metadata": {},
   "source": [
    "Všimněme si ale, že i když jsme nastavili *verbose*=True, nevidíme mezivýsledky. Netušíme tak, co se vlastně uvnitř děje. Když ale nastavíme langchain do debug modu s pomocí *langchain.debug* = True, uvidíme vše do nejmenších podrobností."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7689e-5e08-4806-aa82-78c5b903034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be20b2-4368-40ee-a74f-981e3e80d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain.invoke({\"language\":\"czech\", \"sentences_count\":3, \"company\":\"Turtles speedtravel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bd846",
   "metadata": {},
   "source": [
    "Jiny priklad s vice prompty a vice output_variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "40956c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:47.776497Z",
     "start_time": "2024-09-22T21:24:47.761100Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model_name)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5bfba736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:53.928342Z",
     "start_time": "2024-09-22T21:24:53.926102Z"
    }
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6d0d3832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:00.288675Z",
     "start_time": "2024-09-22T21:25:00.285407Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3e11f62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:05.063576Z",
     "start_time": "2024-09-22T21:25:05.060803Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "021f98d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:09.673208Z",
     "start_time": "2024-09-22T21:25:09.670297Z"
    }
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "646cf406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:32:10.174116Z",
     "start_time": "2024-09-22T21:32:06.387335Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'Jidlo nebylo spatny, ale zadna slava to taky nebyla',\n",
       " 'English_Review': \"The food wasn't bad, but it wasn't anything special either.\",\n",
       " 'summary': 'The food was mediocre, neither bad nor exceptional.',\n",
       " 'followup_message': 'Odpověď: Děkuji za vaši recenzi. Je škoda, že jídlo nesplnilo vaše očekávání. Rádi bychom se dozvěděli více o vašich preferencích, abychom mohli zlepšit naše menu a nabídnout našim hostům lepší zážitek. Doufáme, že nám dáte další šanci!'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af783813-1f49-45fc-aa13-33fcc8aa06a6",
   "metadata": {},
   "source": [
    "#### RouterChain\n",
    "RouterChain dokáže posoudit, na který z podřízených chainů poslat uživatelský vstup. Narozdíl od sekvenčích chainů, kde je posloupnost řízena jménem proměnných (a tedy volbou programátora), v případě LLMRouterChain se o rozzařování skutečně stará jazykový model.  \n",
    "Pozn.: v této podkapitole čerpám z langchainového kurzu z deeplearning.ai opravdu extenzivně - MULTI_PROMPT_ROUTER_TEMPLATE je převzat beze změn metodou ctrl+C, ctrl+V.  \n",
    "Nejprve si vytvoříme základy šablon pro programování a pro vaření."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5ac58-2447-4fe6-89b8-f00ec7c81224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "it_problem_template = \"\"\"You are a very smart programmer. \n",
    "You are great at answering questions about computers, programming and IT in a concise \n",
    "and easy to understand manner. \n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "cooking_template = \"\"\"Your are master chef, expert at cooking and food preparation. \n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "\n",
    "Here is a question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"programming\", \n",
    "        \"description\": \"Good for answering questions about programming and IT\", \n",
    "        \"prompt_template\": it_problem_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"food\", \n",
    "        \"description\": \"Good for answering questions about food and cooking\", \n",
    "        \"prompt_template\": cooking_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0867f-41c0-4e24-87a1-0123065299c1",
   "metadata": {},
   "source": [
    "Následně dojde k vytvoření instance jazykového modelu a listu slovníku o podchainech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91a9c6-9f7c-44c7-84b3-dd3c51fa202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "destination_chains = {}\n",
    "for one_prompt_info in prompt_infos:\n",
    "    name = one_prompt_info[\"name\"]\n",
    "    prompt_template = one_prompt_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=chat, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{one_prompt_info['name']}: {one_prompt_info['description']}\" for one_prompt_info in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4cbff-3de3-4482-b3ac-427de7e3cb88",
   "metadata": {},
   "source": [
    "Vytvoříme si i defaultní podchain, kam půjdou uživatelské dotazy, které se nevejdou nikam jinam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45ae33-07df-4bd0-8095-e070f8ad8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=chat, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711e81d-f1f8-4ba2-a8f6-ed2afcde68cb",
   "metadata": {},
   "source": [
    "Následuje extenzivní popis router šablony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445f206-d214-4c09-9857-252dc4f11cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \n",
    "language model select the model prompt best suited for the input. \n",
    "You will be given the names of the available prompts and a \n",
    "description of what the prompt is best suited for. \n",
    "You may also revise the original input if you think that revising\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string - name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string - a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f87b1-98c5-4cfe-948c-69ceb10470a7",
   "metadata": {},
   "source": [
    "A vytvoření samotného routeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f160d-bb5c-4ba9-8bfe-bbda96cec22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(chat, router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731d4b6-a561-4bcf-adc6-9df69dbbd3d2",
   "metadata": {},
   "source": [
    "A nakonec tu máme chain, který *LLMRouterChain* obaluje a spojuje ho s podchainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b49296-d632-48c7-896d-0da0b9cad176",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed5882-c749-4379-84c6-2554e4a8c1a2",
   "metadata": {},
   "source": [
    "Zde máme příklad programátorského podchainu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9553a-3412-40d0-96e4-0568d3e19d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What are good packages for graphs creation in Python?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af950ceb-9b53-4539-bb61-e16e2cdeeb2b",
   "metadata": {},
   "source": [
    "Tady je dotaz na kuchařský podchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0addc-f51c-4e93-9111-c928e64c79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How should I prepare fried cheese?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36d4ea-8595-4665-91a6-bea295998dce",
   "metadata": {},
   "source": [
    "A nakonec defaultní podchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467f3ad-2219-4c57-82d3-09102d15c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"Who was Joseph II?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118b25a-0d30-49ba-8a1b-1a54332aefd6",
   "metadata": {},
   "source": [
    "#### Transformation chain\n",
    "Viz [Transformation chain](https://python.langchain.com/docs/modules/chains/foundational/transformation).\n",
    "Transformation chain slouží k tomu, aby se na vstupní textový řetězec použila nějaká obecná pythoní funkce. Její jméno (tj. bez parametrů a kulatých závorek) se vloží do parametru *transofrm* konstruktoru *TransformChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "54de474f-f9c7-444a-8ace-f4684390ff5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:33:51.392401Z",
     "start_time": "2024-09-22T21:33:51.389591Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain\n",
    "\n",
    "def replace_animal(input_dict):\n",
    "    orig_text = input_dict[\"text\"]\n",
    "    replaced_text = orig_text.replace(\"squirrel\", \"unicorn\")\n",
    "    replaced_text = replaced_text.replace(\"squirrels\", \"unicorns\")\n",
    "    replaced_text = replaced_text.replace(\"Squirrel\", \"Unicorn\")\n",
    "    replaced_text = replaced_text.replace(\"Squirrels\", \"Unicorns\")\n",
    "    return {\"output_text\": replaced_text}\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=replace_animal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae2552-8427-41d4-9206-9e79ecd969a7",
   "metadata": {},
   "source": [
    "Následně se s chainy pracuje jako v předchozích příkladech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89372aa4-b014-4fbf-a321-0f04f115d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:34:06.786386Z",
     "start_time": "2024-09-22T21:34:06.770887Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Find strange formulations in following text and write why are they strange:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name)\n",
    "llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8b9c938-4597-4714-949d-91f4c60498e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:34:15.002212Z",
     "start_time": "2024-09-22T21:34:11.055042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '\\n    Squirrels are members of the family Sciuridae (/sɪˈjuːrɪdeɪ, -diː/), a family that includes small or medium-size rodents. \\n    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \\n    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \\n    most closely related to the mountain beaver and to the dormice.\\n    ',\n",
       " 'output': 'The text contains several strange formulations that create confusion and highlight inaccuracies:\\n\\n1. **\"Unicorns are members of the family Sciuridae\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family actually refers to squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and misleading. In mythology, unicorns are typically depicted as singular creatures with no such classifications. Additionally, the concept of \"flying unicorns\" is particularly bizarre, as it combines elements of fantasy without any basis in reality.\\n\\n3. **\"Unicorns are indigenous to the Americas, Eurasia, and Africa\"**: This statement is strange because it implies that unicorns exist in these regions, which contradicts their status as mythical beings. There is no evidence of unicorns being indigenous to any part of the world.\\n\\n4. **\"The earliest known fossilized unicorns date from the Eocene epoch\"**: This is misleading because there are no fossil records of unicorns. The Eocene epoch does have fossil records of various real animals, but unicorns, as they are commonly understood, do not exist in the fossil record.\\n\\n5. **\"The unicorns are most closely related to the mountain beaver and to the dormice\"**: This statement is strange because it suggests a biological relationship between mythical unicorns and real animals. Since unicorns are not real, they cannot have any biological relatives.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates confusion and misrepresents both the nature of unicorns and the scientific classification of animals.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.invoke(\n",
    "    \"\"\"\n",
    "    Squirrels are members of the family Sciuridae (/sɪˈjuːrɪdeɪ, -diː/), a family that includes small or medium-size rodents. \n",
    "    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \n",
    "    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \n",
    "    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \n",
    "    most closely related to the mountain beaver and to the dormice.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8e26d-ded6-43fe-99e1-982fc97eec93",
   "metadata": {},
   "source": [
    "## Paměť\n",
    "LLM modely jako takové si při odpovídání na uživatelův vstup předchozí interakce nepamatují. Proto se do nich musí explicitně přidat paměť, která bude historii v té či oné formě obsahovat.  \n",
    "#### ConversationBufferMemory\n",
    "Základním paměťovým objektem je *ConversationBufferMemory*. Ten si zkrátka pamatuje celou konverzaci tak, jak probíhala. Jak ale vypadá praktické použití? Asi nejsnazší je použit [*ConversationChain*](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/conversation/base.py). Do jeho konstruktoru vložíme chatovací model, paměť a lze sem umístit i flag, že požadujeme verbose výstup.  \n",
    "BACHA - *ConversationBufferMemory* dovoluje v parametru *memory_key* měnit defaultní klíč (s hodnotou *history*), skrze který se dá dostat k paměti. Jenomže *ConversationalChain* s ničím takovým nepočítá a pokud nedostane *history*, tak způsobí pád."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59b1498-2d58-4c57-a206-db6c54479b39",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "conv_buffer_memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=conv_buffer_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce76f98-0cfb-4b58-a01f-24fd7e122ec6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa1c2b8-1b5c-4d73-acd6-317a687f8f73",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm an AI designed to assist you with a variety of topics, answer your questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Hi, who are you?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist you with a variety of topics, answer your questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist you with a variety of topics, answer your questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"Hello! I'm an AI designed to assist you with a variety of topics, answer your questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa96aa00-dad5-4088-9a4d-25b67ef6c587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:42:29.457650Z",
     "start_time": "2024-09-23T10:42:26.927241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm an AI designed to assist and engage in conversations with you. I can provide information, answer questions, and discuss a wide range of topics. What would you like to talk about today?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Do you know any famous hamsters?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know any famous hamsters?',\n",
       " 'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist and engage in conversations with you. I can provide information, answer questions, and discuss a wide range of topics. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, there are a few famous hamsters that have captured the hearts of people! One of the most well-known is \"Hammy,\" the hamster from the animated movie \"The Secret Life of Pets.\" Another famous hamster is \"Binky,\" who gained popularity on social media for his adorable antics. Additionally, there\\'s \"Mr. Nibbles,\" a pet hamster that became an internet sensation due to his cute videos on platforms like YouTube. Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Yes, there are a few famous hamsters that have captured the hearts of people! One of the most well-known is \"Hammy,\" the hamster from the animated movie \"The Secret Life of Pets.\" Another famous hamster is \"Binky,\" who gained popularity on social media for his adorable antics. Additionally, there\\'s \"Mr. Nibbles,\" a pet hamster that became an internet sensation due to his cute videos on platforms like YouTube. Do you have a favorite hamster or a specific one in mind?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know any famous hamsters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63fc0831-a7d2-42fb-9dad-e0bf224092d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T08:17:29.696145Z",
     "start_time": "2024-09-23T08:17:28.388383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, who are you?'), AIMessage(content=\"Hello! I'm an AI designed to assist you with a variety of topics, answer questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\"), HumanMessage(content='Do you know any famous hamsters?'), AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular from the animated movie \"The Secret Life of Pets.\" There\\'s also \"Binky,\" a character from the children\\'s book series \"The Adventures of Hamster.\" Additionally, there\\'s \"Mr. Jinx,\" a hamster from the animated series \"The Amazing World of Gumball.\" Hamsters have also gained fame through social media, with many pet hamsters becoming internet sensations due to their cute antics and funny videos. Do you have a favorite hamster or a specific one in mind?')]\n",
      "Human: Have you ever heard about hamster called 'Boo'?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Have you ever heard about hamster called 'Boo'?\",\n",
       " 'history': [HumanMessage(content='Hi, who are you?'),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist you with a variety of topics, answer questions, and engage in friendly conversation. I can provide information, share interesting facts, or just chat about whatever's on your mind. How about you? What's your name?\"),\n",
       "  HumanMessage(content='Do you know any famous hamsters?'),\n",
       "  AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular from the animated movie \"The Secret Life of Pets.\" There\\'s also \"Binky,\" a character from the children\\'s book series \"The Adventures of Hamster.\" Additionally, there\\'s \"Mr. Jinx,\" a hamster from the animated series \"The Amazing World of Gumball.\" Hamsters have also gained fame through social media, with many pet hamsters becoming internet sensations due to their cute antics and funny videos. Do you have a favorite hamster or a specific one in mind?'),\n",
       "  HumanMessage(content=\"Have you ever heard about hamster called 'Boo'?\"),\n",
       "  AIMessage(content='Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his adorable looks and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster or have any other questions about famous pets, feel free to ask!')],\n",
       " 'response': 'Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his adorable looks and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster or have any other questions about famous pets, feel free to ask!'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mnotebook controller is DISPOSED. \n",
      "\u001B[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conversation.invoke(input=\"Have you ever heard about hamster called 'Boo'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5127a2e-022d-42e8-a699-35a6ddb7da58",
   "metadata": {},
   "source": [
    "Na co slouží v definici paměťového objektu parametr *return_messages*? S pomocí metody *load_memory_variables* lze z paměťového objetku získat dosavadní historii konverzace (zde prázdné složené závorky coby parametr metody mají své použití pro určité typy pamětí, které nějaký vstupní parametr požadují). Pakliže bylo *return_messages* rovno False, obdržíme výstup v podobě velkého stringu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102d6bbd-4ffa-4a2e-9253-441f696f3449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T09:52:02.035886Z",
     "start_time": "2024-09-23T09:52:01.915938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist and engage in conversations with you. I can provide information, answer questions, and discuss a wide range of topics. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, there are a few famous hamsters that have captured the hearts of people! One of the most well-known is \"Hammy,\" the hamster from the animated movie \"The Secret Life of Pets.\" Another famous hamster is \"Binky,\" who gained popularity on social media for his adorable antics. Additionally, there\\'s \"Mr. Nibbles,\" a pet hamster that became an internet sensation due to his cute videos on platforms like YouTube. Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81aacf-080c-44de-8757-ddd2bbf3317e",
   "metadata": {},
   "source": [
    "Pokud ale bude *return_messages* rovno True, má výstup metody složitější strukturu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3346f3bf-b299-4f33-8b29-8343fb4c34f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm an AI designed to assist and engage in conversations with you. I can provide information, answer questions, and discuss a wide range of topics. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, there are a few famous hamsters that have captured the hearts of people! One of the most well-known is \"Hammy,\" the hamster from the animated movie \"The Secret Life of Pets.\" Another famous hamster is \"Binky,\" who gained popularity on social media for his adorable antics. Additionally, there\\'s \"Mr. Nibbles,\" a pet hamster that became an internet sensation due to his cute videos on platforms like YouTube. Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4d858",
   "metadata": {},
   "source": [
    "Zaroven muzeme historii upravovat pres metodu \"save_context()\". Zacneme tim, ze si vytvorime novou a prazdou BufferMemory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93f8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692ac7d",
   "metadata": {},
   "source": [
    "A vlozime do ni nasledujici konverzaci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf9df0",
   "metadata": {},
   "source": [
    "Kdyz ted vytiskneme memory, dostaneme prave onu konverzaci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118794fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f25d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d3176",
   "metadata": {},
   "source": [
    "A muzeme pridavat dalsi a dalsi context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146d5cc-a7a6-46f0-af4a-5584237c51cb",
   "metadata": {},
   "source": [
    "V případě, že potřebujeme nastavit systémový prompt, bohužel musíme sáhnout po něčem komplikovanějším než je *ConversationChain* (byť v dalších příkladech pamětí budeme pro jednoduchost používat právě ten). Kód níže uvedený byl převzat (s mírnou úpravou) ze spodku [této stránky](https://python.langchain.com/docs/modules/memory/) dokumentace.  \n",
    "Pozn.: pokud bude v tomto případě u paměti nastaveno *return_messages*=False, kód spadne. Pád je dán faktem, že *MessagesPlaceholder* potřebuje historii jako list konverzací, nikoli jako jeden string. Též je třeba, aby *variable_name* v *MessagePlaceholder* odpovídalo *memory_key* v paměti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504d770-df54-4a15-a991-8a7eab6fa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are an infantile AI assistant who start every message with 'peekaboo'.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "conv_buffer_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=conv_buffer_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b211208-9e87-4d76-a0d6-c7211eb63ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation({\"question\": \"Hi, who are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a998216-e772-4de3-af55-68699a3e3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation({\"question\": \"Do you know any famous hamsters?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad91ad1-a671-4300-a66c-bd4ae710cf1f",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory\n",
    "*ConversationBufferWindowMemory* je variací na výše uvedený *ConversationBufferMemory*. Narozdíl od něj neobsahuje celou konverzaci, ale jen posledních *k* výměn (udáváme stejně se jmenujícím parametrem v konstruktoru paměti). Díky tomu je provoz chatbota levnější."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a9a74-ce83-408d-85b0-3ed26c23f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    memory=window_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fbf6f-cdd5-4b6e-b90b-34bc7e34dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda92cb3-3996-4a16-9b67-859b54ef4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60fe56-17eb-48cf-aec7-a21b35f7af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Do you know any famous rabbits?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9812d7-af38-4c78-bdb5-77e72b1c1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3f1a5",
   "metadata": {},
   "source": [
    "Alternativne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974712d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a48a7-be10-448d-b29e-2cf1b1f11bc5",
   "metadata": {},
   "source": [
    "#### ConversationTokenBufferMemory\n",
    "Na podobném principu je založena i *ConversationTokenBufferMemory*, která uchovává historii jen dokud se vejde do *max_token_limit* počtu tokenů. Pokud nějaký příspěvek tuto hranici přesahuje, historie se de facto vymeže, tj. není to tak, že by v ní zbyl kousek starého příspěvku. Jelikož tokenizace je pro různé modely různá, musí se paměti v parametru *llm* předat i použitý model. Navíc je potřeba (minimálně pro OpenAI modely, ale možná i pro open source modely) mít nainstalovaný balíček [tiktoken](https://pypi.org/project/tiktoken/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c769a-e473-406d-bc19-fbf304019d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "token_memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=60)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    memory=token_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6bc66-12bd-484c-800c-f4e4ab5ba2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd773ff1-4962-43c3-ac1b-461dc4e55341",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f5a55-0f74-4fc0-94fd-6bb96071a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Do you know any famous beavers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd329fe-6a9d-4237-9282-b2bdfba479df",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783014e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92435d6e-8e90-4bbc-beb9-8ff42f00d5e3",
   "metadata": {},
   "source": [
    "#### ConversationSummaryMemory\n",
    "Odlišným typem paměti je *ConversationSummaryMemory*. U ní se provolává jazykový model (specifikovaný v konstruktoru paměti pod parametrem *llm*, tj. může mít jiné vlastnosti než \"hlavní\" v aplikaci používaný model), který má za úkol provést sumarizaci dosavadní historie konverzace a nové konverzační výměny mezi člověkem a strojem. Ale muze to klidne byt ten samy. Užitečné je to zejména u dlouhých kovnerzací, kde úspora z redukce délky historie přebije nutnost většího počtu provolávání modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc9fab2-418d-4710-a153-367e7769927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI(temperature=0),\n",
    "                                           max_token_limit=100)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5443d978-aec8-48b6-963e-e28d53d43bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, who are you?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': '',\n",
       " 'response': \"Hello! I'm an AI designed to assist you with a wide range of topics. I can provide information, answer questions, and even engage in friendly conversation. My goal is to be helpful and informative. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca32eb8-94db-46bd-96d4-9ba12c81a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f30514-cf70-4a5e-bcde-9ca022abfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Do you know what are differences between rhinos and unicorns?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57808f63-eed8-41f2-a093-2aa7edbc5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ee973-a2e0-4d4b-98dd-3653082a3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"And what about similarities?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810d5d7-5281-474b-b4c2-7010de01df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70bea6-dfe2-4aa1-887b-1d4cbd3043de",
   "metadata": {},
   "source": [
    "#### ConversationEntityMemory\n",
    "Dalším speciálním typem paměti je *ConversationEntityMemory*. Ta z konverzace s pomocí jazykového modelu extrahuje informace o entitách.  \n",
    "Abychom se vyhnuli chybové hlášce\n",
    "```\n",
    "Got unexpected prompt input variables. The prompt expects ['history', 'input'], but got ['entities', 'history'] as inputs from memory, and input as the normal input key. (type=value_error)\n",
    "```\n",
    "musíme do *ConversationChain* přidat nový parametr *prompt*, do kterého vložíme importováním získanou *ENTITY_MEMORY_CONVERSATION_TEMPLATE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9c608-fb04-459a-bc26-8c74b9431193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fdb52-0353-4ea1-81d5-cabab0de879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f73d3-3314-4c62-8954-3c401427cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory \n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "entity_memory = ConversationEntityMemory(llm=OpenAI(temperature=0))\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entity_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ece4e-0801-402f-86d9-8724b4061c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3731f4-820b-4393-bacd-3f5c5c2e4e01",
   "metadata": {},
   "source": [
    "Pro zkontrolování obsahu paměti tentokrát nemůžeme použít *entity_memory.load_memory_variables({})*, ale musíme aplikovat *conversation.memory.entity_store.store*. Prozatím tam nic není."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49689bb0-d85e-4892-83e4-422015af71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774023ff-d12f-41f4-afc4-7ae885ff7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Do you know what are differences between rhinos and unicorns?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12104b4f-9e0e-4699-9786-f9740bd7e989",
   "metadata": {},
   "source": [
    "Postupně se ale začne pamět plnit dvojicemi \"entita\": \"informace o entitě\" (tady se to z nějakého důvodu nepovedlo...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5ffe9-f2a2-4a97-9ffc-b0ff3d36c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f0d10-3577-4841-9c72-7481fd9cd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"I read in a scientific journal that Duocorns, an unique breed of unicorns, have tow heads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125a244-0ef1-42f2-9386-ca4ffd3cdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe2681-f57f-40e8-95ae-752d5d9b4573",
   "metadata": {},
   "source": [
    "# Q&A nad dokumenty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be55a8-340f-46d7-80d0-9b3daab60c98",
   "metadata": {},
   "source": [
    "#### Načtení dokumentů\n",
    "##### Načtení pdfka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0012e0-a2fc-463c-abb1-4818466fe859",
   "metadata": {},
   "source": [
    "S klasickým chatbotem si sice můžeme povídat, ale chudák zná přinejlepším jen ty informace, které měl k dispozici při trénování. Co když s ním ale chceme diskutovat obsah našich pro něj v době učení neznámých dokumentů? Této problematice se budeme věnovat právě nyní.  \n",
    "Pro začátek se bude naše množina dokumentů skládat z jednoho jediného kusu - z podmínek ke kreditním kartám od jedné z bank (nalezitelné [zde](https://www.kb.cz/cs/o-bance/dokumenty#13-Platebni-karty-debetni-a-kreditni)). Jedná se o pdf soubor. Pdfka ale umí langchain načítat až po nainstalování balíčku pypdf (přesněji různé langchainové metody mají různé prerekvizity, ale tahle cesta je asi nejméně komplikovaná).  \n",
    "Nejprve vytvoříme instanci třídy PyPDFLoader a to sice tak, že do konstruktoru vložíme cestu k souboru. Bacha - musí se jednat o string, nikoli o Path! Na instanci posléze provoláme metodu *load*. Existuje sice i *load_and_split*, ale tu zde z pedagogických důvodů probírat nebudeme - leze totiž do zelí tématu probíranému o kus dál.\n",
    "\n",
    "Skvely zdroj jak nacitat PDFka je [samozrejme dokumentace](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/#using-pypdf). \n",
    "Dalsi info, treba kvuli multimodalite, je [zde](https://python.langchain.com/docs/how_to/document_loader_pdf/#use-of-multimodal-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef12bb0-c323-4ec1-8862-0109fa406a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed3104-f4f1-4f1c-863c-bbbef3e18b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"source_files\\\\podminky_debetnich_karet.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6eb52-beeb-4529-9482-18b6a1125ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da8cb6-9983-4277-8d69-21a57ef01762",
   "metadata": {},
   "source": [
    "Load nahraje krom obsahu stránek dokumentu i metadata. V nich máme název souboru a číslo stránky. Tj. vypadá to nějak takto:\n",
    "```\n",
    "[Document(page_content='  \\n PODMÍNKY D EBETNÍCH KARET  ... výnosů z  trestné činnost i a financování te rorismu , ve znění \\npozdějších předpi sů ', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'page': 0}),\n",
    " Document(page_content='PODMÍNKY DEBETNÍCH KARET ... poskytnutí dané Bankovní \\nslužby.  \\n ', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'page': 1}),\n",
    "...\n",
    "```\n",
    "Kazda stranka je objekt typu *Document*.\n",
    "Pozn.: To, že u každé stránky - objektu typu *Document* - vidíme na začátku vždy \"PODMÍNKY DEBENTNÍCH KARET\", je dáno skutečností, že se zápatí stránky, které je vždy stejné, nějak dostalo na začátek. To mimo jiné znamená, že je potřeba dokumenty před seriózním použitím začistit. Bohužel se tu též objevuje nadkritické množství mezer v místech, kde mezery neměly být (například hned v \"PODMÍNKY D EBETNÍCH KARET\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11701eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7c910-4ed0-4513-8b8a-40d997b41447",
   "metadata": {},
   "source": [
    "Jiný způsob, jak načíst obsah pdf souborů, je založen na práci balíčku [unstructured](https://pypi.org/project/unstructured/). Při přípravě tohoto textu jsem (pokud si dobře pamatuji) pro pfd žádnou rozšířenou verzi (ala pip install \"unstructured[pdf]\") instalovat nemusel. Tudíž jsem nenarazil na potřebu mít Rust kompilátor kvůli jedné z prerekvizit - balíčku safetensors. Nicméně dodatečně bylo třeba nainstalovat balíčky pdf2image a pdfminer.six (nikoli pdfminer - ten už je neudržovaný, navíc snaha o jeho použití skončila s chybovou hláškou \"ModuleNotFoundError: No module named 'pdfminer.high_level'\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15630cd4-9ce1-424e-b5a5-c702cb5111d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6da361-0c78-4bee-a6af-1990d15fb959",
   "metadata": {},
   "source": [
    "Unstructured loadery mohou fungovat ve dvou modech. Pokud bude parametr *mode* položen rovný \"single\", tak se celý dokument - zde pdfko - po použití metody *load* vrátí jako jeden langchainový *Document* objekt (tj. neproběhne ani rozdělení na stránky). Nicméně pokud se bude *mode* rovnat \"elements\", dojde k roztrhání dokumentu na malé kousky a ty kousky ponesou popisek charakterizují jejich obsah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b734b67-0ca2-42cd-81e6-521cf1051e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\", mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62357f-ddbf-40fd-af3b-3fa61ba69f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888aaf6-1073-44cd-8207-beb8d5e51840",
   "metadata": {},
   "source": [
    "Zde máme pár příkladů:\n",
    "```\n",
    "[Document(page_content='PODMÍNKY DEBETNÍCH KARET', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((239.57, 68.46839999999997), (239.57, 82.50839999999994), (456.64312, 82.50839999999994), (456.64312, 68.46839999999997)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'Title'}),\n",
    " Document(page_content='Tyto Podmínky debetních karet obsahují bližší úpravu práv a povinností vyplývajících z uzavřené smlouvy, na základě které je poskytnuta debetní karta v souladu s pravidly příslušné Karetní společnosti. Seznamte se prosím důkladně s tímto dokumentem. Vaše případné dotazy rádi zodpovíme.', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((56.64, 126.82999999999993), (56.64, 156.4699999999999), (541.018, 156.4699999999999), (541.018, 126.82999999999993)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'NarrativeText'}),\n",
    "  Document(page_content='Článek 1. Poskytnutí debetní karty a její obnova', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((65.184, 169.61839999999995), (65.184, 180.65839999999992), (317.03912, 180.65839999999992), (317.03912, 169.61839999999995)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'NarrativeText'}),\n",
    " Document(page_content='1.1', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((72.504, 195.3499999999999), (72.504, 204.3499999999999), (87.48599999999999, 204.3499999999999), (87.48599999999999, 195.3499999999999)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'UncategorizedText'}),\n",
    "...\n",
    " Document(page_content='VER DDT_PODMPKEV.PDF', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((487.18, 807.3276), (487.18, 811.2876), (539.8808799999999, 811.2876), (539.8808799999999, 807.3276)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 10, 'category': 'Title'})]\n",
    "```\n",
    "Všimněme si, že kousky textu jsou seřazeny podle toho, jak se v pdfku objevily. V metadatech nalezneme mimo jiné číslo stránky, čtyři body ohraničující lokaci textu, jméno souboru anebo kategorii textu.  \n",
    "Jaké kategorie tu vidíme? \n",
    "- Title - nevyskytuje se jen u nadpisů, ale například i u kapitálkami vyvedeného zápatí (\"VER DDT_PODMPKEV.PDF\" z konce příkladu)\n",
    "- NarrativeText - většinově se jedná o občejný text\n",
    "- UncategorizedText - zde se obvykle nalézá \"smetí\" - číslování stránek, čísla paragrafů stojící mimo text anebo zápatí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3527d7-fa7b-460c-b93e-aa0d38871765",
   "metadata": {},
   "source": [
    "Rozdělení na kategorie nicméně není úplně spolehlivé. Když bychom si u našeho dokumentu nechali vypsat všechny \"Title\" dokumenty kódem\n",
    "```python\n",
    "for one_doc in data:\n",
    "    if one_doc.metadata[\"category\"] == \"Title\":\n",
    "        print(one_doc.page_content)\n",
    "```\n",
    "najdeme tam mezi nadpisy a kousky zápatí i normální text, např. \"3D Secure. Všechny námi poskytnuté debetní karty jsou 3D Secure aktivní.\". A naopak v \"NarrativeText\" člověk nalezne pár nadpisů. Je nakonec otázkou, zda není lepší, když si člověk dokument prohlédne a začistí ho ručně podle svého. Nakonec tak bude nejvhodnější single mode unstructured (narozdíl od PyPDFLoaderu nemá nabytečné mezery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f59d6-fad4-46b4-824e-e15c44314d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\", mode=\"single\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6ac5a-42f5-4431-ab9f-e7863f09c61f",
   "metadata": {},
   "source": [
    "Vytvoření objektu typu Document potřebné pro ruční vytváření fragmentů:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6497d-ed58-4601-858e-4410eae88c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "\n",
    "fragment = Document(\n",
    "    page_content=\"this is fragment text\",\n",
    "    metadata={\"file\":\"something.pdf\", \"page\":0, \"another_metadata_field\":\"something\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a0d6a-cf0c-4235-bfa7-059c26048f97",
   "metadata": {},
   "source": [
    "##### Načtení html souboru\n",
    "Pro načítání html stránek existují v rámci Langchainu dvě podporované cesty. Jedna vyžaduje použití balíčku [unstructured](https://pypi.org/project/unstructured/). Jako data použijeme wiki stránku o [jednom druhu křečka](https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster). Zdůrazněme, že následující postup se týka html souboru uloženého na disku, nikoli webové stránky - na to je jiný loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc4df2-2598-47d7-923e-21eeb4bd8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630637a-e794-4995-943b-bb18ed253a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365adbdf-46c0-4d68-8855-71106cf137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59297196-13b6-491c-8991-c4fa23bbd9dc",
   "metadata": {},
   "source": [
    "Nahraný objekt vypadá (po vyřazení většiny textu z důvodu přehlednosti) takto:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nWinter white dwarf hamster\\n\\n43 languages\\n\\nالعربية\\n\\nAsturianu\\n\\nБългарски\\n\\nBrezhoneg\\n\\nCatalà\\n\\nCebuano\\n\\nČeština\\n\\nDeutsch\\n\\nDiné bizaad\\n\\nEesti\\n\\nEspañol\\n\\nEuskara\\n\\nفارسی\\n\\nFrançais\\n\\nFrysk\\n\\n한국어\\n\\nՀայերեն\\n\\nHrvatski\\n\\nBah  \n",
    "...  \n",
    "nCategories:\\n\\nIUCN Red List least concern species\\n\\nPhodopus\\n\\nRodents of Asia\\n\\nMammals described in 1773\\n\\nMammals of Siberia\\n\\nTaxa named by Peter Simon Pallas\\n\\nHidden categories: \\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nGood articles\\n\\nArticles with \\'species\\' microformats', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm'})]\n",
    "```\n",
    "Před použitím bude tedy potřeba provést opravdu masivní začištění."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50eec47-4c9c-424e-88c4-09d1addb7d5e",
   "metadata": {},
   "source": [
    "Opět je možné použít unstructured načítání v modu \"elements\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0846d3b-4aa9-4bfb-8feb-be7ca63f9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\", mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81140d58-5790-4d63-99d6-487772f2fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f873617-a9d9-446a-8c34-e4f20e0cf046",
   "metadata": {},
   "source": [
    "Výsledek vypadá takto:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 1, 'emphasized_text_contents': ['Toggle the table of contents'], 'emphasized_text_tags': ['span'], 'category': 'Title'}),  \n",
    "...  \n",
    " Document(page_content='population density is highly varied.', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['https://en.wikipedia.org/wiki/Population_density'], 'link_texts': ['population density'], 'category': 'NarrativeText'}),\n",
    " Document(page_content='[23]', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['#cite_note-J1979:R1998:E-23'], 'link_texts': ['[23]'], 'category': 'UncategorizedText'}),  \n",
    " ...  \n",
    "Document(page_content=\"Articles with 'species' microformats\", metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['https://en.wikipedia.org/wiki/Category:Articles_with_%27species%27_microformats'], 'link_texts': [\"Articles with 'species' microformats\"], 'category': 'ListItem'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047f941-6317-4bd8-b3e0-97112ad525d5",
   "metadata": {},
   "source": [
    "Pro načtení html souboru lze též použít loader využívající BeautifulSoup4. Moje první provolání metody *load* vedlo k chybové hlášce obsahující mimo jiné\n",
    "```\n",
    "soup = BeautifulSoup(f, **self.bs_kwargs)\n",
    "```\n",
    "a\n",
    "```\n",
    "FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?\n",
    "```\n",
    "A to i když byl ve virtuálním prostředí balíček BeautifulSoup4 nainstalován. Co ale chybělo byl balíček [lxml](https://pypi.org/project/lxml/). Po jeho nainstalování se ale (u anglického!) textu objevila další chybová hláška:\n",
    "```\n",
    "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 27841: character maps to <undefined>\n",
    "```\n",
    "To kvůli tomu, že jsem nepoužil parametr *open_encoding* a html soubor se tak otevíral s defaultním kódováním, kterým je utf-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc2256-b41e-4f68-a934-935fba97b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "loader = BSHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\", open_encoding=\"latin1\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba96dc-63d4-4a0d-ba0b-817372e57f13",
   "metadata": {},
   "source": [
    "Opět z nahraného objektu ukážeme pouze začátek a konec:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload\n",
    "...\n",
    "\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'title': 'Winter white dwarf hamster - Wikipedia'})]\n",
    "```\n",
    "Zdá se, že potřeba začištění je tu ještě větší než u balíčku unstructured..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bb12b-99c3-4fc4-b7d7-e3eadf00d680",
   "metadata": {},
   "source": [
    "##### [Načtení webové stránky](https://python.langchain.com/docs/integrations/document_loaders/web_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750427f-d1b9-496e-82e8-015233d5a0ae",
   "metadata": {},
   "source": [
    "V praxi bychom upřednostňovali, kdybychom vytěžované stránky nemuseli stahovat a kdyby si Langchain informace natahal přímo z webu. Na to slouží *WebBaseLoader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da32b1-83d7-441d-89d5-423a306afbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ef698-62bf-4dcc-95d0-696092ed803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97daed-2948-46f2-a89e-a976f97011fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b07301-096d-495e-aeb5-973d7d9416f9",
   "metadata": {},
   "source": [
    "Zde vidíme příklad formátu, v jakém je stránka načtena:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page across from the title.\n",
    "...\n",
    "\\nContact Wikipedia\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'title': 'Winter white dwarf hamster - Wikipedia', 'language': 'en'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ff565-b138-4af7-8910-533ba5444794",
   "metadata": {},
   "source": [
    "V rámci jednoho volání lze načíst i více stránek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72523577-e118-4df4-bdf7-4cadcf5d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader([\n",
    "    \"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\", \n",
    "    \"https://en.wikipedia.org/wiki/Syrian_hamster\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67adca37-68f5-4d20-b0c3-3dcd6bef3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000d2d3-e78f-4d37-ab07-0da4c802d7b4",
   "metadata": {},
   "source": [
    "Ukázka výsledku:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\n",
    "...\n",
    "\\nContact Wikipedia\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'title': 'Winter white dwarf hamster - Wikipedia', 'language': 'en'}),\n",
    " Document(page_content='\\n\\n\\n\\nGolden hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\n",
    "...\n",
    "\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'title': 'Golden hamster - Wikipedia', 'language': 'en'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3cdb2-655f-4084-b30c-e4f518bef75d",
   "metadata": {},
   "source": [
    "I pro načítání stránek z webu existuje [unstructured loader](https://python.langchain.com/docs/integrations/document_loaders/url)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d931406-abe4-4a2f-ae86-c2d97d05465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f56af1-2736-420e-a1f4-2d8eda02b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\", \n",
    "    \"https://en.wikipedia.org/wiki/Syrian_hamster\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278a424-b8e8-4177-aa33-0048276f51da",
   "metadata": {},
   "source": [
    "Když člověk nemá nainstalovaný balíček libmagic, objeví se hlášky\n",
    "```\n",
    "libmagic is unavailable but assists in filetype detection on file-like objects. Please consider installing libmagic for better results.\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster, exception: Invalid file. The FileType.UNK file type is not supported in partition.\n",
    "libmagic is unavailable but assists in filetype detection on file-like objects. Please consider installing libmagic for better results.\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Syrian_hamster, exception: Invalid file. The FileType.UNK file type is not supported in partition.\n",
    "```\n",
    "Načtený objekt pak bude prázdným listem.\n",
    "Problém je, že existuje více libmagic ([zde](https://pypi.org/project/python-libmagic/#description) a [zde](https://pypi.org/project/libmagic/#description)), ty jsou ale relativně staré a prakticky od svého vzniku neudržované...  \n",
    "Též existuje balíček [python-magic](https://pypi.org/project/python-magic/#history). Ten už vypadá živěji, nicméně když nainstalujeme jeho nejnovější verzi, obdržíme errory\n",
    "```\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster, exception: module 'magic' has no attribute 'from_buffer'\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Syrian_hamster, exception: module 'magic' has no attribute 'from_buffer'\n",
    "```\n",
    "Instalace starší verze vede též k chybovým hláškám.  \n",
    "Problém lze vyřešit instalací [python-magic-bin](https://pypi.org/project/python-magic-bin). Nicméně jedná se o binárky z repa zapadaného prachem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa2cd8-8851-4337-9678-d0edc164786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845948c4-148d-4061-b304-533c3f46d8c3",
   "metadata": {},
   "source": [
    "Ukázka:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nWinter white dwarf hamster\\n\\n43 languages\\n\\nالعربية\\n\\nAsturianu\\n\\nБългарски\\n\\nBrezhoneg\\n\\nCatalà\\n\\nCebuano\\n\\nČeština\\n\\nDeutsch\\n\\nDiné bizaad\\n\\nEesti\\n\\nEspañol\\n\\nEuskara\\n\\nفارسی\\n\\nFrançais\\n\\nFrysk\\n\\n한국어\\n\\nՀայերեն\\n\\nHrvatski\\n\\nBahasa Indonesia\\n\\nItaliano\\n\\nעברית\\n\\nҚазақша\\n\\nKotava\\n\\nLatviešu\\n\\nMagyar\\n\\nمصرى\\n\\nNederlands\\n\\n日本語\\n\\nNorsk bokmål\\n\\nNorsk nynorsk\\n\\nPolski\\n\\nPortuguês\\n\\nRomână\\n  \n",
    "...  \n",
    "Red List least concern species\\n\\nPhodopus\\n\\nRodents of Asia\\n\\nMammals described in 1773\\n\\nMammals of Siberia\\n\\nTaxa named by Peter Simon Pallas\\n\\nHidden categories: \\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nGood articles\\n\\nArticles with \\'species\\' microformats', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster'}),\n",
    " Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nGolden hamster\\n\\n49 languages\\n\\nالعربية\\n\\nAragonés\\n\\nБеларуская (тарашкевіца)\\n\\nБългарски\\n\\nCatalà\\n\\nCebuano\\n\\nČeština\\n\\nCymraeg\\n\\nDeutsch\\n\\nDiné bizaad\\n\\nEesti\\n\\nEspañol\\n\\nEsperanto\\n\\nEuskara\\n\\nفارسی\\n\\nFrançais\\n\\nFrysk\\n\\nGaeilge\\n\\n한국어\\n\\nHrvatski\\n\\nBahasa Indonesia\\n\\nIta  \n",
    " ...  \n",
    " abic-language text\\n\\nAll articles with unsourced statements\\n\\nArticles with unsourced statements from June 2019\\n\\nArticles with unsourced statements from September 2019\\n\\nCommons link is on Wikidata\\n\\nArticles with GND identifiers\\n\\nArticles with J9U identifiers\\n\\nArticles with LCCN identifiers\\n\\nArticles with NKC identifiers\\n\\nArticles containing video clips', metadata={'source': 'https://en.wikipedia.org/wiki/Syrian_hamster'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec45ce-fafb-4027-86d9-4959eb81d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=urls, mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3f5a7-4c6f-4ee7-acaa-ee1974576884",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48824f7a-6dbb-4bfa-886d-b29ac45ff956",
   "metadata": {},
   "source": [
    "Ukázka:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents', metadata={'filetype': 'text/html', 'page_number': 1, 'url': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'emphasized_text_contents': ['Toggle the table of contents'], 'emphasized_text_tags': ['span'], 'category': 'Title'}),  \n",
    "...  \n",
    " Document(page_content='A hamster wheel is a common type of environmental enrichment, and it is important that hamsters have a wheel in their cage. TVT recommends wheels should be at least 30\\xa0cm for Syrian hamsters, since smaller diameters lead to permanent spinal curvatures, especially in young animals. They also recommend a solid running surface because rungs or mesh can cause injury.[19] A hamster should be able to run on its wheel without arching its back. A hamster that has to run with an arched back can have back pain and spine problems. A variety of toys and cardboard tubes and boxes can help to provide enrichment, as they are energetic and need space to exercise.[20]', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Hamster_wheel', '#cite_note-19', '#cite_note-20'], 'link_texts': ['hamster wheel', '[19]', '[20]'], 'category': 'NarrativeText'}),\n",
    " Document(page_content='Most hamsters in American and British pet stores are golden hamsters. Originally, golden hamsters occurred in just one color – the mixture of brown, black, and gold, but they have since developed a variety of color and pattern mutations, including cream, white, blonde, cinnamon, tortoiseshell, black, three different shades of gray, dominant spot, banded, and dilute.[citation needed]', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Wikipedia:Citation_needed'], 'link_texts': [None], 'emphasized_text_contents': ['citation needed', 'citation needed'], 'emphasized_text_tags': ['i', 'span'], 'category': 'NarrativeText'}),  \n",
    "...  \n",
    "Document(page_content='Articles containing video clips', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Category:Articles_containing_video_clips'], 'link_texts': ['Articles containing video clips'], 'category': 'ListItem'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc3413",
   "metadata": {},
   "source": [
    "##### Načtení YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69103e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c6740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pozor, muze trvat par minut\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151cfd8",
   "metadata": {},
   "source": [
    "##### Notion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c36b22",
   "metadata": {},
   "source": [
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "* Duplicate the page into your own Notion space and export as `Markdown / CSV`.\n",
    "* Unzip it and save it as a folder that contains the markdown file for the Notion page.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8306cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8605fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49b651-5f00-4eef-a0a9-4acc195dbc64",
   "metadata": {},
   "source": [
    "#### Splittery\n",
    "Obsah stránek by zejména pro výživnější texty mohl být větší, než počet tokenů, které dokáže v jeden okamžik jazykový model zpracovat. Proto se dokumenty musí rozdělit na malé kousky.  \n",
    "Základním nástrojem pro takovou úlohu je *CharacterTextSplitter*. V jeho konstruktoru musíme do parametru *separator* vložit separační znak (resp. posloupnost znaků). Bacha - *CharacterTextSplitter* podporuje jen a pouze jeden separátor. Pokud bude splitování probíhat podle nějakého speciálního escapovaného znaku (např. podle znaku nového řádku) a nepoužíváme regulární výrazy (tj. parametr *is_separator_regex* není položený rovný True), musíme psát jen jedno zpětné lomítko! Následně specifikujeme optimální velikost fragmentu textu (parametr *chunk_size*; číslo je v počtu znaků podle funkce *len*) a velikost překryvu mezi fragmenty (parametr *chunk_overlap*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80a8b4",
   "metadata": {},
   "source": [
    "##### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166985bf-8997-40a1-8a07-ee258f964622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbededcb-2687-4cac-8d37-af985f7d1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5b7e0-ea69-4886-8125-7cff221fd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038deb21-0278-4a83-a7fc-34a15163d6b5",
   "metadata": {},
   "source": [
    "Pokud bychom chtěli splittovat obyčejný text, použili bychom metodu *split_text* instance *CharacterTextSplitter*, přičemž inkriminovaný text by byl předán metodě jako parametr. Viz nasledujici priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181551ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba013b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e417de",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7ee85",
   "metadata": {},
   "source": [
    "Pojdme si trochu hrat s parametry, at je vidno, co to vlastne dela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45697669",
   "metadata": {},
   "source": [
    "##### Split_Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4ecfa",
   "metadata": {},
   "source": [
    "Nicméně my máme list obsahující navíc krom samotného textu i metadata o stránkách původního pdfka, s čímž není *split_text* očekávající string kompatibilní. Proto musíme použít metodu *split_documents*.  \n",
    "Jak vlastně splitování funguje?\n",
    " - pokud separátor není v dokumentu (v našem případě dokument = jedna stránka) přítomen, k žádnému rozsekání nedochází. Tj. pokud na vstupu bylo 10 stránek, bude stejný počet i na výstupu, což pro praktické použití optimální není.  \n",
    " - pokud je separátor vzácný, tak se některé dokumenty vůbec nerozsekají (protože v nich separátor není), jiné se rozdělí třeba jen podle jediného výskytu separátoru (i když i pak budou oba vzniklé fragmenty větší než *chunk_size*)\n",
    " - pokud je separátor přítomný často, proběhne rozsekávání tak, aby byla téměř dosažena, ale nikdy překročena *chunk_size* (resp. možná se dokument rozseká podle všech výskytů separátoru, ale pak se na sebe některé fragmenty znova nalepí).\n",
    "\n",
    "Bacha, pokud používáme regexy (*is_separator_regex* = True) a zvolíme nějaký obecný pattern (třeba \"\\\\w\"), tak se nám tímto patternem nahradí všechny relevantní znaky nahradí. Tj. fragment pak třeba vypadá takto:\n",
    "```\n",
    "'\\\\w \\\\w \\\\w \\\\w   \\n \\n \\n \\n \\n\\\\w \\\\w \\\\w, \\\\w. \\\\w., \\\\w \\\\w:  \\n\\\\w \\\\w, \\\\w \\\\w \\\\w \\\\w \\\\w. \\\\w, \\\\w \\\\w \\\\w, \\\\w: \\\\w  \\n\\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w, \\\\w \\\\w, \\\\w \\\\w \\\\w \\\\w/\\\\w  \\n\\\\w \\\\w \\\\w.\\\\w \\n \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w  \\\\w \\\\w, \\\\w \\\\w \\n\\\\w \\\\w \\\\w  \\\\w \\\\w \\\\w  \\\\w \\\\w'\n",
    "```\n",
    "Takovému chování zabráníme umístěním parametru *keep_separator*=True do konstruktoru *CharacterTextSplitter*u.  \n",
    "Níže vidíme příklad výstupu metody *split_documents*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8329132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69906715",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eccef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05e66b-e70d-4c9d-8d72-dc342f9017ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])\n",
    "print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b0a4-0b7f-4bfb-af53-8a828ce25e0f",
   "metadata": {},
   "source": [
    "Výše jsme viděli, že *CharacterTextSplitter* není pro práci s obyčejným textem kvůli omezení na jeden separátor moc praktický. Proto je vhodnější použít *RecursiveCharacterTextSplitter*. Ten nemá parametr *separator*, nýbrž *separators*. Do něj se vkládá list potenciálních separátorů. Jeho defaultní hodnotou je [\"\\n\\n\", \"\\n\", \" \", \"\"]. Myšlenka za touto volbou je taková, že se spitter snaží držet pohromadě odstavce (a potom věty a pak slova) tak dlouho, jak to jen jde, kvůli zachování informace schované v textu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd2dac",
   "metadata": {},
   "source": [
    "##### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f94947",
   "metadata": {},
   "source": [
    "Why doesn't this split the string below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209aa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612e0e1",
   "metadata": {},
   "source": [
    "Ok, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87684fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b78118",
   "metadata": {},
   "source": [
    "Z techhle dvou je `RecursiveCharacterTextSplitter` recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffa39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52e607",
   "metadata": {},
   "source": [
    "Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ef92c-5897-4028-a28d-866605a5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120a99d-e53f-43d2-a5a6-78575f77a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2b93e-b124-4725-9d00-714bcf1c3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d03f57-a196-46e5-a810-6b3a954f3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8df8d6",
   "metadata": {},
   "source": [
    "##### Splittovani Programovacich Jazyku - Language()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a51cc3-a01c-403c-b3f5-83a50e00d6b3",
   "metadata": {},
   "source": [
    "V případě, že bychom chtěli pracovat nikoli s přirozeným jazykem, ale s počítačovým kódem, mohou nám pomoci již předpřipravené separátory pro několik hlavních programovacích jazyků. Ty získáme naimportováním *Language* z *langchain.text_splitter*. Pokud separátory chceme vidět, musíme použít *get_separators_for_language*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed617afb-b579-4af7-be99-2e84b283caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fde4e-6531-4718-b93b-0c1d77c42b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21661ce-713d-49b9-8ed2-de0ae0e54fab",
   "metadata": {},
   "source": [
    "Při samotném praktickém použití vložíme *Language.PYTHON* do parametru *language* metody *from_language* (viz příklad převzatý z dokumentace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbdc0c-a420-4121-b9b5-b2e38fa7005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14e2f6",
   "metadata": {},
   "source": [
    "##### Token Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7282d",
   "metadata": {},
   "source": [
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b148768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb61311",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b6e41",
   "metadata": {},
   "source": [
    "##### Context aware splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e7657",
   "metadata": {},
   "source": [
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c63563",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c39de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1e760",
   "metadata": {},
   "source": [
    "##### Dalsi Splittery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdddcdb",
   "metadata": {},
   "source": [
    "Viz langchain.text_splitter.\n",
    "* **MarkdownHeaderTextSplitter()**\n",
    "* **TokenTextSplitter()**\n",
    "* **SentenceTransformersTokenTextSplitter()** - Splitting textu podle tokenu\n",
    "* **NLTKTextSplitter()** - implementuje splittovani textu pomoci knihovny NLTK\n",
    "* **SpacyTextSplitter()** - implementuje splitting text pomoci Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777839d-0678-4c62-9ab3-b5774d9ffb22",
   "metadata": {},
   "source": [
    "#### Embeddings, vectorstore\n",
    "Při hledání odpovědi na určitou otázku de facto hledáme otázce nejpodobnější fragmenty dokumentů. Nicméně jak bychom v přirozeném jazyce vůbec podobnost definovali? Nejpraktičtější řešení spočívá v převodu splitováním vyrobených fragmentů dokumentů na vektory (posloupnosti čísel). S nimi už můžeme pro (ne)podobnost aplikovat klasický matematický aparát ala cosinová podobnost. Tyto vektory se ale též musí někam uložit. Proto mluvíme obecně o tzv. vector stores, přičemž zde budeme konkrétně používat Chromu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a4874-ecc8-4a75-9d74-a68740c490af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b81c13-c1a9-47bf-b219-90e3d728ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"source_files\\\\podminky_debetnich_karet.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381eaf05-1f1d-4b7d-947c-3ccd6506597e",
   "metadata": {},
   "source": [
    "Napřed specifikujeme, jaký model budeme používat pro výpočet embeddingů. *OpenAIEmbeddings* znamená, že použijeme model text-embedding-ada-002 od OpenAI. Ten při klasickém používání ala chatování či doplňování textu není tak mocný jako GPT3.5 nebo aspoň DaVinci. Nicméně při nápočtu embeddingů to zas takovou roli nehraje a naopak se hodí, že je tento model řádově levnější."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee558e-2f58-4654-85ed-e8664fe404f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58a723-cb3b-48b8-a389-19bf36484192",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e295e",
   "metadata": {},
   "source": [
    "Kdyz uz mame inicializovany embedding, muzeme volat na nase vety embeddingovy model a prevest cele vety na vektor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22608a6",
   "metadata": {},
   "source": [
    "A pomoci kosinove podobnosti pak hledat nejpodobnejsi vety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284753c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f856dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533719e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089a0ee",
   "metadata": {},
   "source": [
    "Nicmene, to by bychom museli provest pro kazdou kombinaci hledaneho vyrazu a predem embeddovanych dokumentu. To by v praxi vedlo k tomu, ze si napiseme funkci, do ktere hodime nami hledany dotaz, ktery se nasledne porovna s nejakou databazi jiz existujicich embeddovanych kusu dokumentu a vrati to $k$ nejvic podobnych dokumentu. Proto v langchain balicku vznikl vectorestore, ktery obsahuje onu databazi embeddovanych dokumentu a taky obsahuje metodu _similarity_search()_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609539d-1bb1-42d8-80c6-0eea6cd372ad",
   "metadata": {},
   "source": [
    "Pozn.: v případě práce s Azure OpenAI použijeme *AzureOpenAIEmbeddings*. Musí se specifikovat deployment, ve kterém je nasazený model určený na embeddingování. Taktéž je třeba nastavit *chunk_size* na jedničku (jinak se objeví tuším \"too many inputs\" chybová hláška).\n",
    "```python\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(deployment=\"deplyment_name_s_embedding_modelem\", chunk_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce2462-d66a-46d5-b34a-949aaa3c547b",
   "metadata": {},
   "source": [
    "Pro použití Chromy musíme napřed nainstalovat odpovídající balíček [chromadb](https://pypi.org/project/chromadb/) (pokud se instalace nezdaří, máte možná příliš novou verzi Pythonu - v době psaní těchto řádků byla verze 3.10 ok, ale 3.12 už ne). Následně je potřeba provést importování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c534d5-abf0-47c9-87a6-14db0d70b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ffe2b-92ff-4e7d-8f4f-5b225ef896a5",
   "metadata": {},
   "source": [
    "Chroma je souborová databáze. Musíme tedy specifikovat, kam se budou její soubory (fakticky jde o parquety) ukládat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51e8698-77d7-4ced-ac35-07205982dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_doc_dir = './embeddings/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09234030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./embeddings/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17710e-554b-4ee7-aeab-01dc689c4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=rec_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=simple_doc_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ceac1-dda0-4924-bdc7-5cf9466e7a81",
   "metadata": {},
   "source": [
    "Na následující příkaz nesmíme zapomenout, neboť bez něj by se vektory fakticky neuložily na disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b53a83-2dcd-4a2a-9f66-0cef265ea6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e7800-0d04-4ad5-9880-650f6752994b",
   "metadata": {},
   "source": [
    "Pro načtení uložených embeddingů se použije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195db05b-d77c-4500-8c25-a59a1b77ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=simple_doc_dir, \n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720889f2-f41e-44ba-b994-8b3793da0888",
   "metadata": {},
   "source": [
    "V běžném provozu asi nebudeme následující příkazy krom občasných kontrol potřebovat. Nicméně ne vždy se člověk v běžném provozu pohybuje...  \n",
    "Pro počet záznamů v konkrétním vectorstoru použijeme metodu *\\_collection.count*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3114732-f64e-4fc7-8534-ff2185b676fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcad8d4-981d-4599-9fa5-f8d8f197b4d4",
   "metadata": {},
   "source": [
    "Metoda *peek* ukáže několik prvních záznamů (počet je specifikován parametrem *limit*, přičemž defaultní hodnota má velikost 10).\n",
    "```\n",
    "vectordb._collection.peek(limit=3)\n",
    "```\n",
    "Výstup metody není z nejmenších, proto ho zde v surové podobě neukazujeme. Jedná se o slovník, ve kterém jsou postupně tyto klíče a hodnoty:\n",
    "- ids s listem idček jednotlivých fragmentů dokumentů  \n",
    "- embeddings s listem vektorů (alias listů floatů), ve kteréch jsou fragmenty dokumentů zakódované  \n",
    "- metadatas s listem metadat, která nabývají podoby slovníků s klíči \"page\" a \"source\"\n",
    "- documents s listem samotných fragmentů dokumentů v textové podobě\n",
    "```\n",
    "{'ids': ['a737d8ec-39ea-11ee-8841-80ce622bc396',\n",
    "  'a73b7183-39ea-11ee-a74a-80ce622bc396',\n",
    "  'a73b7184-39ea-11ee-bd3c-80ce622bc396'],\n",
    " 'embeddings': [[0.0016977092018350959,\n",
    "   -0.013771715573966503,\n",
    "   0.0062872255221009254,\n",
    "   ....\n",
    "   ....\n",
    "   -0.0042107910849153996,\n",
    "   -0.027450013905763626,\n",
    "   -0.02284945175051689,\n",
    "   0.06665701419115067,\n",
    "   ...]],\n",
    " 'metadatas': [{'page': 0,\n",
    "   'source': 'source_files\\\\podminky_debetnich_karet.pdf'},\n",
    "  {'page': 0, 'source': 'source_files\\\\podminky_debetnich_karet.pdf'},\n",
    "  {'page': 0, 'source': 'source_files\\\\podminky_debetnich_karet.pdf'}],\n",
    " 'documents': ['PODMÍNKY D EBETNÍCH KARET   \\n \\n \\n \\n \\nKomerční bank a, a. s., se sídlem:  \\nPraha 1, Na Pří kopě 33 čp. 969, PSČ 114 07, IČO: 45317054  \\nZAPSAN Á V OBCHODNÍM REJSTŘÍKU VEDENÉM MĚSTSKÝM SOUDEM V PRAZE, ODDÍL B, VLOŽKA 1 360 1/10',\n",
    "  'VER DDT_ PODMPKEV.PDF \\n Tyto Podmínky debetních karet obsahují bližší úpravu práv a povinností vyplývajících z  uzavřené smlouvy, na základě',\n",
    "  'které je poskytnuta  debetní karta v  souladu s  pravidly příslušné Karetní společnosti.  Seznamte se prosím důkladně \\ns tímto dokumentem. Vaše p řípadné dotazy rádi zodpovíme.  \\n \\nČlánek 1. Poskytnutí  debetní karty a její obnova']}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2edb80d-5f80-40f5-a92f-c4dc8885f455",
   "metadata": {},
   "source": [
    "Metoda get (výsledek je stejný pro *get* i pro *\\_collection.get*) slouží k získání buďto některých záznamů (to tehdy, když do parametru ids vložíme string či list stringů s idčky) anebo všech záznamů (když idčka nespecifikujeme; počet vrácených fragmentů lze omezit parametrem *limit*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb91c1-afc5-4f11-b2cb-8c5bb54d3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dde3c5-2f3c-4878-83dc-7a7705f98ff8",
   "metadata": {},
   "source": [
    "Defaultně se v odpovědi neobjeví embeddingy. Toto chování je řízené parametrem *include*, který defaultně obsahuje [\"metadatas\", \"documents\"]. Tudíž pokud chceme embeddingy, musíme je do listu explicitně přidat.\n",
    "```\n",
    "vectordb.get(\n",
    "    ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\",\n",
    "    include=[\"metadatas\", \"documents\", \"embeddings\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ff5aa-7181-44a3-aece-90e4c5571640",
   "metadata": {},
   "source": [
    "Pokud chceme realizovat filtrování na základě metadat, musíme použít parametr *where*. Do něj vložíme slovník, kde klíčem bude \"page\" nebo \"source\" a hodnotou číslo stránky či zdrojový soubor>\n",
    "```\n",
    "vectordb.get(where={\"page\": 0})\n",
    "```\n",
    "```\n",
    "vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf2b5c-bbb7-46d8-9cdc-69273e745fc0",
   "metadata": {},
   "source": [
    "Pro získávání nejpodobnějších dokumentů vstupnímu textu sice slouží metoda *query* s parametrem *query_texts*, nicméně my v praxi budeme spíše používat langchainovou nadstavbu nad touto metodou."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57deb410-67c5-4716-9d44-4d7158ee0e7c",
   "metadata": {},
   "source": [
    "Co musíme udělat, když chceme některý ze záznamů updatovat? Vezměme si náhodně fragment i idčkem \"a73b7184-39ea-11ee-bd3c-80ce622bc396\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f138cd9-75d5-440d-8c91-b8b8805807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fragment = vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c0a46-5c05-4d3f-b11c-9b0b0c8c27c6",
   "metadata": {},
   "source": [
    "Jeho metadata vypadají takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce3dfd-10c9-42a0-9646-c1037cb997fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fragment[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fa92b-730b-46d0-8f44-9f05f38bc207",
   "metadata": {},
   "source": [
    "Nyní metadata přepíšeme - přidáme další pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5eb26-c33e-4ea7-9994-48e0ffbd9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fragment[\"metadatas\"] = [{\n",
    "    'page': 0, \n",
    "    'source': 'source_files\\\\podminky_debetnich_karet.pdf',\n",
    "    \"some_info\": \"Terms of use of debit cards\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff86c6-d3e1-4c9e-b59e-afe70c3decf8",
   "metadata": {},
   "source": [
    "Provedeme *update* stejnejmennou metodou (bacha, musí to být v *\\_collection* - *vectordb.update* se vztahuje na objekty typu *Document*). Prvním parametrem je idčko, poté zde máme parametr *metadatas*, do kterého vložíme nová metadata. Mohl by tu být i parametr embeddings (pro update embeddingů) či documents (pro úpravu samotných textů)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73608c4-42d2-413a-8226-d76dc9293fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb._collection.update(\"a73b7184-39ea-11ee-bd3c-80ce622bc396\", metadatas=some_fragment[\"metadatas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61657c-a501-4a1b-9e46-862a2a3253ad",
   "metadata": {},
   "source": [
    "Update se opravdu provedl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868233ff-a367-4ae5-bc65-1244ae077340",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94577ede-7839-48dd-90f3-31bb0f741a8b",
   "metadata": {},
   "source": [
    "Přičemž zbylé záznamy zůstávají touto operací nepostižené."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af7661-214f-4aa4-827d-c2332322109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.get(ids=\"a73b7183-39ea-11ee-a74a-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52dd5b7-492a-446c-a23e-272eab415f90",
   "metadata": {},
   "source": [
    "Nakonec nesmíme zapomenout na uložení změn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edd5bd-3679-4fcf-9349-65ff8265ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645d59f-4cdf-497d-8039-87aba5babff6",
   "metadata": {},
   "source": [
    "Podobným způsobem by probíhalo i mazání záznamů, kdy bychom použili metodu *delete*:\n",
    "```\n",
    "vectordb._collection.delete(ids=\"a73b7183-39ea-11ee-a74a-80ce622bc396\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ab4f4",
   "metadata": {},
   "source": [
    "##### VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedf97e",
   "metadata": {},
   "source": [
    "Jiny vector store, ktery stoji za zminku je DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f88eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10544d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e51244",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd457f3-ccf6-4113-8562-8292a990334a",
   "metadata": {},
   "source": [
    "#### Similarity search\n",
    "Řekli jsme si, že metodu *query* na hledání podobnosti dokumentů používat nebudeme. Co ale místo ní máme k dispozici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf4d78-ad11-4fe3-9ec4-44baf1eb495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Jak dlouho debentní karta platí?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61fcd-7387-4b53-9565-cffbafce3139",
   "metadata": {},
   "source": [
    "Metoda *similarity_search* vyhledává *k* nejpodobnějších fragmentů dokumentů k dokumentu vloženému do parametru *query*. Založená je na počítání cosinové podobnosti mezi vektory fragmentů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b63e5-6073-449e-965f-4d161ba2acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs = vectordb.similarity_search(query=question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b030301-9785-4ebd-8853-824e89072203",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a622f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(simple_sim_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7706efa-3e9d-485b-ad58-d2d8e78b3a9a",
   "metadata": {},
   "source": [
    "Lze do ní přidat i parametr *filter*, který se hodí pro omezení množiny, ve které se podobné framenty hledají, a to sice na základě metadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c745af6-7efb-48e7-bbf2-faecf99f1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs = vectordb.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    filter={\"page\":0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da743cf4-25f7-4ecd-a7d5-ba5e6ffa18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323089e",
   "metadata": {},
   "source": [
    "Nebo jiny hypoteticky priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d99e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are some movies about aliens made in 1980?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_docs = vectordb.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    filter={\"year\":1980}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a78e5-3dc4-4591-97d3-6316c7012d92",
   "metadata": {},
   "source": [
    "Metoda *similarity_search* u vrácených fragmentů neukazuje, jak moc jsou dokumentu v *query* podobné. Tuto informaci můžeme ale dostat s metodou *similarity_search_with_score* - ta vrací velikost cosinové podobnosti, tj. menší číslo je lepší a nejlepší je 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a6604-34d5-41cd-8d53-1877e8d95fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score_docs = vectordb.similarity_search_with_score(query=question,k=3)\n",
    "sim_score_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17345ec0-dbe8-422e-9f3d-6193b786da49",
   "metadata": {},
   "source": [
    "Podobně funguje *similarity_search_with_relevance_scores*, pouze je cosinová podobnost přepočítána na relevance score. To se nalézá v uzavřeném intervalu mezi 0 a 1, přičemž 0 jsou zcela nepodobné dokumenty, zatímco 1 mají zcela identické dokumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5160c03-35de-4d50-b388-6c4f550c7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_rel_score_docs = vectordb.similarity_search_with_relevance_scores(query=question,k=3)\n",
    "sim_rel_score_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad7e48-39c2-4215-a5e8-4b0885bf15c0",
   "metadata": {},
   "source": [
    "Na poněkud odlišném principu funguje *max_marginal_relevance_search* (MMR). Tato metoda se snaží současně optimalizovat podobnost a diverzitu dokumentů. To v praxi znamená, že najde na základě cosinové podobnosti *fetch_k* fragmentů (defaultně 20). Poté je ale seřadí tak, že penalizuje podobné či dokonce identické dokumenty a z nového řazení vrátí *k* fragmentů (defaultně 4). Bohužel zdá se, že žádné číslo kvantifikující podobnost či kvalitu výběru není ve funkci dostupné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca412e6-7d5b-4706-88c2-04f91432ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_relev_docs = vectordb.max_marginal_relevance_search(query=question,k=3, fetch_k=20)\n",
    "max_relev_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5330fa64-5b93-4c4f-bf81-853b2855ef49",
   "metadata": {},
   "source": [
    "Specialitou je použití komprese na výstupních fragmentech. Fragmenty mohou totiž obsahovat značné množství informací pro určitý dotaz nerelevantních. Užitečné informace se potom v záplavě zbytečností snadno ztratí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518dd81-b07d-45f6-a75d-da2e0aab1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2cd69-c087-418c-acfa-0b9d07057ef5",
   "metadata": {},
   "source": [
    "Abychom viděli, co Langchain dělá, zapneme debugování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341e36f-38bc-4e47-b664-7c26668b4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d682b44-9ba4-445d-89a4-2da035b0508e",
   "metadata": {},
   "source": [
    "Samotnou kompresi (či přesněji osekávání zbytečných slov) realizuje fakticky jazykový model, musíme tudíž vytvoři jeho instanci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e75ed3-91c7-4625-a190-21855878f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4291967-b73b-43d7-bcf6-91d57194f4ce",
   "metadata": {},
   "source": [
    "Následně vytvoříme samotný kompresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5787b6f-8b6b-4019-9e0a-39d915cf79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d44e08-0ac3-4752-8979-957e1189a63e",
   "metadata": {},
   "source": [
    "Na něm provoláme metodu *get_relevant_documents*. Bohužel jsem nepřišel na to, jak specifikovat počet vrácených fragmentů (parametr *k* nefunguje), takže se vrací defaultní 4.  \n",
    "\"Kompresi\" zajišťuje následující prompt:\n",
    "```\n",
    "Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: Jak dlouho debentní karta platí?\\n> Context:\\n>>>\\nplatíte  předem a  účtujeme  jej nejdříve 5.  obchodní den  po sjednání karty. V dalších měsících  po dobu \\nplatnosti karty  je cena splatná  ve stejný den . Pokud den splatnosti připa dne na den, který není Obchodním\\n>>>\\nExtracted relevant parts:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ab7b9-177d-42e3-803a-693e9d672963",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cff82-0c66-4dc5-bcba-636e92f24466",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef57b7b-085c-4878-92c7-7b266fb5aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898c662",
   "metadata": {},
   "source": [
    "Combinovani metod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a35e21",
   "metadata": {},
   "source": [
    "#### Potencialni problemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b5895",
   "metadata": {},
   "source": [
    "Jeden z problemu, se kterym se muzeme setkat je duplicita informaci. Dejme tomu, ze budeme mit mezi zdroji dat k RAGu jiz existujici zdroj a / nebo velmi podobny zdroj, ktery bude obsahovat vice stejnych kusu informace. Kdybychom pak chteli najit mezi temi chunky $k$ nejvice podobnych fragmentu dokumentu k nami polozenemu dotazu, muze se stat, ze vsech $k$ fragmentu bude totoznych a tudiz je nam takovy vysledek ne uplne uzitecny. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef87187",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e51663",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './LangChain/Chat With LLM/docs/chroma/'\n",
    "!rm -rf ./LangChain/Chat With LLM/docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e957d8f",
   "metadata": {},
   "source": [
    "Je to dano tim, ze na tenhle dotaz bylo nalezeno $k$ super podobnych fragmentu dokumentu v ruznych souborech. A protoze similarity search nevynucuje diverzitu, vrati je vsechny. Proto existuje metoda _max_marginal_relevance_search()_ o ktere jsme mluvili pred chvili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a52736",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d6c78",
   "metadata": {},
   "source": [
    "Jiny problem je vynucovani pouzivani metadat. Nasledujici dotaz se pta na treti lekci, ale odpoved bude i z jinych fragmentu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5998fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea264e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a627a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460e582",
   "metadata": {},
   "source": [
    "#### Jine typy retrievalu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eacf0b",
   "metadata": {},
   "source": [
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6dd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc9fdd-8a90-42f9-bbae-7d3d25876e73",
   "metadata": {},
   "source": [
    "#### Question answering\n",
    "Uživatel asi nebude chtít, aby mu stroj na jeho otázku vyplivl více či méně souvislé fragmenty dokumentů. Bude si spíše přát odpověď v přirozeném jazyce. Této úloze se budeme věnovat nyní.  \n",
    "Nejprve si připravme věci, se kterými jsme se seznámili již v předchozík podkapitolách."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c7bb9-85e6-456e-b298-39db8f76a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f363936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32b339-d9ee-4352-94df-9baa80f793bf",
   "metadata": {},
   "source": [
    "Následně si vytvoříme chain pro question answering - [RetrievalQA](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5213a-0764-4d27-8538-d0fcc62721d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74b26d-268f-470a-b3b1-05d5c4d16bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa5454-81ea-48f8-9f40-c9eefac5fa72",
   "metadata": {},
   "source": [
    "Otázku do něj vložíme takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88d39b-7905-4bdc-8c65-c69fae9aeba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765196c-8eb2-4ccb-b769-81d37d215b13",
   "metadata": {},
   "source": [
    "A obdržíme následující slovník:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f117e8-735a-47e0-8372-24b13b63b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2cb11",
   "metadata": {},
   "source": [
    "**Prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09b547-0428-4dcd-ac0d-bbc450fd9f20",
   "metadata": {},
   "source": [
    "Ok, odpověď v přirozeném jazyce jsme dostali. Co když bychom ale chtěli upravit systémový prompt? A jak si zobrazíme fragmenty, ze kterých jazykový model skládal odpověď?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7626304-d182-4fb2-a013-b9e92865da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cefe70-d47b-4cac-b706-3d911e5450ef",
   "metadata": {},
   "source": [
    "Zdrojové fragmenty dostaneme díky parametru *return_source_documents* rovnému True. Šablonu se svého druhu systémovým promptem pak do chainu vložíme skrze parametr *chain_type_kwargs*. Ten obsahuje slovník, ve kterém musí být pro klíč \"prompt\" vložena námi specifikovaná šablona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cd7c5-5d8a-44a7-ba72-8bdd0364e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535390a-6a15-46c2-b709-0f97225fb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6439491-e36d-423e-bcf6-5842071ff5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f291bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20891b",
   "metadata": {},
   "source": [
    "##### RetrievalQA chain types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd114c",
   "metadata": {},
   "source": [
    "V obecnosti je princip nasledujici: \n",
    "* Polozi se otazka\n",
    "* Podivame se do \"storu\" s chunkama a vybereme ty nejvic potrebny\n",
    "* Spolecne s otazkou vlozime tyhle chunky do LLM, aby nam vygeneroval smysluplnou odpoved.\n",
    "\n",
    "Tomuhle _chain_type_ se rika **stuff**, protoze se takrikajic vsechno nastuffuje do LLMka, at si s tim poradi. To ma samozrejme obvious nevyhody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    ...,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8a9be",
   "metadata": {},
   "source": [
    "Proto existuji alternativni metody.\n",
    "1. **map_reduce** \n",
    "   1. kazdy dokument zvlast posle do LLMka, spolecne s otazkou, aby se pokusil odpovedet na otazku. Hacek je v tom, ze pokud se odpoved naleza rozkrocena mezi nekolik dokumentu, tak tu odpoved retrieval nenajde. Ale vyhoda je, ze do LLMka jsme schopni takhle poslat libovolny pocet dokumentu.\n",
    "2. **refine** \n",
    "   1. taky se nekolikrat vola LLMko, ale: vezme se prvni dokument, spolecne s otazkou. Pak se vezme druhy dokument a prompt (vnitrne) se upravi, o nasledujici text: \"Mas moznost vylepsit nasledujici odpoved (pokud mozno) s nasledujicim kontextem.\". A to se dale opakuje o vsechny dokumenty v rade. \n",
    "3. **map_rerank**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d3a66",
   "metadata": {},
   "source": [
    "![chain_type](./pomocne_soubory/chain_type.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118968e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f90be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_rerank\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac2260",
   "metadata": {},
   "source": [
    "##### RetrievalQA limitations\n",
    " \n",
    "QA fails to preserve conversational history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23840e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907416f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883c3c2",
   "metadata": {},
   "source": [
    "Note, The LLM response varies. Some responses **do** include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b79d9-1eb1-4a9c-868b-73ce24c78980",
   "metadata": {},
   "source": [
    "Určité parametry můžeme vložit i do *vectordb.as_retriever()*. Například pokud bychom chtěli přejít od defaultního similarity searche na max marginal relevance search, přidáme tam parametr *search_type* s hodnotou \"mmr\". Další paramtery už nejsou samostatné, nýbrž se nalézají ve slovníku v parametru *search_kwargs*. Může jít o počet vrácených fragmentů (parametr *k*), *fetch_k* pro MMR, *score_threshold* pro similarity search na vrácení dostatečně kvalitích fragmentů či v případě filtrování dle metadat parametr filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce977a-a183-43da-903e-6b7baf85161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={'k': 5, 'fetch_k': 20}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6ea01",
   "metadata": {},
   "source": [
    "#### Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce3183-cf64-4490-a107-c3728cd6a2bc",
   "metadata": {},
   "source": [
    "Pokud chceme mít chatbota, se kterým lze diskutovat déle než jednu dialogovou výměnu, musíme si vytvořit paměťový objekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780c702-288f-4924-ba70-4607e4fc48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "conv_buff_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88fe7d-06ca-488c-85c7-f6a544437f14",
   "metadata": {},
   "source": [
    "Je třeba též použít jiný chain - *ConversationalRetrievalChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e645ba2-4cb0-44c9-afd3-b168b4a2848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915bda8-1de3-4e82-ba0e-60d0877d165b",
   "metadata": {},
   "source": [
    "Parametry jsou (krom přidání paměti) stejné jako v předchozím chainu. Nicméně v pozadí přibyl další krok, ve kterém chain vezme historii i novou uživatelovu otázku a zkondenzuje je do otázky přežvýkané. Tento krok má následující podobu: \n",
    "```\n",
    "[llm/start] [1:chain:ConversationalRetrievalChain > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
    "{\n",
    "  \"prompts\": [\n",
    "    \"Human: Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n\\nHuman: Jak dlouho debentní karta platí?\\nAssistant: Debetní karta platí do posledního dne měsíce a roku doby platnosti, která je uvedena na kartě.\\nFollow Up Input: Jak se to liší v případě, kdy máme kreditní kartu?\\nStandalone question:\"\n",
    "  ]\n",
    "}\n",
    "```\n",
    "díky čemuž vznikne otázka\n",
    "```\n",
    "\"Jak dlouho platí kreditní karta?\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f424f86-d6a5-452d-bb71-91c24b669106",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=conv_buff_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813aed2-9869-41e3-bae0-679c3f0d54f9",
   "metadata": {},
   "source": [
    "Pozn.: bacha, slovník vstupující do provolávání chainu musí mít klíč \"question\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d205400-d889-4038-b542-80b329772604",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = memory_chain({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f2688-b584-4215-9085-f43cc68b61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077423e-498f-4000-b3a5-37e9c8b656d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"why are those prerequesites needed?\"\n",
    "result = memory_chain({\"question\": question_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a2301-42c9-4fb4-adc0-7ebcbe511c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd31842-ec17-4272-a881-263566598c6c",
   "metadata": {},
   "source": [
    "BTW odpověď je asi správně, ale v celém dokumentu o kreditních kartách nebyla ani zmínka.  \n",
    "Pozn.: pokud chceme vidět zdrojové dokumenty, musíme vložit do konstruktoru *ConversationalRetrievalChain* parametr *verbose* s hodnotou True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2607c-0549-4ef7-b464-5cdd50d6cf2d",
   "metadata": {},
   "source": [
    "#### Automatické používání metadat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463fd85",
   "metadata": {},
   "source": [
    "##### Vitkuv Priklad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abbfca-a627-4f9a-b25e-32ae71d7b255",
   "metadata": {},
   "source": [
    "Načtěme si nejprve krom pdfka o debentních kartách i pdfko o kartách kreditních."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2e897-1d12-4944-a495-cd513cd395fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_list = [\n",
    "    PyPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\"),\n",
    "    PyPDFLoader(\"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\")\n",
    "]\n",
    "\n",
    "pages = []\n",
    "for loader in loaders_list:\n",
    "    pages = pages + loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c56975-6629-400f-bc1d-2b2dba6df38a",
   "metadata": {},
   "source": [
    "Nyní postupujme obvyklým způsobem (bez metadat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d827c-4107-4bb1-892a-387afb48cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928eb9-122b-4568-be95-90725a71ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "simple_doc_dir = \"embeddings\\\\two_cards\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cf2e6-699b-4fd5-abed-5e69a425ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=rec_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=simple_doc_dir\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883dc72-275c-4c24-9abb-9a6774989b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=simple_doc_dir, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482996c-7c97-410f-8697-09d67950ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=llm_model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5f300-21b4-4321-aa55-7736b97759a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191d642-ca77-4a30-a019-4b6f1d51c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Jak je to s aktivováním debentní karty?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a0759-653a-4a76-a932-985347923052",
   "metadata": {},
   "source": [
    "Pozn.: prosím o ignorování pole \"topic\" a \"product\" v metadatech - jedná se o produkt následujících kroků. zde jsou irrelevantní."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f326d8-c143-4677-a8f9-292d203cb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593283c-1e98-4514-ae4e-455574fd2444",
   "metadata": {},
   "source": [
    "Všimněte si, že i když byla odpověď asi správná, dostal se mezi nejvhodnější fragmenty i jeden fragment z pdfka o kartách kreditních.  \n",
    "Jaké je řešení? Inu, lze použít metadata. Pokud člověk pracuje s dokumenty s lehce zpracovatelným názvem (typu \"podminky_produkt_1.pdf\", \"podminky_produkt_2.pdf\") a má štěstí, nemusí přidávat žádná nová metadata. I v našem poměrně primitivním případě to ale moc nefungovalo. \n",
    "Musíme tedy data ve vektorové databázi obohatit o nové metadatové pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fd36c-8aef-4299-8b88-c2b2dc09b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "debit_cards_ids = vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})[\"ids\"]\n",
    "debit_cards_metadatas = vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4755e9-5140-4b63-9f3e-929e37324927",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cards_ids = vectordb.get(where={\"source\": \"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\"})[\"ids\"]\n",
    "credit_cards_metadatas = vectordb.get(where={\"source\": \"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\"})[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af31e7-48cc-4a9b-bba6-e8c64d70ede1",
   "metadata": {},
   "source": [
    "Hned tady může být zádrhel, když do metadat vložíme slova ve tvaru, které později jazykový model nevygeneruje. Metadatové filtrování totiž není fuzzy, ale přesné. Tudíž když modle vyvodí, že se v otázce \"Co musím udělat pro blokaci produktu debentní karty?\" ptáme na produkt \"debentní karta\", nemůžeme mít v metadatech \"debentní kart**y**\". Podobně bacha na case sensitivitu - model (přesněji vláček modelu a databázového enginu) začne pro otázku \"Co musím udělat pro blokaci produktu Debentní karta?\" hledat produkt \"Debentní karta\" a též nic nenajde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baedf9-b99d-492e-b5bb-1f01152e7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_metadata in debit_cards_metadatas:\n",
    "    one_metadata[\"product\"] = \"debentní karta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91350a2-bf2f-4914-b523-f812978631c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_metadata in credit_cards_metadatas:\n",
    "    one_metadata[\"product\"] = \"kreditní karta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a209740-e2ff-4894-b6c1-aa068c2bd85a",
   "metadata": {},
   "source": [
    "Provedeme update a změny databáze uložíme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e7b0e-1708-4624-9fea-668018bf4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb._collection.update(ids=debit_cards_ids, metadatas=debit_cards_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1e14f-e9dc-45f1-91d8-e7961da476a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb._collection.update(ids=credit_cards_ids, metadatas=credit_cards_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6895e-82fa-40b2-94bb-4eaacf6b8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4b3c3-3c2b-46ed-8efa-a36726509bfc",
   "metadata": {},
   "source": [
    "Pro získání fragmentů dokumentů, u kterých už budou hrát roli metadata, musíme použít *SelfQueryRetriever*. Ten vyžaduje mít nainstalovaný balíček [lark](https://pypi.org/project/lark/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1eee2a-68e9-47ad-a71d-0465e89a301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eecc10-ff24-4628-adac-8d7c8a7ba822",
   "metadata": {},
   "source": [
    "Musíme mu mimo jiné podhodit popis metadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df768a-b7b3-4acc-9472-4e52cc054b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"product\",\n",
    "        description=\"Product name\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The document source\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b156c6-50a2-4201-9bc5-ba8bb1ad36a8",
   "metadata": {},
   "source": [
    "Též do *SelfQueryRetriever* vložíme parametr *document_contents*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c759823-ea14-40ed-bc05-10ae212138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Bank products\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=vectordb,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a7b13-911b-4928-8721-fbc0b068442f",
   "metadata": {},
   "source": [
    "No a když jsem tohle všechno udělal, tak... to stejně nefungovalo :D. Možná jsem se špatně dotazoval, možná tenhle typ úlohy funguje snáze v angličtině. Zkusil jsem tak editovat soubor {jméno_vašeho_environmentu}\\Lib\\site-packages\\langchain\\chains\\query_constructor\\prompt.py, ve kterém je šablona za tvoření queriny do Chromy zodpovědná. No, snad jsem přitom nic nerozbil...   \n",
    "Změněné byly tyto části souboru:\n",
    "```\n",
    "BANK_DATA_SOURCE = \"\"\"\\\n",
    "```json\n",
    "{\n",
    "    \"content\": \"Informace k bankovnímu produktu\",\n",
    "    \"attributes\": {\n",
    "        \"produkt\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Název produktu\"\n",
    "        },\n",
    "        \"zamereni\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Zaměření dokumentu, jedna z možností \\\"ceník\\\", \\\"všeobecné informace\\\"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\\\n",
    "\"\"\".replace(\n",
    "    \"{\", \"{{\"\n",
    ").replace(\n",
    "    \"}\", \"}}\"\n",
    ")\n",
    "\n",
    "FULL_ANSWER = \"\"\"\\\n",
    "```json\n",
    "{{\n",
    "    \"query\": \"cena spotřebitelský úvěr\",\n",
    "    \"filter\": \"and(eq(\\\\\"produkt\\\\\", \\\\\"spotřebitelský úvěr\\\\\"), \\\n",
    "eq(\\\\\"zamereni\\\\\", \\\\\"ceník\\\\\"))\"\n",
    "}}\n",
    "```\\\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_EXAMPLES = [\n",
    "    {\n",
    "        \"i\": 1,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"Kolik stojí vyřízení spotřebitelského úvěru\",\n",
    "        \"structured_request\": FULL_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 2,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"V kolik jede vlak?\",\n",
    "        \"structured_request\": NO_FILTER_ANSWER,\n",
    "    },\n",
    "]\n",
    "\n",
    "EXAMPLES_WITH_LIMIT = [\n",
    "    {\n",
    "        \"i\": 1,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"Kolik stojí vyřízení spotřebitelského úvěru\",\n",
    "        \"structured_request\": FULL_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 2,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"V kolik jede vlak\",\n",
    "        \"structured_request\": NO_FILTER_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 3,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"What are three songs about love\",\n",
    "        \"structured_request\": WITH_LIMIT_ANSWER,\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008aeaf2-9a92-45f9-b532-b7aa899d36d6",
   "metadata": {},
   "source": [
    "Pro dotaz \"Co musím udělat pro blokaci debentní karty?\" (popř. \"Co musím udělat pro blokaci debentní karty od KB?\") se vygeneruje\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"blokace debentní karta\\\",\\n    \\\"filter\\\": \\\"NO_FILTER\\\"\\n}\\n```\"\n",
    "```\n",
    "Tj. querina správná, ale filtr se neuplatnil.\n",
    "Při dotazu \"Co musím udělat pro blokaci produktu debentní karta?\" je už filtr správný\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"blokace debentní karta\\\",\\n    \\\"filter\\\": \\\"eq(\\\\\\\"product\\\\\\\", \\\\\\\"debentní karta\\\\\\\")\\\"\\n}\\n```\"\n",
    "```\n",
    "Ale popravdě nedokážu si představit, že by v praxi uživatel používal takto pro model nápovědný dotaz.  \n",
    "Pro zajímavost - na dotaz \"Kolik budu platit u pojištění Merlin od KB?\" by vznikl filtr\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"platit pojištění Merlin KB\\\",\\n    \\\"filter\\\": \\\"and(eq(\\\\\\\"product\\\\\\\", \\\\\\\"Merlin\\\\\\\"), eq(\\\\\\\"source\\\\\\\", \\\\\\\"KB\\\\\\\"))\\\"\\n}\\n```\"\n",
    "```\n",
    "Asi by to chtělo ten šablonový prompt ze souboru trochu vylepšit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa99d2e-b609-4d9b-aef3-a50224001f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Co musím udělat pro blokaci produktu debentní karta?\"\n",
    "result = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1095a-fa7d-4b3d-967a-9c0d74238ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af23c5",
   "metadata": {},
   "source": [
    "##### Originalni prikald z Coursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b44144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './LangChain/Chat With LLM/docs/chroma/'\n",
    "!rm -rf ./LangChain/Chat With LLM/docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aed2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a764ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47175c",
   "metadata": {},
   "source": [
    "**Note:** The default model for `OpenAI` (\"from langchain.llms import OpenAI\") is `text-davinci-003`. Due to the deprication of OpenAI's model `text-davinci-003` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f16373",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece11042",
   "metadata": {},
   "source": [
    "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2634be3-73c0-4007-8739-037d275a0c6a",
   "metadata": {},
   "source": [
    "#### Prefix před fragmenty\n",
    "Co se týče problému nalezení fragmentu ke správné problematice, lze na internetu nalézt doporučení, aby se jméno problematiky vložilo na začátek každého fragmentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5f7d0-6a5f-4c80-ac7e-1becf9764493",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "loader_1 = PyPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\")\n",
    "pages_1 = loader_1.load()\n",
    "rec_splits_1 = rec_text_splitter.split_documents(pages_1)\n",
    "for one_doc in rec_splits_1:\n",
    "    one_doc.page_content = \"debentní karta \\t \" + one_doc.page_content\n",
    "\n",
    "\n",
    "loader_2 = PyPDFLoader(\"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\")\n",
    "pages_2 = loader_2.load()\n",
    "rec_splits_2 = rec_text_splitter.split_documents(pages_2)\n",
    "for one_doc in rec_splits_2:\n",
    "    one_doc.page_content = \"kreditní karta \\t \" + one_doc.page_content\n",
    "\n",
    "all_splits = rec_splits_1 + rec_splits_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715121f-a854-4b93-9a61-cf7d4b9a8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "doc_dir = \"embeddings\\\\fragment_prefix\\\\\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=doc_dir\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780c816-81f6-43c3-8ba1-20a5b36b113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=llm_model_name, temperature=0)\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79a28d-f268-4308-8770-abeca9ff593f",
   "metadata": {},
   "source": [
    "Zdá se, že funkčnost takového přístupu je omezená, nicméně pro úplné zatracení či naopak vychválení do nebes by to chtělo větší otestování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94e76f-65a1-4b67-8955-836ccfb29932",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co musím udělat pro blokaci debentní karty?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e34f32-0887-4d4f-b43f-6d02c9703ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co dělat s kreditkou zaseklou v bankomatu?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342d226-193d-4774-a81b-8ea9f3cf012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co dělat s debetní kartou zaseklou v bankomatu?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716801b-ac9f-411f-9271-01e9051e7137",
   "metadata": {},
   "source": [
    "### Kompletní ukázky\n",
    "V textu výše jsem se snažil komentovat všechny možné věci, které je třeba při vytvoření langchainové aplikace vzít v úvahu. Může být ale užitečné vidět vše pohromadě a právě proto existuje tato kapitola.\n",
    "#### Obyčejný chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d82a1c-366f-42fa-8986-e8b590792b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7, model_name=llm_model_name)\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are Sauron from 'Lord of the Ring' novel.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "window_memory = ConversationBufferWindowMemory(k=5, memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=window_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588050e0-3f77-44dc-aff4-f8cda2ac37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c1838-809b-4db5-ab3c-e5f699f4531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"I have One ring, but I will never give it to you!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fa55d-95e3-492a-b0ec-ab700f8a9fa4",
   "metadata": {},
   "source": [
    "#### Q&A chatbot\n",
    "Skript načítací záznamy do databáze se nachází níže. Možná někoho zarazí metoda listu *extend*. Ta na konec svého mateřského listu vloží všechny elementy iterable objektu (např. listu) ze svého argumentu. Tj. například pro mateřský list [1, 2, 3] a dodatečný list [4, 5] vede extend na [1, 2, 3, 4, 5], zatímco append by skončil s [1, 2, 3, [4, 5]]. No a toto je chtění chování, když si uvědomíme, že *loader.load()* nám dá list Document objektů, které odpovídají jednotlivým stránkám jednoho pdfka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41736efe-e512-4de2-a023-b1d4a793ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"source_files\\\\penzijni-plan-1-1-16.pdf\"),\n",
    "    PyPDFLoader(\"source_files\\\\penzijni-plan-3-1-16.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"ČLÁNEK\", \"\\n\\n\", \"\\n\", \".\"]\n",
    ")\n",
    "\n",
    "splits = r_splitter.split_documents(docs)\n",
    "\n",
    "persist_directory = \"embeddings\\\\chroma_persist_dir\\\\\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc91b1-4822-4982-8517-c2c21d57ca83",
   "metadata": {},
   "source": [
    "Skript realizující dotazování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd61480-0f12-418b-88d8-d7f7aa2fd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "persist_directory = \"embeddings\\\\chroma_persist_dir\\\\\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful answer:\"\"\"\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name) \n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_message=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")\n",
    "\n",
    "while True:\n",
    "    question = input(\"Napiš otázku (exit pro opuštění chatu):\\n\")\n",
    "    if question == \"exit\":\n",
    "        break \n",
    "    result = qa_chain.invoke({\"query\":question})\n",
    "    print(result[\"result\"])\n",
    "    print()\n",
    "    print(\"Zdrojové dokumenty:\")\n",
    "    for one_source_doc in result[\"source_documents\"]:\n",
    "        print(\"--------------------------\")\n",
    "        print(\"    \", one_source_doc)\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a91fab",
   "metadata": {},
   "source": [
    "#### Coursera Chatbot vcetne GUIcka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a62f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1da441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        inp.value = ''  #clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b6d92",
   "metadata": {},
   "source": [
    "## Evaluace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0bffe",
   "metadata": {},
   "source": [
    "LangChain platfroma obsahuje i nastroje pro debugging a evaluaci. Nicmene, jeden z benefitu LLM je, ze se da pouzit i pro evaluaci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce250221",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./pomocne_soubory/OutdoorClothingCatalog_1000.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdc005",
   "metadata": {},
   "source": [
    "### Create our QandA application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27f6d5",
   "metadata": {},
   "source": [
    "Zacneme tim, ze si vytvorime RAG aplikaci pro dotazovani nad csv dokumentem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ac6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model_name)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde0bbb",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d1a40",
   "metadata": {},
   "source": [
    "### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154c2e1",
   "metadata": {},
   "source": [
    "### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warning below can be safely ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74628dab",
   "metadata": {},
   "source": [
    "Zajimava metoda .apply_and_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e61669",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b22459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8912a",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b6109",
   "metadata": {},
   "source": [
    "### Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc610f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a31ce43",
   "metadata": {},
   "source": [
    "### LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850174a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4967a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model_name)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ce492",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7764abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3b63c",
   "metadata": {},
   "source": [
    "### LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ea6e1",
   "metadata": {},
   "source": [
    "The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/.  \n",
    "Use the invite code `lang_learners_2023`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21ff6c",
   "metadata": {},
   "source": [
    "## LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36feb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e1822",
   "metadata": {},
   "source": [
    "Temperature nastavujeme na 0, protoze to chceme pouzit jako reasoning agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e20907",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185fc8e",
   "metadata": {},
   "source": [
    "Dva tooly, ktery loadujeme jsou pro pouziti kalkulacky v ramci jazykoveho modelu a druhy je Wikipedia, coz nam umoznuje volat Wikipedii primo z jazykoveho modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f796d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2bbf7",
   "metadata": {},
   "source": [
    "Je dobre se podivat do dokumentace, protoze agenti jsou pomerne nova zalezitost a nektere veci se mohou zmenit. Navic, tady treba volame agenta \"CHAT_ZERO_SHOT_REACT_DESCRIPTION\", coz znamena, ze je optimalizovany pro chatovani a reagovani na popis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67530b",
   "metadata": {},
   "source": [
    "#### Math Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82f12b",
   "metadata": {},
   "source": [
    "Tenhle priklad zavola action \"calculator\" a posle mu dve cisla, na ktere ma provest operaci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460ee00",
   "metadata": {},
   "source": [
    "#### Wikipedia example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cca944",
   "metadata": {},
   "source": [
    "Naopak, tenhle priklad zavola action \"wikipedia\" a posle mu dotaz, na ktery ma odpovedet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c0fb6",
   "metadata": {},
   "source": [
    "#### Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bb369",
   "metadata": {},
   "source": [
    "\"PythonREPLTool\" je takovy jupyter notebook, ktery bezi v jazykovem modelu. Tady se muze hodit, kdyz chceme nejaky kod spustit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de47407",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93718c15",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221b0d6",
   "metadata": {},
   "source": [
    "### Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39faf5c0",
   "metadata": {},
   "source": [
    "Pro psani vlastnich toolu je dulezity, aby obsahovali podrobou dokumentaci. Tady je priklad, jak by takova dokumentace mohla vypadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ded274",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e916b",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb033e5d",
   "metadata": {},
   "source": [
    "# Function, Tools and Agents with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe71c30",
   "metadata": {},
   "source": [
    "Nova functionalita LangChainu, ktera umoznuje predavat LLM modelu nejen text, ale i nejake funkce, ktere ma vykonat. Tady se podivame na nekolik prikladu, jak toho dosahnout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d453e5",
   "metadata": {},
   "source": [
    "Zadefinujeme si novou vlastni funkci, ktera bude vracet pocasi. OpenAI pridala novou API, _functions_, ktera umoznuje volat nejake funkce primo z LLM modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ec8d7",
   "metadata": {},
   "source": [
    "Description v obou pripadech definice nize je velmi velmi dulezita. Ta totiz umoznuje LLM rozhodnout, zda a kdy volat nasi funkci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c84637",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message[\"function_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response_message[\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message[\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4f89a",
   "metadata": {},
   "source": [
    "Je treba rict, ze LLM za nas tu funkci volat nebude. To musime udelat my. Ale LLM nam pomuze s tim, ze nam rekne, zda (a pripadne kterou, v pripade vice funkci) bychom ji mohli volat. A s jakyma parametrama. Nicmene, je treba dodat, ze popisy funkci se pocitaji do context limitu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139652e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220deb1b",
   "metadata": {},
   "source": [
    "Jak vidno, kdyz do LLM vlozime vetu, ktera nevyzaduje pocasi, tak LLM nevraci parametr _fuction_call_. Tohle lze osetrit parametrem, ktery bud nakaze nebo zakaze volani funkci.\n",
    "\n",
    "Jedna se o parametr **function_call**, jehoz defaultni hodnota je \"auto\". Naopak, pokud chceme, aby LLM nevolal funkci, musime tento parametr nastavit na \"none\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea24d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Boston?\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b451d",
   "metadata": {},
   "source": [
    "Pokud chceme LLM donuti, aby volal funkci, musime tento parametr nastavit na dictionary se jmenem funkce, kterou ma volat.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab98254",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde1c8e",
   "metadata": {},
   "source": [
    "Nasledujici priklad ukazuje, jak se to da pouzit v praxi. Zavolame LLM, to nam vrati parametry, ktery vlozime do funkce a vysledek opet vracime do LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db115cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response[\"choices\"][0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6643167",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n",
    "observation = get_current_weather(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193aa4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9293d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa7d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d2c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b345700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab890b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457201c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
