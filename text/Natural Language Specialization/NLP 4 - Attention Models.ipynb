{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T13:49:33.205980Z",
     "start_time": "2024-06-19T13:49:31.062336Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaelmateju/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt \n",
    "import string\n",
    "import math\n",
    "import random\n",
    "import re # regular expression library; for tokenization of words\n",
    "import time\n",
    "import sentencepiece\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "from collections import Counter # collections library; counter: dict subclass for counting hashable objects\n",
    "from pomocne_soubory.utils_pos import get_word_tag, preprocess\n",
    "from pomocne_soubory.utils2 import get_dict\n",
    "\n",
    "import emoji\n",
    "import pickle\n",
    "\n",
    "import nltk # import NLTK to handle simple NL tasks like tokenization.\n",
    "from nltk.tokenize import word_tokenize            \n",
    "nltk.download(\"punkt\")\n",
    "from nltk.util import ngrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20834d2779f34784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:07:17.003839Z",
     "start_time": "2024-06-19T09:07:15.471677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: portalocker in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (2.8.2)\r\n",
      "Requirement already satisfied: regex in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (2024.5.15)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (0.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (1.26.4)\r\n",
      "Requirement already satisfied: colorama in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages (from sacrebleu) (4.9.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install 'sacrebleu'           # install the sacrebleu package.\n",
    "import sacrebleu                    # import sacrebleu in order compute the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fc97d7b21e5f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:07:54.989629Z",
     "start_time": "2024-06-19T09:07:17.005917Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Setting this env variable prevents TF warnings from showing up\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from pomocne_soubory.utils_nmt_attention import (sentences, train_data, val_data, english_vectorizer, portuguese_vectorizer, masked_loss, masked_acc, tokens_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2e6eb01e66b894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:07:54.993438Z",
     "start_time": "2024-06-19T09:07:54.990834Z"
    }
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa25233ed5acd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Natural Language Processing with Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03aef059c88c8b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b7c5c3412423b",
   "metadata": {},
   "source": [
    "Jeden z prvnich modelu, ktery pouzival Attention mechanismus, je model pro preklad textu. V tomto pripade se jedna o \n",
    "preklad z anglictiny do francouzstiny. Model se nazyva Seq2Seq model, se kterym prisel v roce 2014 Ilya Sutskever ze spolecnosti Google.\n",
    "Model se sklada z dvou hlavnich casti: Encoder a Decoder. Encoder prevede vstupni\n",
    "sekvenci na vektor fixni delky, tzv. embedding dimension, ktery reprezentuje vstupni sekvenci. \n",
    "Decoder prevede tento vektor na vystupni sekvenci, opet ruzne delky. V modelu se pouzivaji dva typy RNN: LSTM a GRU, \n",
    "abychom se vyhnuli problemu s vanishing/exploding gradientem. \n",
    "\n",
    "Encoder vetsinou ma embedding layer, ktery prevede slova na vektory, RNN, ktery prevede vektory na jeden vektor, \n",
    "ktery zachycuje vyznam vstupni sekvence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede97fe3da948d27",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/seq2seq_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2148dc066fbf",
   "metadata": {},
   "source": [
    "Decoder ma take embedding layer, ktery prevede slova na vektory, RNN, ktery prevede vektor na sekvenci vystupnich \n",
    "slov. Prvni slovo je vzdy <start>, ktere se prevede na vektor a ten se pouzije jako vstup do RNN. RNN pak vygeneruje\n",
    "dalsi slovo, ktere se pouzije jako vstup do dalsi iterace. Tento proces se opakuje, dokud model nevygeneruje <end>\n",
    "slovo nebo nedosahne maximalni delky vystupni sekvence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944059d2efeb9166",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/seq2seq_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925458953ee7598",
   "metadata": {},
   "source": [
    "Hlavni nevyhodou modelu je tzv. information bottleneck, kdy je cela informace z vstupni sekvence zakodovana do jednoho\n",
    "vektoru fixni delky. Pro velmi dlouhe vstupni sekvence muze byt tento vektor prilis kratky a neobsahovat dostatek \n",
    "informaci. Resenim by mohlo byt pouzit vsechny vstupni hidden states z encoderu do decoderu, ale to zase vede k \n",
    "pretizeni pameti a vypoctu. Proto vznikl Attention mechanismus, ktery umoznuje modelu se zamirit na ruzne casti\n",
    "vstupni sekvence pri generovani vystupni sekvence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3846f80e9730fa",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/seq2seq_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfcc16759d8829b",
   "metadata": {},
   "source": [
    "Attention mechasmus zkombinuje vsechny hidden states z encoderu a vytvori novy vektor, ktery se nazyva context vector. \n",
    "Zkombinuje = affini soucet hidden states z encoderu a vahy, ktere urcuji, jak moc se ma brat v potaz dany hidden \n",
    "state. Vahy zavisi na aktualnim hidden state z decoderu a vsechny hidden states z encoderu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac89708162648c",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/seq2seq_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbb65a6ddf3aa8",
   "metadata": {},
   "source": [
    "Vahy se napocitavaji pri treniniku modelu. \n",
    "\n",
    "![Seq2Seq](../pomocne_soubory/seq2seq_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d2692f51e872f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: Basic Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bf28b9b9f90c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:13:55.585104Z",
     "start_time": "2024-06-19T10:13:55.573675Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"\"\" Calculate softmax function for an array x along specified axis\n",
    "    \n",
    "        axis=0 calculates softmax across rows which means each column sums to 1 \n",
    "        axis=1 calculates softmax across columns which means each row sums to 1\n",
    "    \"\"\"\n",
    "    return np.exp(x) / np.expand_dims(np.sum(np.exp(x), axis=axis), axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f652ad451ff74",
   "metadata": {},
   "source": [
    "1: Calculating alignment scores\n",
    "\n",
    "The first step is to calculate the alignment scores. This is a measure of similarity between the decoder hidden state and each encoder hidden state. From the paper, this operation looks like\n",
    "\n",
    "$$\n",
    "\\large e_{ij} = v_a^\\top \\tanh{\\left(W_a s_{i-1} + U_a h_j\\right)}\n",
    "$$\n",
    "\n",
    "where $W_a \\in \\mathbb{R}^{n\\times m}$, $U_a \\in \\mathbb{R}^{n \\times m}$, and $v_a \\in \\mathbb{R}^m$\n",
    "are the weight matrices and $n$ is the hidden state size. In practice, this is implemented as a feedforward neural network with two layers, where $m$ is the size of the layers in the alignment network. \n",
    "\n",
    "Here $h_j$ are the encoder hidden states for each input step $j$ and $s_{i - 1}$ is the decoder hidden state of the previous step. The first layer corresponds to $W_a$ and $U_a$, while the second layer corresponds to $v_a$.\n",
    "\n",
    "To implement this, first concatenate the encoder and decoder hidden states to produce an array with size $K \\times 2n$ where $K$ is the number of encoder states/steps. For this, use `np.concatenate` ([docs](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html)). Note that there is only one decoder state so you'll need to reshape it to successfully concatenate the arrays. The easiest way is to use `decoder_state.repeat` ([docs](https://numpy.org/doc/stable/reference/generated/numpy.repeat.html#numpy.repeat)) to match the hidden state array size.\n",
    "\n",
    "Then, apply the first layer as a matrix multiplication between the weights and the concatenated input. Use the tanh function to get the activations. Finally, compute the matrix multiplication of the second layer weights and the activations. This returns the alignment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573c0f834fe1b34a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:13:57.096599Z",
     "start_time": "2024-06-19T10:13:57.089791Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 16\n",
    "attention_size = 10\n",
    "input_length = 5\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Synthetic vectors used to test\n",
    "encoder_states = np.random.randn(input_length, hidden_size)\n",
    "decoder_state = np.random.randn(1, hidden_size)\n",
    "\n",
    "# Weights for the neural network, these are typically learned through training\n",
    "# Use these in the alignment function below as the layer weights\n",
    "layer_1 = np.random.randn(2 * hidden_size, attention_size)\n",
    "layer_2 = np.random.randn(attention_size, 1)\n",
    "\n",
    "# Implement this function. Replace None with your code. Solution at the bottom of the notebook\n",
    "def alignment(encoder_states, decoder_state):\n",
    "    # First, concatenate the encoder states and the decoder state\n",
    "    inputs = np.concatenate((encoder_states, decoder_state.repeat(input_length, axis=0)), axis=1)\n",
    "    assert inputs.shape == (input_length, 2 * hidden_size)\n",
    "    \n",
    "    # Matrix multiplication of the concatenated inputs and layer_1, with tanh activation\n",
    "    activations = np.tanh(np.matmul(inputs, layer_1))\n",
    "    assert activations.shape == (input_length, attention_size)\n",
    "    \n",
    "    # Matrix multiplication of the activations with layer_2. Remember that you don't need tanh here\n",
    "    scores = np.matmul(activations, layer_2)\n",
    "    assert scores.shape == (input_length, 1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5094328d180acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:13:57.501996Z",
     "start_time": "2024-06-19T10:13:57.497897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.35790943]\n",
      " [5.92373433]\n",
      " [4.18673175]\n",
      " [2.11437202]\n",
      " [0.95767155]]\n"
     ]
    }
   ],
   "source": [
    "# Run this to test your alignment function\n",
    "scores = alignment(encoder_states, decoder_state)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d96c1c1c03f525",
   "metadata": {},
   "source": [
    "2: Turning alignment into weights\n",
    "\n",
    "The next step is to calculate the weights from the alignment scores. These weights determine the encoder outputs that are the most important for the decoder output. These weights should be between 0 and 1. You can use the softmax function (which is already implemented above) to get these weights from the attention scores. Pass the attention scores vector to the softmax function to get the weights. Mathematically,\n",
    "\n",
    "$$\n",
    "\\large \\alpha_{ij} = \\frac{\\exp{\\left(e_{ij}\\right)}}{\\sum_{k=1}^K \\exp{\\left(e_{ik}\\right)}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "3: Weight the encoder output vectors and sum\n",
    "\n",
    "The weights tell you the importance of each input word with respect to the decoder state. In this step, you use the weights to modulate the magnitude of the encoder vectors. Words with little importance will be scaled down relative to important words. Multiply each encoder vector by its respective weight to get the alignment vectors, then sum up the weighted alignment vectors to get the context vector. Mathematically,\n",
    "\n",
    "$$\n",
    "\\large c_i = \\sum_{j=1}^K\\alpha_{ij} h_{j}\n",
    "$$\n",
    "\n",
    "Implement these steps in the `attention` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c030ad8240a3953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:13:59.234922Z",
     "start_time": "2024-06-19T10:13:59.230751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63514569  0.04917298 -0.43930867 -0.9268003   1.01903919 -0.43181409\n",
      "  0.13365099 -0.84746874 -0.37572203  0.18279832 -0.90452701  0.17872958\n",
      " -0.58015282 -0.58294027 -0.75457577  1.32985756]\n"
     ]
    }
   ],
   "source": [
    "# Implement this function. Replace None with your code.\n",
    "def attention(encoder_states, decoder_state):\n",
    "    \"\"\" Example function that calculates attention, returns the context vector \n",
    "    \n",
    "        Arguments:\n",
    "        encoder_vectors: NxM numpy array, where N is the number of vectors and M is the vector length\n",
    "        decoder_vector: 1xM numpy array, M is the vector length, much be the same M as encoder_vectors\n",
    "    \"\"\" \n",
    "    \n",
    "    # First, calculate the alignment scores\n",
    "    scores = alignment(encoder_states, decoder_state)\n",
    "    \n",
    "    # Then take the softmax of the alignment scores to get a weight distribution\n",
    "    weights = softmax(scores)\n",
    "    \n",
    "    # Multiply each encoder state by its respective weight\n",
    "    weighted_scores = encoder_states * weights\n",
    "    \n",
    "    # Sum up weighted alignment vectors to get the context vector and return it\n",
    "    context = np.sum(weighted_scores, axis=0)\n",
    "    return context\n",
    "\n",
    "context_vector = attention(encoder_states, decoder_state)\n",
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b12336b44e84d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330798f0df779423",
   "metadata": {},
   "source": [
    "Pro pochopeni jak funguje attention mechanismus viz tenhle post: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e7888763185f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: Attention Mechanism - Scaled dot-product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e03b625d0c0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:00.204802Z",
     "start_time": "2024-06-19T10:14:00.078673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the word2int dictionaries\n",
    "with open(\"./pomocne_soubory/word2int_en.pkl\", \"rb\") as f:\n",
    "    en_words = pickle.load(f)\n",
    "    \n",
    "with open(\"./pomocne_soubory/word2int_fr.pkl\", \"rb\") as f:\n",
    "    fr_words = pickle.load(f)\n",
    "\n",
    "# Load the word embeddings\n",
    "en_embeddings = np.load(\"./pomocne_soubory/embeddings_en.npz\")[\"embeddings\"]\n",
    "fr_embeddings = np.load(\"./pomocne_soubory/embeddings_fr.npz\")[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5034422a6a96c88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:00.284627Z",
     "start_time": "2024-06-19T10:14:00.276045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define some helper functions\n",
    "\n",
    "def tokenize(sentence, token_mapping):\n",
    "    tokenized = []\n",
    "    \n",
    "    for word in sentence.lower().split(\" \"):\n",
    "        try:\n",
    "            tokenized.append(token_mapping[word])\n",
    "        except KeyError:\n",
    "            # Using -1 to indicate an unknown word\n",
    "            tokenized.append(-1)\n",
    "        \n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def embed(tokens, embeddings):\n",
    "    embed_size = embeddings.shape[1]\n",
    "    \n",
    "    output = np.zeros((len(tokens), embed_size))\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == -1:\n",
    "            output[i] = np.zeros((1, embed_size))\n",
    "        else:\n",
    "            output[i] = embeddings[token]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5dd9d441332c4",
   "metadata": {},
   "source": [
    "The scaled-dot product attention consists of two matrix multiplications and a softmax scaling as shown in the diagram below from [Vaswani, et al. (2017)](https://arxiv.org/abs/1706.03762). It takes three input matrices, the queries, keys, and values.\n",
    "\n",
    "![scaled-dot product attention diagram](../pomocne_soubory/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1d741f8ff03aa",
   "metadata": {},
   "source": [
    "Mathematically, this is expressed as:\n",
    "$$ \n",
    "\\large \\mathrm{Attention}\\left(Q, K, V\\right) = \\mathrm{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "where $Q$, $K$, and $V$ are the queries, keys, and values matrices respectively, and $d_k$ is the dimension of the keys. In practice, Q, K, and V all have the same dimensions. This form of attention is faster and more space-efficient than what you implemented before since it consists of only matrix multiplications instead of a learned feed-forward layer.\n",
    "\n",
    "Conceptually, the first matrix multiplication is a measure of the similarity between the queries and the keys. This is transformed into weights using the softmax function. These weights are then applied to the values with the second matrix multiplication resulting in output attention vectors. Typically, decoder states are used as the queries while encoder states are the keys and values.\n",
    "\n",
    "Exercise 1\n",
    "\n",
    "Implement the softmax function with Numpy and use it to calculate the weights from the queries and keys. Assume the queries and keys are 2D arrays (matrices). Note that since the dot-product of Q and K will be a matrix, you'll need to calculate softmax over a specific axis. See the end of the notebook for solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79400a31cb18e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:02.847339Z",
     "start_time": "2024-06-19T10:14:02.844421Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):    \n",
    "    \"\"\" Calculate softmax function for an array x\n",
    "\n",
    "        axis=0 calculates softmax across rows which means each column sums to 1 \n",
    "        axis=1 calculates softmax across columns which means each row sums to 1\n",
    "    \"\"\"\n",
    "    # Replace pass with your code.\n",
    "    y = np.exp(x) \n",
    "    return y / np.expand_dims(np.sum(y, axis=axis), axis)\n",
    "\n",
    "def calculate_weights(queries, keys):\n",
    "    \"\"\" Calculate the weights for scaled dot-product attention\"\"\"\n",
    "    #Replace None with your code.\n",
    "    dot = np.matmul(queries, keys.T)/np.sqrt(keys.shape[1])\n",
    "    weights = softmax(dot, axis=1)\n",
    "    \n",
    "    assert weights.sum(axis=1)[0] == 1, \"Each row in weights must sum to 1\"\n",
    "    \n",
    "    #Replace pass with your code.\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147e1f68dad34750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:03.668550Z",
     "start_time": "2024-06-19T10:14:03.345728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize example sentences in English and French, then get their embeddings\n",
    "sentence_en = \"The agreement on the European Economic Area was signed in August 1992 .\"\n",
    "tokenized_en = tokenize(sentence_en, en_words)\n",
    "embedded_en = embed(tokenized_en, en_embeddings)\n",
    "\n",
    "sentence_fr = \"L accord sur la zone conomique europenne a t sign en aot 1992 .\"\n",
    "tokenized_fr = tokenize(sentence_fr, fr_words)\n",
    "embedded_fr = embed(tokenized_fr, fr_embeddings)\n",
    "\n",
    "# These weights indicate alignment between words in English and French\n",
    "alignment = calculate_weights(embedded_fr, embedded_en)\n",
    "\n",
    "# Visualize weights to check for alignment\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.imshow(alignment, cmap='gray')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(alignment.shape[1]))\n",
    "ax.set_xticklabels(sentence_en.split(\" \"), rotation=90, size=16);\n",
    "ax.set_yticks(np.arange(alignment.shape[0]));\n",
    "ax.set_yticklabels(sentence_fr.split(\" \"), size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782b47a0888e0d0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:04.102218Z",
     "start_time": "2024-06-19T10:14:04.099099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the attention_qkv function is(14, 300)\n",
      "Some elements of the attention_qkv function are\n",
      "[[-0.04039161 -0.00275749  0.00389873  0.04842744 -0.02472726  0.01435613\n",
      "  -0.00370253 -0.0619686  -0.00206159  0.01615228]\n",
      " [-0.04083253 -0.00245985  0.00409068  0.04830341 -0.02479128  0.01447497\n",
      "  -0.00355203 -0.06196036 -0.00241327  0.01582606]]\n"
     ]
    }
   ],
   "source": [
    "def attention_qkv(queries, keys, values):\n",
    "    \"\"\" Calculate scaled dot-product attention from queries, keys, and values matrices \"\"\"\n",
    "    weights = calculate_weights(queries, keys)\n",
    "    return np.matmul(weights, values)\n",
    "\n",
    "\n",
    "attention_qkv_result = attention_qkv(embedded_fr, embedded_en, embedded_en)\n",
    "\n",
    "print(f\"The shape of the attention_qkv function is{attention_qkv_result.shape}\")\n",
    "print(f\"Some elements of the attention_qkv function are\\n{attention_qkv_result[0:2,:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716015b507d8d69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 Setup for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ad5fde97f0be0",
   "metadata": {},
   "source": [
    "Data preprocessing bude vysvelen v dalsim LABu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6a04f1cc9e06b",
   "metadata": {},
   "source": [
    "**Teacher Forcing** - je technika, ktera se pouziva pri trenovani modelu. V kazdem kroku modelu se pouzije skutecne \n",
    "slovo z vystupni sekvence, nikoli predikovane slovo. Tato technika zrychluje trenovani modelu, ale muze zpusobit, ze \n",
    "model se bude chovat jinak pri trenovani a pri predikci. \n",
    "\n",
    "Existuje varianta, ktera se jmenuje **Curriculum Learning**, ktera\n",
    "pouziva Teacher Forcing v case zacina vice a vice pouzivat predikovane slovo misto skutecneho slova.\n",
    "\n",
    "K teto technice existuje i opacna technika, ktera se nazyva **Scheduled Sampling**, ktera nahrazuje skutecne slovo s \n",
    "predikovanym slovem s urcitou pravdepodobnosti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c52f1df66b820",
   "metadata": {},
   "source": [
    "V LABu bude varianta modelu NMT (Neural Machine Translation), ktera pouziva Attention mechanismus. Model bude prekladat\n",
    "text z anglictiny do francouzstiny. Varianta spociva v tom, ze bude obsahovat encoder a pre-attention decoder, \n",
    "spolecne se pak spoji v attention mechanismus a vysledek se pouzije v post-attention decoderu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3218d2c3912a449",
   "metadata": {},
   "source": [
    "![scaled-dot product attention diagram](../pomocne_soubory/nmt_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3b83596edc7fa",
   "metadata": {},
   "source": [
    "![scaled-dot product attention diagram](../pomocne_soubory/nmt_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd4dad65571bba",
   "metadata": {},
   "source": [
    "## 1.3 Machine Translation Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de55f63519c92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751eadb127cf1d86",
   "metadata": {},
   "source": [
    "BLEU (Bilingual Evaluation Understudy) je metrika pro mereni kvality prekladu. Jedna se o precision metriku a \n",
    "napocitava tzv. n-gram precision. \n",
    "\n",
    "BLEU napocitava pocet shodnych n-gramu mezi predikovanou a skutecnou sekvenci (nebo sekvencich). Resp. jde po kazdem \n",
    "n-gramu v predikovane sekvenci a kouka se, zda-li se objevila v prekladu. Pokud ano, tak se zvysi pocet. Tj. jedna se\n",
    " opravdu o precision metriku.\n",
    "Nicmene, kazdy n-gram ze skutecne sekvence se muze vyskytnout nejvyse jedenkrat v predikovane sekvenci. Tj. pocet se \n",
    " pocita jako min(pocet vyskytu slova ve skutecne sekvenci, pocet vyskytu slova ve predikovane sekvenci).\n",
    "\n",
    "BLEU Score se pocita jako geometricke prumer aritmetickych hodnot precisionu pro kazdy n-gram. \n",
    "\n",
    "Nevyhoda BLEU je, ze n-gram precision nebere v potaz poradi slov. Tj. pokud je ve skutecne sekvenci slovo na jinem\n",
    "mist nez v predikovane sekvenci, tak se to nepocita jako chyba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36bfee9d4f53ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6da553e71e4336",
   "metadata": {},
   "source": [
    "$$\n",
    "BLEU = BP\\times\\Bigl( \\prod_{i=1}^{n}precision_i\\Bigr)^{(1/n)}.\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b3c29d263740",
   "metadata": {},
   "source": [
    "2. BLEU score\n",
    "\n",
    "2.1 Definitions and formulas\n",
    "\n",
    "You have seen how to calculate the BLEU score in this week's lectures. Formally, you can express the BLEU score as:\n",
    "$$\n",
    "BLEU = BP\\times\\Bigl( \\prod_{i=1}^{n}precision_i \\Bigr)^{(1/n)}.\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ba7457b7507f8",
   "metadata": {},
   "source": [
    "The BLEU score depends on the $BP$, which stands for Brevity Penalty, and the weighted geometric mean precision for different lengths of n-grams, both of which are described below. The product runs from $i=1$ to $i=n$ to account for 1-grams to n-grams and the exponent of $1/n$ is there to calculate the geometrical average. In this notebook, you will use $n=4$\n",
    "\n",
    "The **Brevity Penalty** is defined as an exponential decay:\n",
    "\n",
    "$$BP = min\\Bigl(1, e^{(1-({len(ref)}/{len(cand)}))}\\Bigr),\\tag{2}$$\n",
    "\n",
    "where ${len(ref)}$ and ${len(cand)}$ refer to the length or count of words in the reference and candidate translations. The brevity penalty helps to handle very short translations. \n",
    "\n",
    "The **precision** is defined as :\n",
    "\n",
    "$$precision_i = \\frac {\\sum_{s_i \\in{cand}}min\\Bigl(C(s_i, cand), C(s_i, ref)\\Bigr)}{\\sum_{s_i \\in{cand}} C(s_i, cand)}.\\tag{3}$$\n",
    "\n",
    "The sum goes over all the i-grams $s_i$ in the candidate sentence $cand$. $C(s_i, cand)$ and $C(s_i, ref)$ are the counts of the i-grams in the candidate and reference sentences respectively. So the sum counts all the n-grams in the candidate sentence that also appear in the reference sentence, but only counts them as many times as they appear in the reference sentence and not more. This is then divided by the total number of i-grams in the candidate sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9466d832cd2c9fc",
   "metadata": {},
   "source": [
    "2.2 Visualizing the BLEU score\n",
    "\n",
    "Brevity Penalty:\n",
    "\n",
    "The brevity penalty penalizes generated translations that are shorter than the reference sentence. It compensates for the fact that the BLEU score has no recall term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73ca7fc22e7263d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:08.189464Z",
     "start_time": "2024-06-19T10:14:08.118607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference_length = 1\n",
    "candidate_length = np.linspace(1.5, 0.5, 100)\n",
    "\n",
    "length_ratio = reference_length / candidate_length\n",
    "BP = np.minimum(1, np.exp(1 - length_ratio))\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(1)\n",
    "lines = ax.plot(length_ratio, BP)\n",
    "ax.set(\n",
    "    xlabel=\"Ratio of the length of the reference to the candidate text\",\n",
    "    ylabel=\"Brevity Penalty\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee217eac609cc5",
   "metadata": {},
   "source": [
    "N-Gram Precision:\n",
    "\n",
    "The n-gram precision counts how many n-grams (in your case unigrams, bigrams, trigrams, and four-grams for i =1 , ... , 4) match their n-gram counterpart in the reference translations. This term acts as a precision metric. Unigrams account for adequacy while longer n-grams account for fluency of the translation. To avoid overcounting, the n-gram counts are clipped to the maximal n-gram count occurring in the reference ($m_{n}^{ref}$). Typically precision shows exponential decay with the degree of the n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67d7417c41faa48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:08.684685Z",
     "start_time": "2024-06-19T10:14:08.632226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mocked dataset showing the precision for different n-grams\n",
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.7, \"3-gram\": 0.6, \"4-gram\": 0.5}\n",
    "\n",
    "# Plot the datapoints defined above\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(*zip(*data.items()))\n",
    "ax.set(ylabel=\"N-gram precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a2b221ed471c7",
   "metadata": {},
   "source": [
    "N-gram BLEU score:\n",
    "\n",
    "When the n-gram precision is normalized by the brevity penalty (BP), then the exponential decay of n-grams is almost fully compensated. The BLEU score corresponds to a geometric average of this modified n-gram precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0fd8141e28ddedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:09.731202Z",
     "start_time": "2024-06-19T10:14:09.680968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mocked dataset showing the precision multiplied by the BP for different n-grams\n",
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.77, \"3-gram\": 0.74, \"4-gram\": 0.71}\n",
    "\n",
    "# Plot the datapoints defined above\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(*zip(*data.items()))\n",
    "ax.set(ylabel=\"Modified N-gram precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac16d61d643589",
   "metadata": {},
   "source": [
    "3. Example Calculations of the BLEU score\n",
    "\n",
    "In this example you will have a reference sentence and 2 candidate sentences. You will tokenize all sentences using the NLTK package. Then you will compare the two candidates to the reference using BLEU score.\n",
    "\n",
    "First you define and tokenize the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a42bd4a6f814c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:10.053867Z",
     "start_time": "2024-06-19T10:14:10.044979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NASA Opportunity rover is battling a massive dust storm on planet Mars. -> ['the', 'nasa', 'opportunity', 'rover', 'is', 'battling', 'a', 'massive', 'dust', 'storm', 'on', 'planet', 'mars', '.']\n",
      "\n",
      "\n",
      "The Opportunity rover is combating a big sandstorm on planet Mars. -> ['the', 'opportunity', 'rover', 'is', 'combating', 'a', 'big', 'sandstorm', 'on', 'planet', 'mars', '.']\n",
      "\n",
      "\n",
      "A NASA rover is fighting a massive storm on planet Mars. -> ['a', 'nasa', 'rover', 'is', 'fighting', 'a', 'massive', 'storm', 'on', 'planet', 'mars', '.']\n"
     ]
    }
   ],
   "source": [
    "reference = \"The NASA Opportunity rover is battling a massive dust storm on planet Mars.\"\n",
    "candidate_1 = \"The Opportunity rover is combating a big sandstorm on planet Mars.\"\n",
    "candidate_2 = \"A NASA rover is fighting a massive storm on planet Mars.\"\n",
    "\n",
    "tokenized_ref = nltk.word_tokenize(reference.lower())\n",
    "tokenized_cand_1 = nltk.word_tokenize(candidate_1.lower())\n",
    "tokenized_cand_2 = nltk.word_tokenize(candidate_2.lower())\n",
    "\n",
    "print(f\"{reference} -> {tokenized_ref}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_1} -> {tokenized_cand_1}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_2} -> {tokenized_cand_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43ee344f9ed0504d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:10.437661Z",
     "start_time": "2024-06-19T10:14:10.435182Z"
    }
   },
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference):\n",
    "    \"\"\"\n",
    "    Calculates the brevity penalty given the candidate and reference sentences.\n",
    "    \"\"\"\n",
    "    reference_length = len(reference)\n",
    "    candidate_length = len(candidate)\n",
    "\n",
    "    if reference_length < candidate_length:\n",
    "        BP = 1\n",
    "    else:\n",
    "        penalty = 1 - (reference_length / candidate_length)\n",
    "        BP = np.exp(penalty)\n",
    "\n",
    "    return BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c587bb0bd3427fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:11.261495Z",
     "start_time": "2024-06-19T10:14:11.258251Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_clipped_precision(candidate, reference):\n",
    "    \"\"\"\n",
    "    Calculates the precision given the candidate and reference sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_precision_score = []\n",
    "    \n",
    "    # Loop through values 1, 2, 3, 4. This is the length of n-grams\n",
    "    for n_gram_length in range(1, 5):\n",
    "        reference_n_gram_counts = Counter(ngrams(reference, n_gram_length))        \n",
    "        candidate_n_gram_counts = Counter(ngrams(candidate, n_gram_length))                \n",
    "\n",
    "        total_candidate_ngrams = sum(candidate_n_gram_counts.values())       \n",
    "        \n",
    "        for ngram in candidate_n_gram_counts: \n",
    "            # check if it is in the reference n-gram\n",
    "            if ngram in reference_n_gram_counts:\n",
    "                # if the count of the candidate n-gram is bigger than the corresponding\n",
    "                # count in the reference n-gram, then set the count of the candidate n-gram \n",
    "                # to be equal to the reference n-gram\n",
    "                \n",
    "                if candidate_n_gram_counts[ngram] > reference_n_gram_counts[ngram]: \n",
    "                    candidate_n_gram_counts[ngram] = reference_n_gram_counts[ngram] # t\n",
    "                                                   \n",
    "            else:\n",
    "                candidate_n_gram_counts[ngram] = 0 # else set the candidate n-gram equal to zero\n",
    "\n",
    "        clipped_candidate_ngrams = sum(candidate_n_gram_counts.values())\n",
    "        \n",
    "        clipped_precision_score.append(clipped_candidate_ngrams / total_candidate_ngrams)\n",
    "    \n",
    "    # Calculate the geometric average: take the mean of elemntwise log, then exponentiate\n",
    "    # This is equivalent to taking the n-th root of the product as shown in equation (1) above\n",
    "    s = np.exp(np.mean(np.log(clipped_precision_score)))\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ebf9bb971f1f2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:11.694166Z",
     "start_time": "2024-06-19T10:14:11.691048Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_clipped_precision_2(candidate, reference):\n",
    "    \"\"\"\n",
    "    Calculates the precision given the candidate and reference sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_precision_score = []\n",
    "    \n",
    "    # Loop through values 1, 2, 3, 4. This is the length of n-grams\n",
    "    for n_gram_length in range(1, 5):\n",
    "        reference_n_gram_counts = Counter(ngrams(reference, n_gram_length))        \n",
    "        candidate_n_gram_counts = Counter(ngrams(candidate, n_gram_length))                \n",
    "\n",
    "        total_candidate_ngrams = sum(candidate_n_gram_counts.values())       \n",
    "        \n",
    "        for ngram in candidate_n_gram_counts: \n",
    "            # check if it is in the reference n-gram\n",
    "            candidate_n_gram_counts[ngram] = min([candidate_n_gram_counts[ngram], reference_n_gram_counts[ngram]])\n",
    "\n",
    "        clipped_candidate_ngrams = sum(candidate_n_gram_counts.values())\n",
    "        \n",
    "        clipped_precision_score.append(clipped_candidate_ngrams / total_candidate_ngrams)\n",
    "    \n",
    "    # Calculate the geometric average: take the mean of elemntwise log, then exponentiate\n",
    "    # This is equivalent to taking the n-th root of the product as shown in equation (1) above\n",
    "    s = np.exp(np.mean(np.log(clipped_precision_score)))\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ee1581a0f2f252c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:12.284773Z",
     "start_time": "2024-06-19T10:14:12.282123Z"
    }
   },
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference):\n",
    "    BP = brevity_penalty(candidate, reference)    \n",
    "    geometric_average_precision = average_clipped_precision_2(candidate, reference)    \n",
    "    return BP * geometric_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963221c1860fdc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:12.522294Z",
     "start_time": "2024-06-19T10:14:12.516128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score of reference versus candidate 1: 27.6\n",
      "BLEU score of reference versus candidate 2: 35.3\n"
     ]
    }
   ],
   "source": [
    "result_candidate_1 = round(bleu_score(tokenized_cand_1, tokenized_ref) * 100, 1)\n",
    "print(f\"BLEU score of reference versus candidate 1: {result_candidate_1}\")\n",
    "result_candidate_2 = round(bleu_score(tokenized_cand_2, tokenized_ref) * 100, 1)\n",
    "print(f\"BLEU score of reference versus candidate 2: {result_candidate_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "726c2aa15ff06bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:12.741950Z",
     "start_time": "2024-06-19T10:14:12.736946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score of reference versus candidate 1: 27.6\n",
      "BLEU score of reference versus candidate 2: 35.3\n"
     ]
    }
   ],
   "source": [
    "result_candidate_1 = round(sacrebleu.sentence_bleu(candidate_1, [reference]).score, 1)\n",
    "print(f\"BLEU score of reference versus candidate 1: {result_candidate_1}\")\n",
    "result_candidate_2 = round(sacrebleu.sentence_bleu(candidate_2, [reference]).score, 1)\n",
    "print(f\"BLEU score of reference versus candidate 2: {result_candidate_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6b0adacd637fc",
   "metadata": {},
   "source": [
    "4.  BLEU computation on a corpus\n",
    "\n",
    "4.1 Loading Datasets for Evaluation Using the BLEU Score\n",
    "\n",
    "In this section, you will use a simple pipeline for evaluating machine translated text. You will use English to German translations generated by [Google Translate](https://translate.google.com). There are three files you will need:\n",
    "\n",
    "1. A source text in English. In this lab, you will use the first 1671 words of the [wmt19](http://statmt.org/wmt19/translation-task.html) evaluation dataset downloaded via SacreBLEU.\n",
    "2. A reference translation to German of the corresponding first 1671 words from the original English text. This is also provided by SacreBLEU.\n",
    "3. A candidate machine translation to German from the same 1671 words. This is generated by Google Translate.\n",
    "\n",
    "With that, you can now compare the reference and candidate translation to get the BLEU Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df3fd9cc371ac44b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:12.914960Z",
     "start_time": "2024-06-19T10:14:12.889031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the raw data\n",
    "wmt19_src = open(\"pomocne_soubory/wmt19_src.txt\", \"r\")\n",
    "wmt19_src_1 = wmt19_src.read()\n",
    "wmt19_src.close()\n",
    "\n",
    "wmt19_ref = open(\"pomocne_soubory/wmt19_ref.txt\", \"r\")\n",
    "wmt19_ref_1 = wmt19_ref.read()\n",
    "wmt19_ref.close()\n",
    "\n",
    "wmt19_can = open(\"pomocne_soubory/wmt19_can.txt\", \"r\")\n",
    "wmt19_can_1 = wmt19_can.read()\n",
    "wmt19_can.close()\n",
    "\n",
    "tokenized_corpus_src = nltk.word_tokenize(wmt19_src_1.lower())\n",
    "tokenized_corpus_ref = nltk.word_tokenize(wmt19_ref_1.lower())\n",
    "tokenized_corpus_cand = nltk.word_tokenize(wmt19_can_1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9472d612b405d834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:13.073687Z",
     "start_time": "2024-06-19T10:14:13.070982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English source text:\n",
      "\n",
      "Welsh AMs worried about 'looking like muppets'\n",
      "There is consternation among some AMs at a suggestion their title should change to MWPs (Member of the Welsh Parliament).\n",
      " -> ['\\ufeffwelsh', 'ams', 'worried', 'about', \"'looking\", 'like', \"muppets'\", 'there', 'is', 'consternation', 'among', 'some', 'ams', 'at', 'a', 'suggestion', 'their', 'title', 'should', 'change', 'to', 'mwps', '(', 'member', 'of', 'the', 'welsh', 'parliament', ')', '.']\n",
      "\n",
      "\n",
      "German reference translation:\n",
      "\n",
      "Walisische Ageordnete sorgen sich \"wie Ddel auszusehen\"\n",
      "Es herrscht Bestrzung unter einigen Mitgliedern der Versammlung ber einen Vorschlag, der ihren Titel zu MWPs (Mitglied der walisischen Parlament) ndern soll.\n",
      " -> ['\\ufeffwalisische', 'ageordnete', 'sorgen', 'sich', '``', 'wie', 'ddel', 'auszusehen', \"''\", 'es', 'herrscht', 'bestrzung', 'unter', 'einigen', 'mitgliedern', 'der', 'versammlung', 'ber', 'einen', 'vorschlag', ',', 'der', 'ihren', 'titel', 'zu', 'mwps', '(', 'mitglied', 'der', 'walisischen', 'parlament', ')', 'ndern', 'soll', '.']\n",
      "\n",
      "\n",
      "German machine translation:\n",
      "\n",
      "Walisische AMs machten sich Sorgen, dass sie wie Muppets aussehen knnten\n",
      "Einige AMs sind bestrzt ber den Vorschlag, ihren Titel in MWPs (Mitglied des walisischen Parlaments) zu ndern.\n",
      "Es ist aufg -> ['walisische', 'ams', 'machten', 'sich', 'sorgen', ',', 'dass', 'sie', 'wie', 'muppets', 'aussehen', 'knnten', 'einige', 'ams', 'sind', 'bestrzt', 'ber', 'den', 'vorschlag', ',', 'ihren', 'titel', 'in', 'mwps', '(', 'mitglied', 'des', 'walisischen', 'parlaments']\n"
     ]
    }
   ],
   "source": [
    "print(\"English source text:\\n\")\n",
    "print(f\"{wmt19_src_1[0:170]} -> {tokenized_corpus_src[0:30]}\\n\\n\")\n",
    "print(\"German reference translation:\\n\")\n",
    "print(f\"{wmt19_ref_1[0:219]} -> {tokenized_corpus_ref[0:35]}\\n\\n\")\n",
    "print(\"German machine translation:\\n\")\n",
    "print(f\"{wmt19_can_1[0:199]} -> {tokenized_corpus_cand[0:29]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b72ef2d178695f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:13.907727Z",
     "start_time": "2024-06-19T10:14:13.893249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score of the reference versus candidate translation: 43.2\n"
     ]
    }
   ],
   "source": [
    "result =  round(sacrebleu.sentence_bleu(wmt19_can_1, [wmt19_ref_1]).score, 1)\n",
    "print(f\"BLEU score of the reference versus candidate translation: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d25f242c773b4",
   "metadata": {},
   "source": [
    "4.6 BLEU Score Interpretation on a Corpus\n",
    "\n",
    "The table below (taken from [here](https://cloud.google.com/translate/automl/docs/evaluate)) shows the typical values of BLEU score. You can see that the translation above is of high quality according to this table and in comparison to the given reference sentence. (*if you see \"Hard to get the gist\", please open your workspace, delete `wmt19_can.txt` and get the latest version via the Lab Help button*)\n",
    "\n",
    "|Score      | Interpretation                                                |\n",
    "|:---------:|:-------------------------------------------------------------:|\n",
    "| < 10      | Almost useless                                                |\n",
    "| 10 - 19   | Hard to get the gist                                          |\n",
    "| 20 - 29   | The gist is clear, but has significant grammatical errors     |\n",
    "| 30 - 40   | Understandable to good translations                           |\n",
    "| 40 - 50   | High quality translations                                     |\n",
    "| 50 - 60   | Very high quality, adequate, and fluent translations          |\n",
    "| > 60      | Quality often better than human                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b4aa76f65080a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ROUGE Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfd1de48d77b37",
   "metadata": {},
   "source": [
    "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) je metrika pro mereni kvality prekladu. Je to recall metrika,\n",
    "ktera pocita podobnost mezi predikovanou a skutecnou sekvenci.\n",
    "Puvodne byl ROUGE vyvinut pro mereni kvality automatickeho sumarizovani textu, ale pozdeji byl pouzit i pro mereni\n",
    "kvality prekladu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdb7ef9dab9f01",
   "metadata": {},
   "source": [
    "ROUGE se deli na nekolik typu: ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, ROUGE-SU.\n",
    "- ROUGE-N: pocita n-gram recall\n",
    "- ROUGE-L: pocita longest common subsequence recall\n",
    "- ROUGE-W: pocita weighted LCS recall\n",
    "- ROUGE-S: pocita skip-bigram recall\n",
    "- ROUGE-SU: pocita skip-bigram recall s unigramy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21faa02541fde204",
   "metadata": {},
   "source": [
    "ROUGE-N: pocita n-gram recall.\n",
    "\n",
    "Pocita se jako pocet shodnych n-gramu v predikovane a skutecne sekvenci deleno pocet n-gramu ve skutecne sekvenci. \n",
    "Nicmene na rozdil od BLEU, ROUGE-N pocita recall, tj. pocet n-gramu, ktere jsou ve skutecne sekvenci a zaroven v\n",
    "predikovane sekvenci deleno pocet n-gramu ve skutecne sekvenci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6674161e1cdf451",
   "metadata": {},
   "source": [
    "F1 score: je harmonicky prumer precision a recall. Tj.\n",
    "$$\n",
    "F1 = \\frac{2 \\times precision \\times recall}{precision + recall}\n",
    "$$\n",
    "v nasem pripade:\n",
    "$$\n",
    "F1 = \\frac{2 \\times ROUGE-N_{precision} \\times ROUGE-N_{recall}}{ROUGE-N_{precision} + ROUGE-N_{recall}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f62fd84fa35cba6",
   "metadata": {},
   "source": [
    "Stejne jako v pripade BLEU, ani zamena poradi neni chyba a nebere se v potaz poradi slov."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522092c13c81507",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.4 Sampling and Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1411a9e886df590",
   "metadata": {},
   "source": [
    "- Random Sampling\n",
    "- Temperature Sampling\n",
    "- Greedy Decoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2170ab6e13e8c",
   "metadata": {},
   "source": [
    "Greedy Decoding - vybira nejpravdepodobnejsi slovo v zaverecnem softmax layer. \n",
    "Random Sampling - vybira slovo nahodne podle pravdepodobnosti v zaverecnem softmax layer.\n",
    "Temperature Sampling - zvetsuje nebo zmensuje pravdepodobnost vyberu slova v zaverecnem softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f618cc1bd6e9e9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.5 Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2769d36d1de3f",
   "metadata": {},
   "source": [
    "Beam search dela to, ze v kazdem kroku vybira vice slov a pak vybere nejlepsi sekvenci.\n",
    "Parameter B, beam_width, urcuje, kolik sekvenci se vybere v kazdem kroku. Vybiraji se slova, dokud vsech B \n",
    "nejpravdepodobnejsich sekvenci neni konecna sekvence.\n",
    "\n",
    "Greedy Sampling je specialni pripad beam search s beam_width = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da9888e59fdc73",
   "metadata": {},
   "source": [
    "![scaled-dot product attention diagram](../pomocne_soubory/beam_search_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703515bc3d72eaf",
   "metadata": {},
   "source": [
    "Pro dekodovani, si nejprve zavolam decoder na prvni token ve vete: <start> nebo taky nekdy <sos> (start of sentence).\n",
    " Vybereme B nejpravdepodobnejsich slov a jejich pravdepodobnosti. Tyto sekvence se ulozi do beam. Pak se zavola \n",
    " decoder na kazdy token v beamu a vybere se B nejpravdepodobnejsich sekvenci. Tento proces se opakuje, dokud neni \n",
    " konecna sekvence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666f3e5f47aed60",
   "metadata": {},
   "source": [
    "![scaled-dot product attention diagram](../pomocne_soubory/beam_search_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb897b4b1345d59",
   "metadata": {},
   "source": [
    "Defaultni vanila verze beam search ma nektere nevyhody:\n",
    "- penalizuje dlouhe sekvence, coz je dusledek, ze se jedna o soucin pravdepodobnosti slov v sekvenci. To lze \n",
    "    resit, ze soucin normalizuje delkou vety.\n",
    "- vyzaduje vice pameti, protoze si uchovava B nejpravdepodobnejsich sekvenci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eccace80249afa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.6 Minimum Bayes Risk Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6442a48a5f816",
   "metadata": {},
   "source": [
    "The Minimum Bayes Risk (MBR) decoding algorithm in the context of neural machine translation aims to find a \n",
    "translation that minimizes the expected loss (or risk) based on a given loss function. Here, we will use the ROUGE \n",
    "score as the loss function to illustrate the process.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Hypothesis Space ($\\mathcal{H}$)**: The set of possible translations generated by the NMT model.\n",
    "2. **Reference Translations ($R$)**: The set of true translations (often one or more reference translations).\n",
    "3. **Loss Function**: Measures the difference between the hypothesis and the reference. We will use the ROUGE score, \n",
    "which evaluates the quality of a summary (or translation) by comparing it to reference summaries (or translations).\n",
    "\n",
    "### Expected Loss and MBR\n",
    "\n",
    "The goal of MBR is to find a hypothesis $ \\hat{h} $ that minimizes the expected loss. Formally,\n",
    "\n",
    "$$ \\hat{h} = \\arg \\min_{h \\in \\mathcal{H}} \\mathbb{E}_{h' \\sim P(h'|x)} [L(h, h')] $$\n",
    "\n",
    "where:\n",
    "- $ h $ is a hypothesis translation.\n",
    "- $ x $ is the source sentence.\n",
    "- $ P(h'|x) $ is the probability of generating hypothesis $ h' $ given the source sentence $ x $.\n",
    "- $ L(h, h') $ is the loss function measuring the difference between hypotheses $ h $ and $ h' $.\n",
    "\n",
    "Using the ROUGE score as the loss function $ L(h, h') $:\n",
    "\n",
    "$$ L(h, h') = 1 - \\text{ROUGE}(h, h') $$\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. **Generate Hypotheses**: Generate a set of possible translations $ \\mathcal{H} = \\{ h_1, h_2, \\ldots, h_n \\} $ using the NMT model.\n",
    "2. **Calculate Pairwise ROUGE**: Compute the ROUGE score between all pairs of hypotheses $ (h_i, h_j) $.\n",
    "3. **Compute Expected Loss**: For each hypothesis $ h_i $, compute the expected loss:\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}_{h' \\sim P(h'|x)} [L(h_i, h')] = \\sum_{h_j \\in \\mathcal{H}} P(h_j|x) L(h_i, h_j)\n",
    "   $$\n",
    "\n",
    "   Since $ L(h_i, h_j) = 1 - \\text{ROUGE}(h_i, h_j) $, we get:\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}_{h' \\sim P(h'|x)} [L(h_i, h')] = \\sum_{h_j \\in \\mathcal{H}} P(h_j|x) (1 - \\text{ROUGE}(h_i, h_j))\n",
    "   $$\n",
    "\n",
    "4. **Select Minimum Risk Hypothesis**: Choose the hypothesis $ \\hat{h} $ with the minimum expected loss:\n",
    "\n",
    "   $$\n",
    "   \\hat{h} = \\arg \\min_{h_i \\in \\mathcal{H}} \\sum_{h_j \\in \\mathcal{H}} P(h_j|x) (1 - \\text{ROUGE}(h_i, h_j))\n",
    "   $$\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Let's consider an example with 3 hypotheses $ \\{h_1, h_2, h_3\\} $ and their pairwise ROUGE-1 scores:\n",
    "\n",
    "| Hypotheses | $ h_1 $ | $ h_2 $ | $ h_3 $ |\n",
    "|------------|-----------|-----------|-----------|\n",
    "| $ h_1 $  | 1.0       | 0.8       | 0.6       |\n",
    "| $ h_2 $  | 0.8       | 1.0       | 0.7       |\n",
    "| $ h_3 $  | 0.6       | 0.7       | 1.0       |\n",
    "\n",
    "Assume equal probabilities $ P(h_i|x) = \\frac{1}{3} $:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{h' \\sim P(h'|x)} [L(h_1, h')] = \\frac{1}{3}(1-1.0) + \\frac{1}{3}(1-0.8) + \\frac{1}{3}(1-0.6) = 0.2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{h' \\sim P(h'|x)} [L(h_2, h')] = \\frac{1}{3}(1-0.8) + \\frac{1}{3}(1-1.0) + \\frac{1}{3}(1-0.7) = 0.1667\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{h' \\sim P(h'|x)} [L(h_3, h')] = \\frac{1}{3}(1-0.6) + \\frac{1}{3}(1-0.7) + \\frac{1}{3}(1-1.0) = 0.2333\n",
    "$$\n",
    "\n",
    "Since $ \\mathbb{E}_{h' \\sim P(h'|x)} [L(h_2, h')] $ is the minimum, the chosen hypothesis $ \\hat{h} $ is $ h_2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4d348-5add-4b68-9403-46e80984b720",
   "metadata": {},
   "source": [
    "V nasem pripade se to da jeste zjednodusit, protoze predpokladame, ze vsechny preklady mohou vzniknout se stejnou pravdepodobnosti, takze ze vzorce odpadne $ P(h_i|x)$ a nahradi se konstantou. Dale $argmin (1-ROUGE) = argmax(ROUGE)$.\n",
    "Takze vzorec pak vypada nasledovn:\n",
    "$$\n",
    "\\arg\\max_{\\hat{y}} \\frac{1}{n}\\sum_{y \\in Y} ROUGE(\\hat{y}, y)\n",
    "$$\n",
    "kde $Y$ je mnozina vsech moznych prekladu a $n$ je pocet vsech moznych prekladu, $n$ je velikost beamu, resp. pocet \n",
    "kandidat, tj. $n = |Y|$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d60fa-b1fc-4fda-bfef-97a46f75c9bb",
   "metadata": {},
   "source": [
    "![mbr](../pomocne_soubory/mbr_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6aaa49ddf810dd",
   "metadata": {},
   "source": [
    "Algoritmus metody je nasledujici:\n",
    "1. Vytvori se B nejpravdepodobnejsich sekvenci - kandidatu.\n",
    "2. Pro kazdy pr sekvenci se spocita similarity metrika nebo loss function jako je treba ROUGE score (nebo BLEU)\n",
    "3. Vybere se sekvence, ktera ma vuci ostatnim kandidatum nejvyssi similarity metriku nebo nejnizsi loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f82da223648eb",
   "metadata": {},
   "source": [
    "![mbr](../pomocne_soubory/mbr_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302348456b2975f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LAB: Neural Machine Translation with Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512e80cd1001fb9",
   "metadata": {},
   "source": [
    "1. Data Preparation\n",
    "\n",
    "The text pre-processing bits have already been taken care of (if you are interested in this be sure to check the `utils.py` file). The steps performed can be summarized as:\n",
    "\n",
    "- Reading the raw data from the text files\n",
    "- Cleaning the data (using lowercase, adding space around punctuation, trimming whitespaces, etc)\n",
    "- Splitting it into training and validation sets\n",
    "- Adding the start-of-sentence and end-of-sentence tokens to every sentence\n",
    "- Tokenizing the sentences\n",
    "- Creating a Tensorflow dataset out of the tokenized sentences\n",
    "\n",
    "Take a moment to inspect the raw sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edb4528be2be7f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:25.724989Z",
     "start_time": "2024-06-19T10:14:25.712836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English (to translate) sentence:\n",
      "\n",
      "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n",
      "\n",
      "Portuguese (translation) sentence:\n",
      "\n",
      "No importa o quanto voc tenta convencer os outros de que chocolate  baunilha, ele ainda ser chocolate, mesmo que voc possa convencer a si mesmo e poucos outros de que  baunilha.\n"
     ]
    }
   ],
   "source": [
    "portuguese_sentences, english_sentences = sentences\n",
    "\n",
    "print(f\"English (to translate) sentence:\\n\\n{english_sentences[-5]}\\n\")\n",
    "print(f\"Portuguese (translation) sentence:\\n\\n{portuguese_sentences[-5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba04256da730659e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:26.719687Z",
     "start_time": "2024-06-19T10:14:26.717711Z"
    }
   },
   "outputs": [],
   "source": [
    "del portuguese_sentences\n",
    "del english_sentences\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71c37c794567b",
   "metadata": {},
   "source": [
    "Notice that you imported an `english_vectorizer` and a `portuguese_vectorizer` from `utils.py`. These were created using [tf.keras.layers.TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) and they provide interesting features such as ways to visualize the vocabulary and convert text into tokenized ids and vice versa. In fact, you can inspect the first ten words of the vocabularies for both languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea5b069feaea1ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:28.263998Z",
     "start_time": "2024-06-19T10:14:28.104176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words of the english vocabulary:\n",
      "\n",
      "['', '[UNK]', '[SOS]', '[EOS]', '.', 'tom', 'i', 'to', 'you', 'the']\n",
      "\n",
      "First 10 words of the portuguese vocabulary:\n",
      "\n",
      "['', '[UNK]', '[SOS]', '[EOS]', '.', 'tom', 'que', 'o', 'nao', 'eu']\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 10 words of the english vocabulary:\\n\\n{english_vectorizer.get_vocabulary()[:10]}\\n\")\n",
    "print(f\"First 10 words of the portuguese vocabulary:\\n\\n{portuguese_vectorizer.get_vocabulary()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51911497b2f0a9a",
   "metadata": {},
   "source": [
    "Notice that the first 4 words are reserved for special words. In order, these are:\n",
    "\n",
    "- the empty string\n",
    "- a special token to represent an unknown word\n",
    "- a special token to represent the start of a sentence\n",
    "- a special token to represent the end of a sentence\n",
    "\n",
    "You can see how many words are in a vocabulary by using the `vocabulary_size` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167126917c6fc4db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:29.082412Z",
     "start_time": "2024-06-19T10:14:29.079791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese vocabulary is made up of 12000 words\n",
      "English vocabulary is made up of 12000 words\n"
     ]
    }
   ],
   "source": [
    "# Size of the vocabulary\n",
    "vocab_size_por = portuguese_vectorizer.vocabulary_size()\n",
    "vocab_size_eng = english_vectorizer.vocabulary_size()\n",
    "\n",
    "print(f\"Portuguese vocabulary is made up of {vocab_size_por} words\")\n",
    "print(f\"English vocabulary is made up of {vocab_size_eng} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98fcce844fecb82",
   "metadata": {},
   "source": [
    "You can define [tf.keras.layers.StringLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) objects that will help you map from words to ids and vice versa. Do this for the portuguese vocabulary since this will be useful later on when you decode the predictions from your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae0715622eeee185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:31.137543Z",
     "start_time": "2024-06-19T10:14:30.986217Z"
    }
   },
   "outputs": [],
   "source": [
    "# This helps you convert from words to ids\n",
    "word_to_id = tf.keras.layers.StringLookup(\n",
    "    vocabulary=portuguese_vectorizer.get_vocabulary(), \n",
    "    mask_token=\"\", \n",
    "    oov_token=\"[UNK]\"\n",
    ")\n",
    "\n",
    "# This helps you convert from ids to words\n",
    "id_to_word = tf.keras.layers.StringLookup(\n",
    "    vocabulary=portuguese_vectorizer.get_vocabulary(),\n",
    "    mask_token=\"\",\n",
    "    oov_token=\"[UNK]\",\n",
    "    invert=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e0e2a9dca363c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:32.377829Z",
     "start_time": "2024-06-19T10:14:32.353679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The id for the [UNK] token is 1\n",
      "The id for the [SOS] token is 2\n",
      "The id for the [EOS] token is 3\n",
      "The id for baunilha (vanilla) is 7079\n"
     ]
    }
   ],
   "source": [
    "unk_id = word_to_id(\"[UNK]\")\n",
    "sos_id = word_to_id(\"[SOS]\")\n",
    "eos_id = word_to_id(\"[EOS]\")\n",
    "baunilha_id = word_to_id(\"baunilha\")\n",
    "\n",
    "print(f\"The id for the [UNK] token is {unk_id}\")\n",
    "print(f\"The id for the [SOS] token is {sos_id}\")\n",
    "print(f\"The id for the [EOS] token is {eos_id}\")\n",
    "print(f\"The id for baunilha (vanilla) is {baunilha_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732867ff716ebfd7",
   "metadata": {},
   "source": [
    "Finally take a look at how the data that is going to be fed to the neural network looks like. Both `train_data` and `val_data` are of type `tf.data.Dataset` and are already arranged in batches of 64 examples. To get the first batch out of a tf dataset you can use the `take` method. To get the first example out of the batch you can slice the tensor and use the `numpy` method for nicer printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bed005f892151a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:33.851480Z",
     "start_time": "2024-06-19T10:14:33.428775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized english sentence:\n",
      "[  2  13 300  59 130   8   7   9 952   4   3   0   0]\n",
      "\n",
      "\n",
      "Tokenized portuguese sentence (shifted to the right):\n",
      "[   2  237  243   47   57  299   35 1024    4    0    0    0]\n",
      "\n",
      "\n",
      "Tokenized portuguese sentence:\n",
      "[ 237  243   47   57  299   35 1024    4    3    0    0    0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (to_translate, sr_translation), translation in train_data.take(1):\n",
    "    print(f\"Tokenized english sentence:\\n{to_translate[0, :].numpy()}\\n\\n\")\n",
    "    print(f\"Tokenized portuguese sentence (shifted to the right):\\n{sr_translation[0, :].numpy()}\\n\\n\")\n",
    "    print(f\"Tokenized portuguese sentence:\\n{translation[0, :].numpy()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c52fea63692b4",
   "metadata": {},
   "source": [
    "There are a couple of important details to notice.\n",
    "\n",
    "- Padding has already been applied to the tensors and the value used for this is 0\n",
    "- Each example consists of 3 different tensors:\n",
    "    - The sentence to translate\n",
    "    - The shifted-to-the-right translation\n",
    "    - The translation\n",
    "    \n",
    "The first two can be considered as the features, while the third one as the target. By doing this your model can perform Teacher Forcing as you saw in the lectures.\n",
    "\n",
    "Now it is time to begin coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74e5834b5acf8d",
   "metadata": {},
   "source": [
    "2. NMT model with attention\n",
    "\n",
    "The model you will build uses an encoder-decoder architecture. This Recurrent Neural Network (RNN) takes in a tokenized version of a sentence in its encoder, then passes it on to the decoder for translation. As mentioned in the lectures, just using a a regular sequence-to-sequence model with LSTMs will work effectively for short to medium sentences but will start to degrade for longer ones. You can picture it like the figure below where all of the context of the input sentence is compressed into one vector that is passed into the decoder block. You can see how this will be an issue for very long sentences (e.g. 100 tokens or more) because the context of the first parts of the input will have very little effect on the final vector passed to the decoder.\n",
    "\n",
    "<img src='pomocne_soubory/plain_rnn.png' width=\"600\">\n",
    "\n",
    "Adding an attention layer to this model avoids this problem by giving the decoder access to all parts of the input sentence. To illustrate, let's just use a 4-word input sentence as shown below. Remember that a hidden state is produced at each timestep of the encoder (represented by the orange rectangles). These are all passed to the attention layer and each are given a score given the current activation (i.e. hidden state) of the decoder. For instance, let's consider the figure below where the first prediction \"como\" is already made. To produce the next prediction, the attention layer will first receive all the encoder hidden states (i.e. orange rectangles) as well as the decoder hidden state when producing the word \"como\" (i.e. first green rectangle). Given this information, it will score each of the encoder hidden states to know which one the decoder should focus on to produce the next word. As a result of training, the model might have learned that it should align to the second encoder hidden state and subsequently assigns a high probability to the word \"voc\". If we are using greedy decoding, we will output the said word as the next symbol, then restart the process to produce the next word until we reach an end-of-sentence prediction.\n",
    "\n",
    "<img src='pomocne_soubory/attention_overview.png' width=\"600\">\n",
    "\n",
    "\n",
    "There are different ways to implement attention and the one we'll use for this assignment is the Scaled Dot Product Attention which has the form:\n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\n",
    "\n",
    "You will dive deeper into this equation in the next week but for now, you can think of it as computing scores using queries (Q) and keys (K), followed by a multiplication of values (V) to get a context vector at a particular timestep of the decoder. This context vector is fed to the decoder RNN to get a set of probabilities for the next predicted word. The division by square root of the keys dimensionality ($\\sqrt{d_k}$) is for improving model performance and you'll also learn more about it next week. For our machine translation application, the encoder activations (i.e. encoder hidden states) will be the keys and values, while the decoder activations (i.e. decoder hidden states) will be the queries.\n",
    "\n",
    "You will see in the upcoming sections that this complex architecture and mechanism can be implemented with just a few lines of code. \n",
    "\n",
    "First you will define two important global variables:\n",
    "\n",
    "- The size of the vocabulary\n",
    "- The number of units in the LSTM layers (the same number will be used for all LSTM layers)\n",
    "\n",
    "In this assignment, the vocabulary sizes for English and Portuguese are the same. Therefore, we use a single constant VOCAB_SIZE throughout the notebook. While in other settings, vocabulary sizes could differ, that is not the case in our assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d1a3b00bc54f486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:36.948324Z",
     "start_time": "2024-06-19T10:14:36.943886Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12000\n",
    "UNITS = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5edaab21fd710",
   "metadata": {},
   "source": [
    "Exercise 1 - Encoder\n",
    "\n",
    "Your first exercise is to code the encoder part of the neural network. For this, complete the `Encoder` class below. Notice that in the constructor (the `__init__` method) you need to define all of the sublayers of the encoder and then use these sublayers during the forward pass (the `call` method).\n",
    "\n",
    "The encoder consists of the following layers:\n",
    "\n",
    "- [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding). For this layer you need to define the appropriate `input_dim` and `output_dim` and let it know that you are using '0' as padding, which can be done by using the appropriate value for the `mask_zero` parameter.\n",
    "    \n",
    "+ [Bidirectional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional) [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM). In TF you can implement bidirectional behaviour for RNN-like layers. This part is already taken care of but you will need to specify the appropriate type of layer as well as its parameters. In particular you need to set the appropriate number of units and make sure that the LSTM returns the full sequence and not only the last output, which can be done by using the appropriate value for the `return_sequences` parameter.\n",
    "\n",
    "\n",
    "You need to define the forward pass using the syntax of TF's [functional API](https://www.tensorflow.org/guide/keras/functional_api). What this means is that you chain function calls together to define your network like this:\n",
    "\n",
    "```python\n",
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73b248263a82b17c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:37.718279Z",
     "start_time": "2024-06-19T10:14:37.714181Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(  \n",
    "            input_dim=vocab_size,\n",
    "            output_dim=units,\n",
    "            mask_zero=True\n",
    "        )  \n",
    "\n",
    "        self.rnn = tf.keras.layers.Bidirectional(  \n",
    "            merge_mode=\"sum\",  \n",
    "            layer=tf.keras.layers.LSTM(\n",
    "                units=units,\n",
    "                return_sequences=True\n",
    "            ),  \n",
    "        )  \n",
    "\n",
    "    def call(self, context):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (tf.Tensor): The sentence to translate\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Encoded sentence to translate\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass the context through the embedding layer\n",
    "        x = self.embedding(context)\n",
    "\n",
    "        # Pass the output of the embedding through the RNN\n",
    "        x = self.rnn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f5397cbda93e922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:39.363371Z",
     "start_time": "2024-06-19T10:14:38.624527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of sentences in english has shape: (64, 13)\n",
      "\n",
      "Encoder output has shape: (64, 13, 256)\n"
     ]
    }
   ],
   "source": [
    "# Do a quick check of your implementation\n",
    "\n",
    "# Create an instance of your class\n",
    "encoder = Encoder(VOCAB_SIZE, UNITS)\n",
    "\n",
    "# Pass a batch of sentences to translate from english to portuguese\n",
    "encoder_output = encoder(to_translate)\n",
    "\n",
    "print(f'Tensor of sentences in english has shape: {to_translate.shape}\\n')\n",
    "print(f'Encoder output has shape: {encoder_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad207e0c778ce12",
   "metadata": {},
   "source": [
    "Exercise 2 - CrossAttention\n",
    "\n",
    "Your next exercise is to code the layer that will perform cross attention between the original sentences and the translations. For this, complete the `CrossAttention` class below. Notice that in the constructor (the `__init__` method) you need to define all of the sublayers and then use these sublayers during the forward pass (the `call` method). For this particular case some of these bits are already taken care of.\n",
    "\n",
    "The cross attention consists of the following layers:\n",
    "\n",
    "- [MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention). For this layer you need to define the appropriate `key_dim`, which is the size of the key and query tensors. You will also need to set the number of heads to 1 since you aren't implementing multi head attention but attention between two tensors. The reason why this layer is preferred over [Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention) is that it allows simpler code during the forward pass.\n",
    "    \n",
    "A couple of things to notice:\n",
    "- You need a way to pass both the output of the attention alongside the shifted-to-the-right translation (since this cross attention happens in the decoder side). For this you will use an [Add](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add) layer so that the original dimension is preserved, which would not happen if you use something like a [Concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate) layer.\n",
    "\n",
    "+ Layer normalization is also performed for better stability of the network by using a [LayerNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization) layer.\n",
    "\n",
    "- You don't need to worry about these last steps as these are already solved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae9eeee5b599949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:42.552602Z",
     "start_time": "2024-06-19T10:14:42.540518Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = ( \n",
    "            tf.keras.layers.MultiHeadAttention(\n",
    "                key_dim=units,\n",
    "                num_heads=1\n",
    "            ) \n",
    "        )  \n",
    "\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, context, target):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (tf.Tensor): Encoded sentence to translate\n",
    "            target (tf.Tensor): The embedded shifted-to-the-right translation\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Cross attention between context and target\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the MH attention by passing in the query and value\n",
    "        # For this case the query should be the translation and the value the encoded sentence to translate\n",
    "        # Hint: Check the call arguments of MultiHeadAttention in the docs\n",
    "        attn_output = self.mha(\n",
    "            query=target,\n",
    "            value=context\n",
    "        )  \n",
    "\n",
    "        x = self.add([target, attn_output])\n",
    "\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fac4c07e050c98a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:43.796639Z",
     "start_time": "2024-06-19T10:14:43.433785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of contexts has shape: (64, 13, 256)\n",
      "Tensor of translations has shape: (64, 12, 256)\n",
      "Tensor of attention scores has shape: (64, 12, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Do a quick check of your implementation\n",
    "\n",
    "# Create an instance of your class\n",
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# The attention layer expects the embedded sr-translation and the context\n",
    "# The context (encoder_output) is already embedded so you need to do this for sr_translation:\n",
    "sr_translation_embed = tf.keras.layers.Embedding(VOCAB_SIZE, output_dim=UNITS, mask_zero=True)(sr_translation)\n",
    "\n",
    "# Compute the cross attention\n",
    "attention_result = attention_layer(encoder_output, sr_translation_embed)\n",
    "\n",
    "print(f'Tensor of contexts has shape: {encoder_output.shape}')\n",
    "print(f'Tensor of translations has shape: {sr_translation_embed.shape}')\n",
    "print(f'Tensor of attention scores has shape: {attention_result.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa503bc7be857ac0",
   "metadata": {},
   "source": [
    "Exercise 3 - Decoder\n",
    "\n",
    "\n",
    "Now you will implement the decoder part of the neural network by completing the `Decoder` class below. Notice that in the constructor (the `__init__` method) you need to define all of the sublayers of the decoder and then use these sublayers during the forward pass (the `call` method).\n",
    "\n",
    "The decoder consists of the following layers:\n",
    "\n",
    "- [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding). For this layer you need to define the appropriate `input_dim` and `output_dim` and let it know that you are using '0' as padding, which can be done by using the appropriate value for the `mask_zero` parameter.\n",
    "  \n",
    "  \n",
    "+ Pre-attention [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM). Unlike in the encoder in which you used a Bidirectional LSTM, here you will use a vanilla LSTM. Don't forget to set the appropriate number of units and make sure that the LSTM returns the full sequence and not only the last output, which can be done by using the appropriate value for the `return_sequences` parameter. It is very important that this layer returns the state since this will be needed for inference so make sure to set the `return_state` parameter accordingly. Notice that LSTM layers return state as a tuple of two tensors called `memory_state` and `carry_state`, **however these names have been changed to better reflect what you have seen in the lectures to `hidden_state` and `cell_state` respectively**.\n",
    "\n",
    "- The attention layer that performs cross attention between the sentence to translate and the right-shifted translation. Here you need to use the `CrossAttention` layer you defined in the previous exercise.\n",
    "\n",
    "+ Post-attention [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM). Another LSTM layer. For this one you don't need it to return the state.\n",
    "\n",
    "- Finally a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer. This one should have the same number of units as the size of the vocabulary since you expect it to compute the logits for every possible word in the vocabulary. Make sure to use a `logsoftmax` activation function for this one, which you can get as [tf.nn.log_softmax](https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e53d14b430c2f15e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:49.978756Z",
     "start_time": "2024-06-19T10:14:49.971344Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # The embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=units,\n",
    "            mask_zero=True\n",
    "        )  \n",
    "\n",
    "        # The RNN before attention\n",
    "        self.pre_attention_rnn = tf.keras.layers.LSTM(\n",
    "            units=units,\n",
    "            return_sequences=True,\n",
    "            return_state=True\n",
    "        )  \n",
    "\n",
    "        # The attention layer\n",
    "        self.attention = CrossAttention(units)\n",
    "\n",
    "        # The RNN after attention\n",
    "        self.post_attention_rnn = tf.keras.layers.LSTM(\n",
    "            units=units,\n",
    "            return_sequences=True\n",
    "        )  \n",
    "\n",
    "        # The dense layer with logsoftmax activation\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            units=vocab_size,\n",
    "            activation= tf.nn.log_softmax\n",
    "        )  \n",
    "\n",
    "    def call(self, context, target, state=None, return_state=False):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            context (tf.Tensor): Encoded sentence to translate\n",
    "            target (tf.Tensor): The shifted-to-the-right translation\n",
    "            state (list[tf.Tensor, tf.Tensor], optional): Hidden state of the pre-attention LSTM. Defaults to None.\n",
    "            return_state (bool, optional): If set to true return the hidden states of the LSTM. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The log_softmax probabilities of predicting a particular token\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the embedding of the input\n",
    "        x = self.embedding(target)\n",
    "\n",
    "        # Pass the embedded input into the pre attention LSTM\n",
    "        # Hints:\n",
    "        # - The LSTM you defined earlier should return the output alongside the state (made up of two tensors)\n",
    "        # - Pass in the state to the LSTM (needed for inference)\n",
    "        x, hidden_state, cell_state = self.pre_attention_rnn(x, initial_state=state)\n",
    "\n",
    "        # Perform cross attention between the context and the output of the LSTM (in that order)\n",
    "        x = self.attention(context, x)\n",
    "\n",
    "        # Do a pass through the post attention LSTM\n",
    "        x = self.post_attention_rnn(x)\n",
    "\n",
    "        # Compute the logits\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        if return_state:\n",
    "            return logits, [hidden_state, cell_state]\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f15a76c82f56849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:50.924053Z",
     "start_time": "2024-06-19T10:14:50.504807Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention_1' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of contexts has shape: (64, 13, 256)\n",
      "Tensor of right-shifted translations has shape: (64, 12)\n",
      "Tensor of logits has shape: (64, 12, 12000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'decoder' (of type Decoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Do a quick check of your implementation\n",
    "\n",
    "# Create an instance of your class\n",
    "decoder = Decoder(VOCAB_SIZE, UNITS)\n",
    "\n",
    "# Notice that you don't need the embedded version of sr_translation since this is done inside the class\n",
    "logits = decoder(encoder_output, sr_translation)\n",
    "\n",
    "print(f'Tensor of contexts has shape: {encoder_output.shape}')\n",
    "print(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\n",
    "print(f'Tensor of logits has shape: {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2bdc72535422b",
   "metadata": {},
   "source": [
    "Exercise 4 - Translator\n",
    "\n",
    "Now you have to put together all of the layers you previously coded into an actual model. For this, complete the `Translator` class below. Notice how unlike the Encoder and Decoder classes inherited from `tf.keras.layers.Layer`, the Translator class inherits from `tf.keras.Model`.\n",
    "\n",
    "Remember that `train_data` will yield a tuple with the sentence to translate and the shifted-to-the-right translation, which are the \"features\" of the model. This means that the inputs of your network will be tuples containing context and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d4933d96a65967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:54.420808Z",
     "start_time": "2024-06-19T10:14:54.407163Z"
    }
   },
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        \"\"\"Initializes an instance of this class\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            units (int): Number of units in the LSTM layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the encoder with the appropriate vocab_size and number of units\n",
    "        self.encoder = Encoder(vocab_size, units)\n",
    "\n",
    "        # Define the decoder with the appropriate vocab_size and number of units\n",
    "        self.decoder = Decoder(vocab_size, units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass of this layer\n",
    "\n",
    "        Args:\n",
    "            inputs (tuple(tf.Tensor, tf.Tensor)): Tuple containing the context (sentence to translate) and the target (shifted-to-the-right translation)\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The log_softmax probabilities of predicting a particular token\n",
    "        \"\"\"\n",
    "\n",
    "        # In this case inputs is a tuple consisting of the context and the target, unpack it into single variables\n",
    "        context, target = inputs[0], inputs[1]\n",
    "\n",
    "        # Pass the context through the encoder\n",
    "        encoded_context = self.encoder(context)\n",
    "\n",
    "        # Compute the logits by passing the encoded context and the target to the decoder\n",
    "        logits = self.decoder(encoded_context, target)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e1b7d1e1a3d2062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:55.639484Z",
     "start_time": "2024-06-19T10:14:54.987875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention_2' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'decoder_1' (of type Decoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of sentences to translate has shape: (64, 13)\n",
      "Tensor of right-shifted translations has shape: (64, 12)\n",
      "Tensor of logits has shape: (64, 12, 12000)\n"
     ]
    }
   ],
   "source": [
    "# Do a quick check of your implementation\n",
    "\n",
    "# Create an instance of your class\n",
    "translator = Translator(VOCAB_SIZE, UNITS)\n",
    "\n",
    "# Compute the logits for every word in the vocabulary\n",
    "logits = translator((to_translate, sr_translation))\n",
    "\n",
    "print(f'Tensor of sentences to translate has shape: {to_translate.shape}')\n",
    "print(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\n",
    "print(f'Tensor of logits has shape: {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e586dd9a8fe27e4",
   "metadata": {},
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47148bc913162e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:58.419141Z",
     "start_time": "2024-06-19T10:14:58.408253Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, epochs=1, steps_per_epoch=500):\n",
    "    model.compile(optimizer=\"adam\", loss=masked_loss, metrics=[masked_acc, masked_loss])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data.repeat(),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=50,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)],\n",
    "    )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cee67fc1edcc8067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:14:58.868885Z",
     "start_time": "2024-06-19T10:14:58.861835Z"
    }
   },
   "outputs": [],
   "source": [
    "# epochs=1\n",
    "# steps_per_epoch=500\n",
    "# translator.compile(optimizer=\"adam\", loss=masked_loss, metrics=[masked_acc, masked_loss])\n",
    "\n",
    "# history = translator.fit(\n",
    "#     train_data.repeat(),\n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_data=val_data,\n",
    "#     validation_steps=50,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fecc068591278bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:16.252702Z",
     "start_time": "2024-06-19T10:15:00.131874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 495ms/step - loss: 5.8206 - masked_acc: 0.1513 - masked_loss: 5.8206 - val_loss: 4.3815 - val_masked_acc: 0.3321 - val_masked_loss: 4.3815\n"
     ]
    }
   ],
   "source": [
    "# Train the translator (this takes some minutes so feel free to take a break)\n",
    "\n",
    "trained_translator, history = compile_and_train(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cad0b5a720705f",
   "metadata": {},
   "source": [
    "4. Using the model for inference \n",
    "\n",
    "\n",
    "Now that your model is trained you can use it for inference. To help you with this the `generate_next_token` function is provided. Notice that this function is meant to be used inside a for-loop, so you feed to it the information of the previous step to generate the information of the next step. In particular you need to keep track of the state of the pre-attention LSTM in the decoder and if you are done with the translation. Also notice that a `temperature` variable is introduced which determines how to select the next token given the predicted logits:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df5c3207517b7bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:20.226300Z",
     "start_time": "2024-06-19T10:19:20.209367Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_next_token(decoder, context, next_token, done, state, temperature=0.0):\n",
    "    \"\"\"Generates the next token in the sequence\n",
    "\n",
    "    Args:\n",
    "        decoder (Decoder): The decoder\n",
    "        context (tf.Tensor): Encoded sentence to translate\n",
    "        next_token (tf.Tensor): The predicted next token\n",
    "        done (bool): True if the translation is complete\n",
    "        state (list[tf.Tensor, tf.Tensor]): Hidden states of the pre-attention LSTM layer\n",
    "        temperature (float, optional): The temperature that controls the randomness of the predicted tokens. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple(tf.Tensor, np.float, list[tf.Tensor, tf.Tensor], bool): The next token, log prob of said token, hidden state of LSTM and if translation is done\n",
    "    \"\"\"\n",
    "    # Get the logits and state from the decoder\n",
    "    logits, state = decoder(context, next_token, state=state, return_state=True)\n",
    "    \n",
    "    # Trim the intermediate dimension \n",
    "    logits = logits[:, -1, :]\n",
    "        \n",
    "    # If temp is 0 then next_token is the argmax of logits\n",
    "    if temperature == 0.0:\n",
    "        next_token = tf.argmax(logits, axis=-1)\n",
    "        \n",
    "    # If temp is not 0 then next_token is sampled out of logits\n",
    "    else:\n",
    "        logits = logits / temperature\n",
    "        next_token = tf.random.categorical(logits, num_samples=1)\n",
    "    \n",
    "    # Trim dimensions of size 1\n",
    "    logits = tf.squeeze(logits)\n",
    "    next_token = tf.squeeze(next_token)\n",
    "    \n",
    "    # Get the logit of the selected next_token\n",
    "    logit = logits[next_token].numpy()\n",
    "    \n",
    "    # Reshape to (1,1) since this is the expected shape for text encoded as TF tensors\n",
    "    next_token = tf.reshape(next_token, shape=(1,1))\n",
    "    \n",
    "    # If next_token is End-of-Sentence token you are done\n",
    "    if next_token == eos_id:\n",
    "        done = True\n",
    "    \n",
    "    return next_token, logit, state, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ae846fb44a51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:26.821839Z",
     "start_time": "2024-06-19T10:19:21.329612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token: [[396]]\n",
      "Logit: -18.8035\n",
      "Done? False\n"
     ]
    }
   ],
   "source": [
    "# PROCESS SENTENCE TO TRANSLATE AND ENCODE\n",
    "\n",
    "# A sentence you wish to translate\n",
    "eng_sentence = \"I love languages\"\n",
    "\n",
    "# Convert it to a tensor\n",
    "texts = tf.convert_to_tensor(eng_sentence)[tf.newaxis]\n",
    "\n",
    "# Vectorize it and pass it through the encoder\n",
    "context = english_vectorizer(texts).to_tensor()\n",
    "context = encoder(context)\n",
    "\n",
    "# SET STATE OF THE DECODER\n",
    "\n",
    "# Next token is Start-of-Sentence since you are starting fresh\n",
    "next_token = tf.fill((1,1), sos_id)\n",
    "\n",
    "# Hidden and Cell states of the LSTM can be mocked using uniform samples\n",
    "state = [tf.random.uniform((1, UNITS)), tf.random.uniform((1, UNITS))]\n",
    "\n",
    "# You are not done until next token is EOS token\n",
    "done = False\n",
    "\n",
    "# Generate next token\n",
    "next_token, logit, state, done = generate_next_token(decoder, context, next_token, done, state, temperature=0.5)\n",
    "print(f\"Next token: {next_token}\\nLogit: {logit:.4f}\\nDone? {done}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94487387bffc8406",
   "metadata": {},
   "source": [
    "Exercise 5 - translate\n",
    "\n",
    "Now you can put everything together to translate a given sentence. For this, complete the `translate` function below. This function will take care of the following steps: \n",
    "- Process the sentence to translate and encode it\n",
    "\n",
    "+ Set the initial state of the decoder\n",
    "\n",
    "- Get predictions of the next token (starting with the \\<SOS> token) for a maximum of iterations (in case the \\<EOS> token is never returned)\n",
    "    \n",
    "+ Return the translated text (as a string), the logit of the last iteration (this helps measure how certain was that the sequence was translated in its totality) and the translation in token format.\n",
    "\n",
    "\n",
    "Hints: \n",
    "\n",
    "- The previous cell provides a lot of insights on how this function should work, so if you get stuck refer to it.\n",
    "\n",
    "+ Some useful docs:\n",
    "    + [tf.newaxis](https://www.tensorflow.org/api_docs/python/tf#newaxis)\n",
    "\n",
    "    - [tf.fill](https://www.tensorflow.org/api_docs/python/tf/fill)\n",
    "\n",
    "    + [tf.zeros](https://www.tensorflow.org/api_docs/python/tf/zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75613272788353ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:26.842056Z",
     "start_time": "2024-06-19T10:19:26.833219Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(model, text, max_length=50, temperature=0.0):\n",
    "    \"\"\"Translate a given sentence from English to Portuguese\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained translator\n",
    "        text (string): The sentence to translate\n",
    "        max_length (int, optional): The maximum length of the translation. Defaults to 50.\n",
    "        temperature (float, optional): The temperature that controls the randomness of the predicted tokens. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, np.float, tf.Tensor): The translation, logit that predicted <EOS> token and the tokenized translation\n",
    "    \"\"\"\n",
    "    # Lists to save tokens and logits\n",
    "    tokens, logits = [], []\n",
    "\n",
    "    # PROCESS THE SENTENCE TO TRANSLATE\n",
    "    \n",
    "    # Convert the original string into a tensor\n",
    "    text = tf.convert_to_tensor(text)[tf.newaxis]\n",
    "    \n",
    "    # Vectorize the text using the correct vectorizer\n",
    "    context = english_vectorizer(text).to_tensor()\n",
    "    \n",
    "    # Get the encoded context (pass the context through the encoder)\n",
    "    # Hint: Remember you can get the encoder by using model.encoder\n",
    "    context = model.encoder(context)\n",
    "    \n",
    "    # INITIAL STATE OF THE DECODER\n",
    "    \n",
    "    # First token should be SOS token with shape (1,1)\n",
    "    next_token = tf.fill((1,1), sos_id)\n",
    "    \n",
    "    # Initial hidden and cell states should be tensors of zeros with shape (1, UNITS)\n",
    "    state = [tf.zeros((1, UNITS)), tf.zeros((1, UNITS))]\n",
    "    \n",
    "    # You are done when you draw a EOS token as next token (initial state is False)\n",
    "    done = False\n",
    "\n",
    "    # Iterate for max_length iterations\n",
    "    for i in range(max_length):\n",
    "        # Generate the next token\n",
    "        try:\n",
    "            next_token, logit, state, done = generate_next_token(\n",
    "                decoder=model.decoder,\n",
    "                context=context,\n",
    "                next_token=next_token,\n",
    "                done=done,\n",
    "                state=state,\n",
    "                temperature=temperature\n",
    "            )\n",
    "        except:\n",
    "             raise Exception(\"Problem generating the next token\")\n",
    "        \n",
    "        # If done then break out of the loop\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        # Add next_token to the list of tokens\n",
    "        tokens.append(next_token)\n",
    "        \n",
    "        # Add logit to the list of logits\n",
    "        logits.append(logit)\n",
    "\n",
    "    # Concatenate all tokens into a tensor\n",
    "    tokens = tf.concat(tokens, axis=-1)\n",
    "    \n",
    "    # Convert the translated tokens into text\n",
    "    translation = tf.squeeze(tokens_to_text(tokens, id_to_word))\n",
    "    translation = translation.numpy().decode()\n",
    "    \n",
    "    return translation, logits[-1], tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fbecdeb8d4a68c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:27.256031Z",
     "start_time": "2024-06-19T10:19:26.843001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.0\n",
      "\n",
      "Original sentence: I love languages\n",
      "Translation: eu tom .\n",
      "Translation tokens:[[9 5 4]]\n",
      "Logit: -1.761\n"
     ]
    }
   ],
   "source": [
    "# Running this cell multiple times should return the same output since temp is 0\n",
    "\n",
    "temp = 0.0 \n",
    "original_sentence = \"I love languages\"\n",
    "\n",
    "translation, logit, tokens = translate(trained_translator, original_sentence, temperature=temp)\n",
    "\n",
    "print(f\"Temperature: {temp}\\n\\nOriginal sentence: {original_sentence}\\nTranslation: {translation}\\nTranslation tokens:{tokens}\\nLogit: {logit:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "738af0496a77580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:35.510561Z",
     "start_time": "2024-06-19T10:19:35.091823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.7\n",
      "\n",
      "Original sentence: I love languages\n",
      "Translation: tom a ponto .\n",
      "Translation tokens:[[  5  12 751   4]]\n",
      "Logit: -1.191\n"
     ]
    }
   ],
   "source": [
    "# Running this cell multiple times should return different outputs since temp is not 0\n",
    "# You can try different temperatures\n",
    "\n",
    "temp = 0.7\n",
    "original_sentence = \"I love languages\"\n",
    "\n",
    "translation, logit, tokens = translate(trained_translator, original_sentence, temperature=temp)\n",
    "\n",
    "print(f\"Temperature: {temp}\\n\\nOriginal sentence: {original_sentence}\\nTranslation: {translation}\\nTranslation tokens:{tokens}\\nLogit: {logit:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954c4edeb4a1688",
   "metadata": {},
   "source": [
    "5. Minimum Bayes-Risk Decoding\n",
    "\n",
    "As mentioned in the lectures, getting the most probable token at each step may not necessarily produce the best results. Another approach is to do Minimum Bayes Risk Decoding or MBR. The general steps to implement this are:\n",
    "\n",
    "- Take several random samples\n",
    "+ Score each sample against all other samples\n",
    "- Select the one with the highest score\n",
    "\n",
    "You will be building helper functions for these steps in the following sections.\n",
    "\n",
    "With the ability to generate different translations by setting different temperature values you can do what you saw in the lectures and generate a bunch of translations and then determine which one is the best candidate. You will now do this by using the provided `generate_samples` function. This function will return any desired number of candidate translations alongside the log-probability for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71797bb625911fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:39.011071Z",
     "start_time": "2024-06-19T10:19:38.999972Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_samples(model, text, n_samples=4, temperature=0.6):\n",
    "    \n",
    "    samples, log_probs = [], []\n",
    "\n",
    "    # Iterate for n_samples iterations\n",
    "    for _ in range(n_samples):\n",
    "        \n",
    "        # Save the logit and the translated tensor\n",
    "        _, logp, sample = translate(model, text, temperature=temperature)\n",
    "        \n",
    "        # Save the translated tensors\n",
    "        samples.append(np.squeeze(sample.numpy()).tolist())\n",
    "        \n",
    "        # Save the logits\n",
    "        log_probs.append(logp)\n",
    "                \n",
    "    return samples, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d0b9674cfd0d42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:41.782602Z",
     "start_time": "2024-06-19T10:19:40.280072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated tensor: [9, 5, 4] has logit: -2.935\n",
      "Translated tensor: [9, 5, 4] has logit: -2.935\n",
      "Translated tensor: [9, 5, 4] has logit: -2.935\n",
      "Translated tensor: [9, 9, 14, 22, 198, 4] has logit: -1.717\n"
     ]
    }
   ],
   "source": [
    "samples, log_probs = generate_samples(trained_translator, 'I love languages')\n",
    "\n",
    "for s, l in zip(samples, log_probs):\n",
    "    print(f\"Translated tensor: {s} has logit: {l:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3044fb49549a45",
   "metadata": {},
   "source": [
    "Comparing overlaps\n",
    "\n",
    "Now that you can generate multiple translations it is time to come up with a method to measure the goodness of each one. As you saw in the lectures, one way to achieve this is by comparing each sample against the others. \n",
    "\n",
    "There are several metrics you can use for this purpose, as shown in the lectures and you can try experimenting with any one of these. For this assignment, you will be calculating scores for **unigram overlaps**. \n",
    "\n",
    "One of these metrics is the widely used yet simple [Jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index) which gets the intersection over union of two sets. The `jaccard_similarity` function returns this metric for any pair of candidate and reference translations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd77b2570f9afb04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:43.399208Z",
     "start_time": "2024-06-19T10:19:43.393862Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(candidate, reference):\n",
    "        \n",
    "    # Convert the lists to sets to get the unique tokens\n",
    "    candidate_set = set(candidate)\n",
    "    reference_set = set(reference)\n",
    "    \n",
    "    # Get the set of tokens common to both candidate and reference\n",
    "    common_tokens = candidate_set.intersection(reference_set)\n",
    "    \n",
    "    # Get the set of all tokens found in either candidate or reference\n",
    "    all_tokens = candidate_set.union(reference_set)\n",
    "    \n",
    "    # Compute the percentage of overlap (divide the number of common tokens by the number of all tokens)\n",
    "    overlap = len(common_tokens) / len(all_tokens)\n",
    "        \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df780edeafc9e90b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:43.666634Z",
     "start_time": "2024-06-19T10:19:43.663083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard similarity between lists: [1, 2, 3] and [1, 2, 3, 4] is 0.750\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [1, 2, 3, 4]\n",
    "\n",
    "js = jaccard_similarity(l1, l2)\n",
    "\n",
    "print(f\"jaccard similarity between lists: {l1} and {l2} is {js:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7e4716f74323b",
   "metadata": {},
   "source": [
    "Exercise 6 - rouge1_similarity\n",
    "\n",
    "Jaccard similarity is good but a more commonly used metric in machine translation is the ROUGE score. For unigrams, this is called ROUGE-1 and as shown in the lectures, you can output the scores for both precision and recall when comparing two samples. To get the final score, you will want to compute the F1-score as given by:\n",
    "\n",
    "$$score = 2* \\frac{(precision * recall)}{(precision + recall)}$$\n",
    "\n",
    "For the implementation of the `rouge1_similarity` function you want to use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) class from the Python standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c91873699252bd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:45.340717Z",
     "start_time": "2024-06-19T10:19:45.333022Z"
    }
   },
   "outputs": [],
   "source": [
    "def rouge1_similarity(candidate, reference):\n",
    "    \"\"\"Computes the ROUGE 1 score between two token lists\n",
    "\n",
    "    Args:\n",
    "        candidate (list[int]): Tokenized candidate translation\n",
    "        reference (list[int]): Tokenized reference translation\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap between the two token lists\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a frequency table of the candidate and reference tokens\n",
    "    # Hint: use the Counter class (already imported)\n",
    "    candidate_word_counts = Counter(candidate)\n",
    "    reference_word_counts = Counter(reference)\n",
    "    \n",
    "    # Initialize overlap at 0\n",
    "    overlap = 0\n",
    "    \n",
    "    # Iterate over the tokens in the candidate frequency table\n",
    "    # Hint: Counter is a subclass of dict and you can get the keys \n",
    "    #       out of a dict using the keys method like this: dict.keys()\n",
    "    for token in candidate_word_counts.keys():\n",
    "        \n",
    "        # Get the count of the current token in the candidate frequency table\n",
    "        # Hint: You can access the counts of a token as you would access values of a dictionary\n",
    "        token_count_candidate = candidate_word_counts[token]\n",
    "        \n",
    "        # Get the count of the current token in the reference frequency table\n",
    "        # Hint: You can access the counts of a token as you would access values of a dictionary\n",
    "        token_count_reference = reference_word_counts[token]\n",
    "        \n",
    "        # Update the overlap by getting the minimum between the two token counts above\n",
    "        overlap += min([token_count_candidate, token_count_reference])\n",
    "    \n",
    "    # Compute the precision\n",
    "    # Hint: precision = overlap / (number of tokens in candidate list) \n",
    "    precision = overlap / len(candidate)\n",
    "    \n",
    "    # Compute the recall\n",
    "    # Hint: recall = overlap / (number of tokens in reference list) \n",
    "    recall = overlap / len(reference)\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "        # Compute the Rouge1 Score\n",
    "        # Hint: This is equivalent to the F1 score\n",
    "        f1_score = 2.0 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        return f1_score\n",
    "\n",
    "    return 0 # If precision + recall = 0 then return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d047b85ab66b040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:46.085952Z",
     "start_time": "2024-06-19T10:19:46.082445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 1 similarity between lists: [1, 2, 3] and [1, 2, 3, 4] is 0.857\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [1, 2, 3, 4]\n",
    "\n",
    "r1s = rouge1_similarity(l1, l2)\n",
    "\n",
    "print(f\"rouge 1 similarity between lists: {l1} and {l2} is {r1s:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb0b71c408e3e2",
   "metadata": {},
   "source": [
    "Computing the Overall Score\n",
    "\n",
    "\n",
    "You will now build a function to generate the overall score for a particular sample. As mentioned in the lectures, you need to compare each sample with all other samples. For instance, if we generated 30 sentences, we will need to compare sentence 1 to sentences 2 through 30. Then, we compare sentence 2 to sentences 1 and 3 through 30, and so forth. At each step, we get the average score of all comparisons to get the overall score for a particular sample. To illustrate, these will be the steps to generate the scores of a 4-sample list.\n",
    "\n",
    "- Get similarity score between sample 1 and sample 2\n",
    "+ Get similarity score between sample 1 and sample 3\n",
    "- Get similarity score between sample 1 and sample 4\n",
    "+ Get average score of the first 3 steps. This will be the overall score of sample 1\n",
    "- Iterate and repeat until samples 1 to 4 have overall scores.\n",
    "\n",
    "\n",
    "The results will be stored in a dictionary for easy lookups.\n",
    "\n",
    "Exercise 7 - average_overlap\n",
    "\n",
    "Complete the `average_overlap` function below which should implement the process described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfd6bf8b02d2b08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:49.414088Z",
     "start_time": "2024-06-19T10:19:49.406536Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_overlap(samples, similarity_fn):\n",
    "    \"\"\"Computes the arithmetic mean of each candidate sentence in the samples\n",
    "\n",
    "    Args:\n",
    "        samples (list[list[int]]): Tokenized version of translated sentences\n",
    "        similarity_fn (Function): Similarity function used to compute the overlap\n",
    "\n",
    "    Returns:\n",
    "        dict[int, float]: A dictionary mapping the index of each translation to its score\n",
    "    \"\"\"\n",
    "    # Initialize dictionary\n",
    "    scores = {}\n",
    "    \n",
    "    # Iterate through all samples (enumerate helps keep track of indexes)\n",
    "    for index_candidate, candidate in enumerate(samples):    \n",
    "     \n",
    "        # Initially overlap is zero\n",
    "        overlap = 0\n",
    "        \n",
    "        # Iterate through all samples (enumerate helps keep track of indexes)\n",
    "        for index_sample, sample in enumerate(samples):\n",
    "\n",
    "            # Skip if the candidate index is the same as the sample index\n",
    "            if index_candidate == index_sample:\n",
    "                continue\n",
    "                \n",
    "            # Get the overlap between candidate and sample using the similarity function\n",
    "            sample_overlap = similarity_fn(candidate, sample)\n",
    "            \n",
    "            # Add the sample overlap to the total overlap\n",
    "            overlap += sample_overlap\n",
    "\n",
    "        # Get the score for the candidate by computing the average\n",
    "        score = overlap / (len(samples) - 1)\n",
    "\n",
    "        # Only use 3 decimal points\n",
    "        score = round(score, 3)\n",
    "        \n",
    "        # Save the score in the dictionary. use index as the key.\n",
    "        scores[index_candidate] = score\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4aabecffb3807feb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:50.979683Z",
     "start_time": "2024-06-19T10:19:50.974660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average overlap between lists: [1, 2, 3], [1, 2, 4] and [1, 2, 4, 5] using Jaccard similarity is:\n",
      "\n",
      "{0: 0.45, 1: 0.625, 2: 0.575}\n"
     ]
    }
   ],
   "source": [
    "# Test with Jaccard similarity\n",
    "\n",
    "l1 = [1, 2, 3]\n",
    "l2 = [1, 2, 4]\n",
    "l3 = [1, 2, 4, 5]\n",
    "\n",
    "avg_ovlp = average_overlap([l1, l2, l3], jaccard_similarity)\n",
    "\n",
    "print(f\"average overlap between lists: {l1}, {l2} and {l3} using Jaccard similarity is:\\n\\n{avg_ovlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "201bd1991a493ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:52.844791Z",
     "start_time": "2024-06-19T10:19:52.838862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average overlap between lists: [1, 2, 3], [1, 4], [1, 2, 4, 5] and [5, 6] using Rouge1 similarity is:\n",
      "\n",
      "{0: 0.324, 1: 0.356, 2: 0.524, 3: 0.111}\n"
     ]
    }
   ],
   "source": [
    "# Test with Rouge1 similarity\n",
    "\n",
    "l1 = [1, 2, 3]\n",
    "l2 = [1, 4]\n",
    "l3 = [1, 2, 4, 5]\n",
    "l4 = [5,6]\n",
    "\n",
    "avg_ovlp = average_overlap([l1, l2, l3, l4], rouge1_similarity)\n",
    "\n",
    "print(f\"average overlap between lists: {l1}, {l2}, {l3} and {l4} using Rouge1 similarity is:\\n\\n{avg_ovlp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceafdfa9aa06b4d",
   "metadata": {},
   "source": [
    "In practice, it is also common to see the weighted mean being used to calculate the overall score instead of just the arithmetic mean. This is implemented in the `weighted_avg_overlap` function below and you can use it in your experiments to see which one will give better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff692e428ba69996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:55.612127Z",
     "start_time": "2024-06-19T10:19:55.601240Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_avg_overlap(samples, log_probs, similarity_fn):\n",
    "    \n",
    "    # Scores dictionary\n",
    "    scores = {}\n",
    "    \n",
    "    # Iterate over the samples\n",
    "    for index_candidate, candidate in enumerate(samples):    \n",
    "        \n",
    "        # Initialize overlap and weighted sum\n",
    "        overlap, weight_sum = 0.0, 0.0\n",
    "        \n",
    "        # Iterate over all samples and log probabilities\n",
    "        for index_sample, (sample, logp) in enumerate(zip(samples, log_probs)):\n",
    "\n",
    "            # Skip if the candidate index is the same as the sample index            \n",
    "            if index_candidate == index_sample:\n",
    "                continue\n",
    "                \n",
    "            # Convert log probability to linear scale\n",
    "            sample_p = float(np.exp(logp))\n",
    "\n",
    "            # Update the weighted sum\n",
    "            weight_sum += sample_p\n",
    "\n",
    "            # Get the unigram overlap between candidate and sample\n",
    "            sample_overlap = similarity_fn(candidate, sample)\n",
    "            \n",
    "            # Update the overlap\n",
    "            overlap += sample_p * sample_overlap\n",
    "            \n",
    "        # Compute the score for the candidate\n",
    "        score = overlap / weight_sum\n",
    "\n",
    "        # Only use 3 decimal points\n",
    "        score = round(score, 3)\n",
    "        \n",
    "        # Save the score in the dictionary. use index as the key.\n",
    "        scores[index_candidate] = score\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cef96d5d12cb73b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:56.296566Z",
     "start_time": "2024-06-19T10:19:56.291309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted average overlap using Jaccard similarity is:\n",
      "\n",
      "{0: 0.443, 1: 0.631, 2: 0.558}\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [1, 2, 4]\n",
    "l3 = [1, 2, 4, 5]\n",
    "log_probs = [0.4, 0.2, 0.5]\n",
    "\n",
    "w_avg_ovlp = weighted_avg_overlap([l1, l2, l3], log_probs, jaccard_similarity)\n",
    "\n",
    "print(f\"weighted average overlap using Jaccard similarity is:\\n\\n{w_avg_ovlp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f5487245ef1a5",
   "metadata": {},
   "source": [
    "mbr_decode\n",
    "\n",
    "You will now put everything together in the the `mbr_decode` function below. This final step is not graded as this function is just a wrapper around all the cool stuff you have coded so far! \n",
    "\n",
    "You can use it to play around, trying different numbers of samples, temperatures and similarity functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5aeb4f1be087b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:19:59.008302Z",
     "start_time": "2024-06-19T10:19:58.988401Z"
    }
   },
   "outputs": [],
   "source": [
    "def mbr_decode(model, text, n_samples=5, temperature=0.6, similarity_fn=jaccard_similarity):\n",
    "    \n",
    "    # Generate samples\n",
    "    samples, log_probs = generate_samples(model, text, n_samples=n_samples, temperature=temperature)\n",
    "    \n",
    "    # Compute the overlap scores\n",
    "    scores = weighted_avg_overlap(samples, log_probs, similarity_fn)\n",
    "\n",
    "    # Decode samples\n",
    "    decoded_translations = [tokens_to_text(s, id_to_word).numpy().decode('utf-8') for s in samples]\n",
    "    \n",
    "    # Find the key with the highest score\n",
    "    max_score_key = max(scores, key=lambda k: scores[k])\n",
    "    \n",
    "    # Get the translation \n",
    "    translation = decoded_translations[max_score_key]\n",
    "    \n",
    "    return translation, decoded_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72cfd67e8b32a5d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:01.750503Z",
     "start_time": "2024-06-19T10:19:59.696721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation candidates:\n",
      "eu eu eu tom .\n",
      "eu tom .\n",
      "voce eu tom sao miope .\n",
      "eu tom .\n",
      "eu tom [UNK] .\n",
      "eu eu tom .\n",
      "tom tom .\n",
      "eu tom .\n",
      "eu tom .\n",
      "eu tom .\n",
      "\n",
      "Selected translation: eu tom .\n"
     ]
    }
   ],
   "source": [
    "english_sentence = \"I love languages\"\n",
    "\n",
    "translation, candidates = mbr_decode(trained_translator, english_sentence, n_samples=10, temperature=0.6)\n",
    "\n",
    "print(\"Translation candidates:\")\n",
    "for c in candidates:\n",
    "    print(c)\n",
    "\n",
    "print(f\"\\nSelected translation: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43aef3f082795",
   "metadata": {},
   "source": [
    "# 2 Text Summarizaion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1737de1-fadd-4b6f-ab13-703409f570f8",
   "metadata": {},
   "source": [
    "Jeden z prvnich modelu s attention mechanismem byla zaroven convolucni sit. Nicmene se ukazalo, ze bez convolucni vrsty se model trenuje rychleji a ma lepsi vysledky. Taky proto se ten prelomov paper jmenuje \"Attention is all you need\". Taky uvedla \"na trh\" transformer architekturu. Od te doby se vicemene architektura nemeni, jen se pridavaji dimenze a/nebo pocty encoderu a/nebo pocety decoderu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee585c1e-f9f6-4786-82cd-a85a2799d0c9",
   "metadata": {},
   "source": [
    "Klasicky RNN, stejne jako model vyse, ma tu nevyhodu, ze kazda dalsi bunka ceka na vysledek predchoziho vypoctu. I kdyz attention mechanismus popsany vyse umoznil zamerit se na dilci casti textu a trochu tim vyresil problemy s vanishing gradient nebo ztratou informace napric dlouhou vetou, stale ji tim nevyresil uplne. A tak vznika Transformer. Sit, ktera neobsahuje zadny prvky RNN, a vypocet lze provest maticove v jednom vypoctu. Stejne tak napocet gradientu je opet jen soucin matic a je tak rychly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d15b5-6e7c-4bb0-a320-0f3adf9d92cb",
   "metadata": {},
   "source": [
    "Nekolik vyznamnych transformer modelu je: Bert, T5, GPT-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba4f1bb6c76de4",
   "metadata": {},
   "source": [
    "Naprosto skvely clanek, kde je dobre a nazorne vysvetlen princip Transformeru je zde: \n",
    "http://jalammar.github.io/illustrated-transformer/. Ted jen ve zkratce:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a84ed423d560af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attention mechanismus graficke vysvetleni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc05e81-bb26-4200-89f5-45a2bf1edb3d",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/The_transformer_encoders_decoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12261fd0c5beba4",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/The_transformer_encoder_decoder_stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2608371b8ec6f29",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/Transformer_encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fdd07bc3c2e69",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/Transformer_decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157241a02dbdbb74",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/embeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c15343df0351c",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/encoder_with_tensors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a462db1909902",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/encoder_with_tensors_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3c651fd0ca0fc",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_self_attention_vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f720485907e425d",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_self_attention_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c285904f9076d",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/self-attention_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6d26cbaf327b4",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/self-attention-output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f104c1c773f5d",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/self-attention-matrix-calculation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd6d5f12ec27b6",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/self-attention-matrix-calculation-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859816d3097297d",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_attention_heads_qkv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c0407f1b06fb3",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_attention_heads_z.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5197df4aa7acc0",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_attention_heads_weight_matrix_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9bbbf686be017",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_multi-headed_self-attention-recap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddaaa30a597977",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_positional_encoding_vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca8d3482eb3f91",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_positional_encoding_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54c3bd413ff638",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/attention-is-all-you-need-positional-encoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb07843b2ee60d8",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_resideual_layer_norm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9c3a1cccdf3f8",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_resideual_layer_norm_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460623f6647fa4c7",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_resideual_layer_norm_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f91e56b5f9556",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_decoding_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b0fd4cabffb53",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_decoding_2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9269b92b218d8ab",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/transformer_decoder_output_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da418438adbc5d",
   "metadata": {},
   "source": [
    "A kde vsude se takovy transformer pouziva?\n",
    "- sumarizace textu\n",
    "- autocomplete\n",
    "- NER\n",
    "- Q&A\n",
    "- ...\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741bd639dc32d4a",
   "metadata": {},
   "source": [
    "Spousta modelu je tzv. instructed. Tj. ze existuje prompt, ktery se zada jako klicove slovo a model na nej odpovi. T5 je jeden z techto modelu.\n",
    "\n",
    "![transformer](../transfomer_soubory/t5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9becca9e4c2579",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dacf5d324286ba",
   "metadata": {},
   "source": [
    "Encoder-Decoder Attention - query je z predchoziho stavu decoderu a key a value jsou z encoderu. Tento typ attention \n",
    "se pouziva v decoderu\n",
    "\n",
    "Self-Attention - query, key a value jsou z jednoho zdroje. Tento typ attention se pouziva v encoderu\n",
    "\n",
    "Masked Self-Attention - pouziva se v decoderu, kde se maskuje budouci informace. Pouziva se pro trenovani."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5e1f31d148a66",
   "metadata": {},
   "source": [
    "![transformer](../transfomer_soubory/masked_self_att.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88798f1fa2856dd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1496027236cd7",
   "metadata": {},
   "source": [
    " The Three Ways of Attention and Dot Product Attention: Ungraded Lab Notebook\n",
    "\n",
    "In this notebook you'll explore the three ways of attention (encoder-decoder attention, causal attention, and bi-directional self attention) and how to implement the latter two with dot product attention. \n",
    "\n",
    " Background\n",
    "\n",
    "As you learned last week, **attention models** constitute powerful tools in the NLP practitioner's toolkit. Like LSTMs, they learn which words are most important to phrases, sentences, paragraphs, and so on. Moreover, they mitigate the vanishing gradient problem even better than LSTMs. You've already seen how to combine attention with LSTMs to build **encoder-decoder models** for applications such as machine translation. \n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L3_dot-product-attention_S01_introducing-attention_stripped.png\" width=\"500\"/>\n",
    "\n",
    "This week, you'll see how to integrate attention into **transformers**. Because transformers do not process one token at a time, they are much easier to parallelize and accelerate. Beyond text summarization, applications of transformers include: \n",
    "* Machine translation\n",
    "* Auto-completion\n",
    "* Named Entity Recognition\n",
    "* Chatbots\n",
    "* Question-Answering\n",
    "* And more!\n",
    "\n",
    "Along with embedding, positional encoding, dense layers, and residual connections, attention is a crucial component of transformers. At the heart of any attention scheme used in a transformer is **dot product attention**, of which the figures below display a simplified picture:\n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L3_dot-product-attention_S03_concept-of-attention_stripped.png\" width=\"500\"/>\n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L3_dot-product-attention_S04_attention-math_stripped.png\" width=\"500\"/>\n",
    "\n",
    "With basic dot product attention, you capture the interactions between every word (embedding) in your query and every word in your key. If the queries and keys belong to the same sentences, this constitutes **bi-directional self-attention**. In some situations, however, it's more appropriate to consider only words which have come before the current one. Such cases, particularly when the queries and keys come from the same sentences, fall into the category of **causal attention**. \n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L4_causal-attention_S02_causal-attention_stripped.png\" width=\"500\"/>\n",
    "\n",
    "For causal attention, you add a **mask** to the argument of our softmax function, as illustrated below: \n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L4_causal-attention_S03_causal-attention-math_stripped.png\" width=\"500\"/>\n",
    "\n",
    "<img src=\"transfomer_soubory/C4_W2_L4_causal-attention_S04_causal-attention-math-2_stripped.png\" width=\"500\"/>\n",
    "\n",
    "Now let's see how to implement the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5b26504dcdb33a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:43.016914Z",
     "start_time": "2024-06-19T10:20:43.010519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17212d6f62339f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:44.226180Z",
     "start_time": "2024-06-19T10:20:44.223677Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_tensor(t, name):\n",
    "    \"\"\"Display shape and tensor\"\"\"\n",
    "    print(f'{name} shape: {t.shape}\\n')\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e3fab2bc06ec7",
   "metadata": {},
   "source": [
    "Create some tensors and display their shapes. Feel free to experiment with your own tensors. Keep in mind, though, that the query, key, and value arrays must all have the same embedding dimensions (number of columns), and the mask array must have the same shape as `tf.matmul(query, key_transposed)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c70a94daee54d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:46.696684Z",
     "start_time": "2024-06-19T10:20:46.675152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (2, 3)\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "\n",
      "key shape: (2, 3)\n",
      "\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "value shape: (2, 3)\n",
      "\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 1.]]\n",
      "\n",
      "mask shape: (2, 2)\n",
      "\n",
      "[[1. 0.]\n",
      " [1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = tf.constant([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "display_tensor(q, 'query')\n",
    "k = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "display_tensor(k, 'key')\n",
    "v = tf.constant([[0.0, 1.0, 0.0], [1.0, 0.0, 1.0]])\n",
    "display_tensor(v, 'value')\n",
    "m = tf.constant([[1.0, 0.0], [1.0, 1.0]])\n",
    "display_tensor(m, 'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ad7eca38f4b13",
   "metadata": {},
   "source": [
    "Dot product attention\n",
    "\n",
    "Here you compute \n",
    "$\\textrm{softmax} \\left(\\frac{Q K^T}{\\sqrt{d}} + M \\right) V$, where the (optional, but default) scaling factor $\\sqrt{d}$ is the square root of the embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9aef0a9cfba5375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:50.210900Z",
     "start_time": "2024-06-19T10:20:50.197925Z"
    }
   },
   "outputs": [],
   "source": [
    "def dot_product_attention(q, k, v, mask, scale=True):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q (tf.Tensor): query of shape (..., seq_len_q, depth)\n",
    "        k (tf.Tensor): key of shape (..., seq_len_k, depth)\n",
    "        v (tf.Tensor): value of shape (..., seq_len_v, depth_v)\n",
    "        mask (tf.Tensor): mask with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "        scale (boolean): if True, the result is a scaled dot-product attention. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        attention_output (tf.Tensor): the result of the attention function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Multiply q and k transposed.\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk with the square root of dk\n",
    "    if scale:\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        matmul_qk = matmul_qk / tf.math.sqrt(dk)\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        matmul_qk = matmul_qk + (1. - mask) * -1e9 \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.keras.activations.softmax(matmul_qk)\n",
    "\n",
    "    # Multiply the attention weights by v\n",
    "    attention_output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cc68f3de424746d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:51.962393Z",
     "start_time": "2024-06-19T10:20:51.958712Z"
    }
   },
   "outputs": [],
   "source": [
    "def causal_dot_product_attention(q, k, v, scale=True):\n",
    "    \"\"\" Masked dot product self attention.\n",
    "    Args:\n",
    "        q (numpy.ndarray): queries.\n",
    "        k (numpy.ndarray): keys.\n",
    "        v (numpy.ndarray): values.\n",
    "    Returns:\n",
    "        numpy.ndarray: masked dot product self attention tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Size of the penultimate dimension of the query\n",
    "    mask_size = q.shape[-2]\n",
    "\n",
    "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
    "    mask = tf.experimental.numpy.tril(tf.ones((mask_size, mask_size)))  \n",
    "    \n",
    "    return dot_product_attention(q, k, v, mask, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e3b82f680c6c2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:52.378313Z",
     "start_time": "2024-06-19T10:20:52.162466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result shape: (2, 3)\n",
      "\n",
      "[[0.         1.         0.        ]\n",
      " [0.8496746  0.15032543 0.8496746 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = causal_dot_product_attention(q, k, v)\n",
    "display_tensor(result, 'result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0604e9b37f4ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380af3d56141778",
   "metadata": {},
   "source": [
    " 1 - Masking\n",
    "\n",
    "There are two types of masks that are useful when building your Transformer network: the *padding mask* and the *look-ahead mask*. Both help the softmax computation give the appropriate weights to the words in your input sentence. \n",
    "\n",
    " 1.1 - Padding Mask\n",
    "\n",
    "Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let's say the maximum length of your model is five, it is fed the following sequences:\n",
    "\n",
    "    [[\"Do\", \"you\", \"know\", \"when\", \"Jane\", \"is\", \"going\", \"to\", \"visit\", \"Africa\"], \n",
    "     [\"Jane\", \"visits\", \"Africa\", \"in\", \"September\" ],\n",
    "     [\"Exciting\", \"!\"]\n",
    "    ]\n",
    "\n",
    "which might get vectorized as:\n",
    "\n",
    "    [[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],\n",
    "     [ 56, 1285, 15, 181, 545],\n",
    "     [ 87, 600]\n",
    "    ]\n",
    "    \n",
    "When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:\n",
    "\n",
    "    [[ 71, 121, 4, 56, 99],\n",
    "     [ 2344, 345, 1284, 15, 0],\n",
    "     [ 56, 1285, 15, 181, 545],\n",
    "     [ 87, 600, 0, 0, 0],\n",
    "    ]\n",
    "    \n",
    "Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length. Similarly, for sequences shorter than the maximum length, zeros will also be added for padding.\n",
    "\n",
    "When pasing these vectors through the attention layers, the zeros will typically disappear  (you will get completely new vectors given the mathematical operations that happen in the attention block). However, you still want the network to attend only to the first few numbers in that vector (given by the sentence length) and this is when a padding mask comes in handy. You will need to define a boolean mask that specifies to which elements you must attend (1) and which elements you must ignore (0) and you do this by looking at all the zeros in the sequence. Then you use the mask to set the values of the vectors (corresponding to the zeros in the initial vector) close to negative infinity (-1e9).\n",
    "\n",
    "Imagine your input vector is `[87, 600, 0, 0, 0]`. This would give you a mask of `[1, 1, 0, 0, 0]`. When your vector passes through the attention mechanism, you get another (randomly looking) vector, let's say `[1, 2, 3, 4, 5]`, which after masking becomes `[1, 2, -1e9, -1e9, -1e9]`, so that when you take the softmax, the last three elements (where there were zeros in the input) don't affect the score.\n",
    "\n",
    "The [MultiheadAttention](https://keras.io/api/layers/attention_layers/multi_head_attention/) layer implemented in Keras, uses this masking logic.\n",
    "\n",
    "**Note:** The below function only creates the mask of an _already padded sequence_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99d5e4ff3fc9a329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:55.675888Z",
     "start_time": "2024-06-19T10:20:55.666850Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids (matrix like): matrix of size (n, m)\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (n, 1, m)\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits. \n",
    "    # this will allow for broadcasting later when comparing sequences\n",
    "    return seq[:, tf.newaxis, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ca900a398e797d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:57.382239Z",
     "start_time": "2024-06-19T10:20:57.147368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0.]]], shape=(3, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[7., 6., 0., 0., 0.], [1., 2., 3., 0., 0.], [3., 0., 0., 0., 0.]])\n",
    "print(create_padding_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63c73b8d96fcee72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:20:58.041958Z",
     "start_time": "2024-06-19T10:20:57.996668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax of non-masked vectors:\n",
      "\n",
      "tf.Tensor(\n",
      "[[[7.2959948e-01 2.6840463e-01 6.6530856e-04 6.6530856e-04 6.6530856e-04]]\n",
      "\n",
      " [[8.4437363e-02 2.2952455e-01 6.2391245e-01 3.1062769e-02 3.1062769e-02]]\n",
      "\n",
      " [[8.3392531e-01 4.1518692e-02 4.1518692e-02 4.1518692e-02 4.1518692e-02]]], shape=(3, 1, 5), dtype=float32)\n",
      "\n",
      "Softmax of masked vectors:\n",
      "\n",
      "tf.Tensor(\n",
      "[[[0.7310586  0.2689414  0.         0.         0.        ]]\n",
      "\n",
      " [[0.09003057 0.24472848 0.665241   0.         0.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.         0.        ]]], shape=(3, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create the mask for x\n",
    "mask = create_padding_mask(x)\n",
    "\n",
    "# Extend the dimension of x to match the dimension of the mask\n",
    "x_extended = x[:, tf.newaxis, :]\n",
    "\n",
    "print(\"Softmax of non-masked vectors:\\n\")\n",
    "print(tf.keras.activations.softmax(x_extended))\n",
    "\n",
    "print(\"\\nSoftmax of masked vectors:\\n\")\n",
    "print(tf.keras.activations.softmax(x_extended + (1 - mask) * -1.0e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f094ea9740f6ee",
   "metadata": {},
   "source": [
    " 1.2 - Look-ahead Mask\n",
    "\n",
    "The look-ahead mask follows similar intuition. In training, you will have access to the complete correct output of your training example. The look-ahead mask helps your model pretend that it correctly predicted a part of the output and see if, *without looking ahead*, it can correctly predict the next output. \n",
    "\n",
    "For example, if the expected correct output is `[1, 2, 3]` and you wanted to see if given that the model correctly predicted the first value it could predict the second value, you would mask out the second and third values. So you would input the masked sequence `[1, -1e9, -1e9]` and see if it could generate `[1, 2, -1e9]`.\n",
    "\n",
    "Just because you've worked so hard, we'll also implement this mask for you . Again, take a close look at the code so you can effectively implement it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71018b45e215e9bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:02.621168Z",
     "start_time": "2024-06-19T10:21:02.610711Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns a lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length (int): matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c3572423140cf9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:03.341130Z",
     "start_time": "2024-06-19T10:21:03.232967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d77af00b26a540",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LAB: Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8efa4467959a7c",
   "metadata": {},
   "source": [
    "1. Positional Encoding\n",
    "\n",
    "In sequence to sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model.  However, when you train a Transformer network using multi-head attention, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:\n",
    "    \n",
    "$$\n",
    "PE_{(pos, 2i)}= sin\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "\\tag{1}$$\n",
    "<br>\n",
    "$$\n",
    "PE_{(pos, 2i+1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "\\tag{2}$$\n",
    "\n",
    "* $d$ is the dimension of the word embedding and positional encoding\n",
    "* $pos$ is the position of the word.\n",
    "* $k$ refers to each of the different dimensions in the positional encodings, with $i$ equal to $k$ $//$ $2$.\n",
    "\n",
    "To develop some intuition about positional encodings, you can think of them broadly as a feature that contains the information about the relative positions of words. The sum of the positional encoding and word embedding is ultimately what is fed into the model. If you just hard code the positions in, say by adding a matrix of 1's or whole numbers to the word embedding, the semantic meaning is distorted. Conversely, the values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted, and is instead enriched with positional information. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data.\n",
    "\n",
    " 1.1 - Sine and Cosine Angles\n",
    "\n",
    "Notice that even though the sine and cosine positional encoding equations take in different arguments (`2i` versus `2i+1`, or even versus odd numbers) the inner terms for both equations are the same: $$\\theta(pos, i, d) = \\frac{pos}{10000^{\\frac{2i}{d}}} \\tag{3}$$\n",
    "\n",
    "Consider the inner term as you calculate the positional encoding for a word in a sequence.<br> \n",
    "$PE_{(pos, 0)}= sin\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i = 0` gives `i = 0` <br>\n",
    "$PE_{(pos, 1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i + 1 = 1` gives `i = 0`\n",
    "\n",
    "The angle is the same for both! The angles for $PE_{(pos, 2)}$ and $PE_{(pos, 3)}$ are the same as well, since for both, `i = 1` and therefore the inner term is $\\left(\\frac{pos}{{10000}^{\\frac{2}{d}}}\\right)$. This relationship holds true for all paired sine and cosine curves:\n",
    "\n",
    "|      k         | <code>       0      </code>|<code>       1      </code>|<code>       2      </code>|<code>       3      </code>| <code> ... </code> |<code>      d - 2     </code>|<code>      d - 1     </code>| \n",
    "| ---------------- | :------: | ----------------- | ----------------- | ----------------- | ----- | ----------------- | ----------------- |\n",
    "| encoding(0) = |[$sin(\\theta(0, 0, d))$| $cos(\\theta(0, 0, d))$| $sin(\\theta(0, 1, d))$| $cos(\\theta(0, 1, d))$|... |$sin(\\theta(0, d//2, d))$| $cos(\\theta(0, d//2, d))$]|\n",
    "| encoding(1) = | [$sin(\\theta(1, 0, d))$| $cos(\\theta(1, 0, d))$| $sin(\\theta(1, 1, d))$| $cos(\\theta(1, 1, d))$|... |$sin(\\theta(1, d//2, d))$| $cos(\\theta(1, d//2, d))$]|\n",
    "...\n",
    "| encoding(pos) = | [$sin(\\theta(pos, 0, d))$| $cos(\\theta(pos, 0, d))$| $sin(\\theta(pos, 1, d))$| $cos(\\theta(pos, 1, d))$|... |$sin(\\theta(pos, d//2, d))$| $cos(\\theta(pos, d//2, d))]$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc5498c0e687faa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:08.431007Z",
     "start_time": "2024-06-19T10:21:08.426469Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_angles(position, k, d_model):\n",
    "    \"\"\"\n",
    "    Computes a positional encoding for a word \n",
    "    \n",
    "    Arguments:\n",
    "        position (int): position of the word\n",
    "        k (int): refers to each of the different dimensions in the positional encodings, with i equal to k//2\n",
    "        d_model(int): the dimension of the word embedding and positional encoding\n",
    "    \n",
    "    Returns:\n",
    "        _ (float): positional embedding value for the word\n",
    "    \"\"\"\n",
    "    i = k // 2\n",
    "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
    "    return position * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce5976fa2159a428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:08.865473Z",
     "start_time": "2024-06-19T10:21:08.861491Z"
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int): Maximum number of positions to be encoded \n",
    "        d (int): Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n",
    "    \"\"\"\n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rads = get_angles(np.arange(positions)[:, np.newaxis],\n",
    "                          np.arange(d)[np.newaxis, :],\n",
    "                          d)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a68ea4ef44b63fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:10.295635Z",
     "start_time": "2024-06-19T10:21:10.104139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(128, 256)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('d')\n",
    "plt.xlim((0, 256))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb438e60b3060930",
   "metadata": {},
   "source": [
    "### LAB: Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "149df714468f1baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:17.598554Z",
     "start_time": "2024-06-19T10:21:13.291968Z"
    }
   },
   "outputs": [],
   "source": [
    "import transfomer_soubory.utils_attention as utils_att\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "174903561e440861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:17.893113Z",
     "start_time": "2024-06-19T10:21:17.605173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "Lucas: Hey! How was your day?\r\n",
      "Demi: Hey there! \r\n",
      "Demi: It was pretty fine, actually, thank you!\r\n",
      "Demi: I just got promoted! :D\r\n",
      "Lucas: Whoa! Great news!\r\n",
      "Lucas: Congratulations!\r\n",
      "Lucas: Such a success has to be celebrated.\r\n",
      "Demi: I agree! :D\r\n",
      "Demi: Tonight at Death & Co.?\r\n",
      "Lucas: Sure!\r\n",
      "Lucas: See you there at 10pm?\r\n",
      "Demi: Yeah! See you there! :D\n",
      "\n",
      "Summary:\n",
      "Demi got promoted. She will celebrate that with Lucas at Death & Co at 10 pm.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"transfomer_soubory/corpus\"\n",
    "\n",
    "train_data, test_data = utils_att.get_train_test_data(data_dir)\n",
    "\n",
    "# Take one example from the dataset and print it\n",
    "example_summary, example_dialogue = train_data.iloc[10]\n",
    "print(f\"Dialogue:\\n{example_dialogue}\")\n",
    "print(f\"\\nSummary:\\n{example_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900087300cdd04b",
   "metadata": {},
   "source": [
    "2 - Preprocess the data\n",
    "\n",
    "First you will do some preprocessing of the data and split it into inputs and outputs. Here you also remove some of the characters that are specific to this dataset and add the `[EOS]` (end of sentence) token to the end, like it was discussed in the lecture videos. You will also add a `[SOS]` (start of sentence) token to the beginning of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a3e8851aac3e4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:20.776356Z",
     "start_time": "2024-06-19T10:21:20.326292Z"
    }
   },
   "outputs": [],
   "source": [
    "document, summary = utils_att.preprocess(train_data)\n",
    "document_test, summary_test = utils_att.preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "722c2cbabcf0d3bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:23.550421Z",
     "start_time": "2024-06-19T10:21:21.174712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 34250\n"
     ]
    }
   ],
   "source": [
    "# The [ and ] from default tokens cannot be removed, because they mark the SOS and EOS token.\n",
    "filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n'\n",
    "oov_token = '[UNK]'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token, lower=False)\n",
    "\n",
    "documents_and_summary = pd.concat([document, summary], ignore_index=True)\n",
    "\n",
    "tokenizer.fit_on_texts(documents_and_summary)\n",
    "\n",
    "inputs = tokenizer.texts_to_sequences(document)\n",
    "targets = tokenizer.texts_to_sequences(summary)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f'Size of vocabulary: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb48747227515054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:26.560629Z",
     "start_time": "2024-06-19T10:21:26.254851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data for being able to run it in this environment.\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "# Pad the sequences.\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53c2a57376349047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:26.569180Z",
     "start_time": "2024-06-19T10:21:26.564612Z"
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d_model):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int): Maximum number of positions to be encoded \n",
    "        d_model (int): Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n",
    "    \"\"\"\n",
    "    \n",
    "    position = np.arange(positions)[:, np.newaxis]\n",
    "    k = np.arange(d_model)[np.newaxis, :]\n",
    "    i = k // 2\n",
    "    \n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
    "    angle_rads = position * angle_rates\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62b54002b66d270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:28.716171Z",
     "start_time": "2024-06-19T10:21:28.712475Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids (matrix like): matrix of size (n, m)\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (n, 1, m)\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding to the attention logits. \n",
    "    # this will allow for broadcasting later when comparing sequences\n",
    "    return seq[:, tf.newaxis, :] \n",
    "\n",
    "\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns a lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length (int): matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13aebae8cbc0310",
   "metadata": {},
   "source": [
    "5 - Self-Attention\n",
    "\n",
    "As the authors of the Transformers paper state, \"Attention is All You Need\". \n",
    "\n",
    "<img src=\"transfomer_soubory/assign_self-attention.png\" alt=\"Encoder\" width=\"600\"/>\n",
    "<caption><center><font color='purple'><b>Figure 1: Self-Attention calculation visualization</font></center></caption>\n",
    "    \n",
    "The use of self-attention paired with traditional convolutional networks allows for parallelization which speeds up training. You will implement **scaled dot product attention** which takes in a query, key, value, and a mask as inputs to return rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{4}\\\n",
    "$$\n",
    "\n",
    "* $Q$ is the matrix of queries \n",
    "* $K$ is the matrix of keys\n",
    "* $V$ is the matrix of values\n",
    "* $M$ is the optional mask you choose to apply \n",
    "* ${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "Exercise 1 - scaled_dot_product_attention \n",
    "\n",
    "Implement the function `scaled_dot_product_attention()` to create attention-based representations.\n",
    "\n",
    "**Reminder**: The boolean mask parameter can be passed in as `none` or as either padding or look-ahead. \n",
    "    \n",
    "* Multiply (1. - mask) by -1e9 before adding it to the scaled attention logits. \n",
    "\n",
    "**Additional Hints**\n",
    "* You may find [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) useful for matrix multiplication (check how you can use the parameter transpose_b).\n",
    "* You can use [tf.keras.activations.softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) for softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19e52d3222a6a6dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:31.592646Z",
     "start_time": "2024-06-19T10:21:31.587243Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q (tf.Tensor): query of shape (..., seq_len_q, depth)\n",
    "        k (tf.Tensor): key of shape (..., seq_len_k, depth)\n",
    "        v (tf.Tensor): value of shape (..., seq_len_v, depth_v)\n",
    "        mask (tf.Tensor): mask with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    # Multiply q and k transposed.\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True)\n",
    "\n",
    "    # scale matmul_qk with the square root of dk\n",
    "    dk = tf.cast(np.sqrt(k.shape[1]), tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / dk\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:  # Don't replace this None\n",
    "        scaled_attention_logits += (1. - mask) * (-1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.keras.activations.softmax(scaled_attention_logits)\n",
    "\n",
    "    # Multiply the attention weights by v\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecda3f7543b8af9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:33.857130Z",
     "start_time": "2024-06-19T10:21:33.706764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " [[[1.   0.62]\n",
      "  [0.62 0.62]\n",
      "  [0.74 0.31]]]\n",
      "\n",
      "Attention weigths:\n",
      " [[[0.   0.38 0.   0.23 0.38]\n",
      "  [0.38 0.   0.   0.23 0.38]\n",
      "  [0.26 0.43 0.   0.16 0.16]]]\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "q = np.array([[1, 1, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]]).astype(np.float32)\n",
    "k = np.array([[1, 1, 0, 1], [1, 0, 1, 1 ], [1, 1, 1, 0], [0, 0, 0, 1], [0, 1, 0, 1]]).astype(np.float32)\n",
    "v = np.array([[0, 0], [1, 0], [1, 0], [1, 1], [1, 1]]).astype(np.float32)\n",
    "mask = np.array([[[0, 1, 0, 1, 1], [1, 0, 0, 1, 1], [1, 1, 0, 1, 1]]])\n",
    "\n",
    "ou, atw = scaled_dot_product_attention(q, k, v, mask)\n",
    "ou = np.around(ou, decimals=2)\n",
    "atw = np.around(atw, decimals=2)\n",
    "\n",
    "print(f\"Output:\\n {ou}\")\n",
    "print(f\"\\nAttention weigths:\\n {atw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721d0253db2ee32",
   "metadata": {},
   "source": [
    "6 - Encoder\n",
    "\n",
    "The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which you'll build later in the assignment. In this section of the assignment, you will implement the Encoder by pairing multi-head attention and a feed forward neural network (Figure 2a). \n",
    "<img src=\"transfomer_soubory/assign_encoder_layer.png\" alt=\"Encoder\" width=\"400\"/>\n",
    "<caption><center><font color='purple'><b>Figure 2a: Transformer encoder layer</font></center></caption>\n",
    "\n",
    "* `MultiHeadAttention` you can think of as computing the self-attention several times to detect different features. \n",
    "* Feed forward neural network contains two Dense layers which we'll implement as the function `FullyConnected`\n",
    "\n",
    "Your input sentence first passes through a *multi-head attention layer*, where the encoder looks at other words in the input sentence as it encodes a specific word. The outputs of the multi-head attention layer are then fed to a *feed forward neural network*. The exact same feed forward network is independently applied to each position.\n",
    "   \n",
    "* For the `MultiHeadAttention` layer, you will use the [MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) implemented in Keras. If you're curious about how to split the query matrix Q, key matrix K, and value matrix V into different heads, you can look through the implementation. \n",
    "* You will also use the [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) with two dense layers to built the feed forward neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a212ccfbf24ef314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:37.561436Z",
     "start_time": "2024-06-19T10:21:37.554369Z"
    }
   },
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    \"\"\"\n",
    "    Returns a sequential model consisting of two dense layers. The first dense layer has\n",
    "    fully_connected_dim neurons and is activated by relu. The second dense layer has\n",
    "    embedding_dim and no activation.\n",
    "\n",
    "    Arguments:\n",
    "        embedding_dim (int): output dimension\n",
    "        fully_connected_dim (int): dimension of the hidden layer\n",
    "\n",
    "    Returns:\n",
    "        _ (tf.keras.Model): sequential model\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, d_model)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600c6c77c4c6d84",
   "metadata": {},
   "source": [
    "6.1 Encoder Layer\n",
    "\n",
    "Now you can pair multi-head attention and feed forward neural network together in an encoder layer! You will also use residual connections and layer normalization to help speed up training (Figure 2a).\n",
    "\n",
    "The encoder block (Figure 2) is is already implemented for you. Take a very close look at its implementation, as you will later have to create the decoder yourself, and a lot of the code is very similar. The encoder block performs the following steps: \n",
    "1. It takes the Q, V, K matrices and a boolean mask to a multi-head attention layer. Remember that to compute *self*-attention Q, V and K are the same. You will also perform Dropout in this multi-head attention layer during training. \n",
    "2. There is a skip connection to add your original input `x` and the output of the multi-head attention layer. \n",
    "3. After adding the skip connection, the output passes through the first normalization layer.\n",
    "4. Finally, steps 1-3 are repeated but with the feed forward neural network with a dropout layer instead of the multi-head attention layer. \n",
    "\n",
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Additional Information (Click to expand)</b></font></summary>\n",
    "    \n",
    "* The `__init__` method creates all the layers that will be accesed by the the `call` method. Wherever you want to use a layer defined inside  the `__init__`  method you will have to use the syntax `self.[insert layer name]`. \n",
    "* You will find the documentation of [MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) helpful. *Note that if query, key and value are the same, then this function performs self-attention.*\n",
    "* The call arguments for `self.mha` are (Where B is for batch_size, T is for target sequence shapes, and S is output_shape):\n",
    " - `query`: Query Tensor of shape (B, T, dim).\n",
    " - `value`: Value Tensor of shape (B, S, dim).\n",
    " - `key`: Optional key Tensor of shape (B, S, dim). If not given, will use the same value for both key and value, which is the most common case.\n",
    " - `attention_mask`: a boolean mask of shape (B, T, S), that prevents attention to certain positions. The boolean mask specifies which query elements can attend to which key elements, 1 indicates attention and 0 indicates no attention. Broadcasting can happen for the missing batch dimensions and the head dimension.\n",
    " - `return_attention_scores`: A boolean to indicate whether the output should be attention output if True, or (attention_output, attention_scores) if False. Defaults to False.\n",
    " - `training`: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (no dropout). Defaults to either using the training mode of the parent layer/model, or False (inference) if there is no parent layer. Take a look at [tf.keras.layers.Dropout](https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/Dropout) for more details (Additional reading in [Keras FAQ](https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9ef579e65b5e4e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:21:44.365196Z",
     "start_time": "2024-06-19T10:21:44.343214Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This architecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out (tf.Tensor): Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # calculate self-attention using mha(~1 line).\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        self_mha_output = self.mha(x, x, x, mask)  # Self attention (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # skip connection\n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer\n",
    "        skip_x_attention = self.layernorm1(x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer through a ffn\n",
    "        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output\n",
    "        # to get the output of the encoder layer\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7568f994761dea2",
   "metadata": {},
   "source": [
    "6.2 - Full Encoder\n",
    "\n",
    "Now you're ready to build the full Transformer Encoder (Figure 2b), where you will embed your input and add the positional encodings you calculated. You will then feed your encoded embeddings to a stack of Encoder layers. \n",
    "\n",
    "<img src=\"transfomer_soubory/assign_encoder.png\" alt=\"Encoder\" width=\"330\"/>\n",
    "<caption><center><font color='purple'><b>Figure 2b: Transformer Encoder</font></center></caption>\n",
    "\n",
    "The Encoder class is implemented for you. It performs the following steps: \n",
    "1. Pass the input through the Embedding layer.\n",
    "2. Scale the embedding by multiplying it by the square root of the embedding dimension. \n",
    "3. Add the position encoding: self.pos_encoding `[:, :seq_len, :]` to the embedding.\n",
    "4. Pass the encoded embedding through a dropout layer\n",
    "5. Pass the output of the dropout layer through the stack of encoding layers using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "feea13b2602113e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:13.370573Z",
     "start_time": "2024-06-19T11:41:13.361374Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Pass input through the Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        # Scale embedding by multiplying it by the square root of the embedding dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        # Add the position encoding to embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        # Pass the encoded embedding through a dropout layer\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9585086e0e26b",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "7 - Decoder\n",
    "\n",
    "Now it is time to implement the decoder. You have seen it in the videos and you can use some help by looking at the encoder implementation above. The Decoder layer takes the K and V matrices generated by the Encoder and computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).\n",
    "\n",
    "<img src=\"transfomer_soubory/assing_decoder_layer.png\" alt=\"Decoder\" width=\"250\"/>\n",
    "<caption><center><font color='purple'><b>Figure 3a: Transformer Decoder layer</font></center></caption>\n",
    "\n",
    "<a name='7-1'></a>    \n",
    "7.1 - Decoder Layer\n",
    "Again, you'll pair multi-head attention with a feed forward neural network, but this time you'll implement two multi-head attention layers. You will also use residual connections and layer normalization to help speed up training (Figure 3a).\n",
    "\n",
    "<a name='ex-2'></a>    \n",
    "Exercise 2 - DecoderLayer\n",
    "    \n",
    "Implement `DecoderLayer()` using the `call()` method\n",
    "    \n",
    "1. Block 1 is a multi-head attention layer with a residual connection, and look-ahead mask. Like in the `EncoderLayer`, Dropout is defined within the multi-head attention layer.\n",
    "2. Block 2 will take into account the output of the Encoder, so the multi-head attention layer will receive K and V from the encoder, and Q from the Block 1. You will then apply a normalization layer and a residual connection, just like you did before with the `EncoderLayer`.\n",
    "3. Finally, Block 3 is a feed forward neural network with dropout and normalization layers and a residual connection.\n",
    "    \n",
    "**Additional Hints:**\n",
    "* The first two blocks are fairly similar to the EncoderLayer except you will return `attention_scores` when computing self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79006179f49d5e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:18.326109Z",
     "start_time": "2024-06-19T11:41:18.306126Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecoderLayer\u001b[39;00m(\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    The decoder layer is composed by two multi-head attention blocks,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    one that takes the new input and uses self-attention, and the other\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    one that combines it with the output of the encoder, followed by a\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    fully connected block.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, embedding_dim, num_heads, fully_connected_dim, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, layernorm_eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The decoder layer is composed by two multi-head attention blocks,\n",
    "    one that takes the new input and uses self-attention, and the other\n",
    "    one that combines it with the output of the encoder, followed by a\n",
    "    fully connected block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "\n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output (tf.Tensor): Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            out3 (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attn_weights_block1 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, target_seq_len)\n",
    "            attn_weights_block2 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        # enc_output.shape == (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # BLOCK 1\n",
    "        # calculate self-attention and return attention scores as attn_weights_block1.\n",
    "        # Dropout will be applied during training (~1 line).\n",
    "        mult_attn_out1, attn_weights_block1 = self.mha1(x, x, x, attention_mask=look_ahead_mask, return_attention_scores=True)\n",
    "\n",
    "        # apply layer normalization (layernorm1) to the sum of the attention output and the input (~1 line)\n",
    "        Q1 = self.layernorm1(x + mult_attn_out1)\n",
    "\n",
    "        # BLOCK 2\n",
    "        # calculate self-attention using the Q from the first block and K and V from the encoder output.\n",
    "        # Dropout will be applied during training\n",
    "        # Return attention scores as attn_weights_block2 (~1 line)\n",
    "        mult_attn_out2, attn_weights_block2 = self.mha2(Q1, enc_output, enc_output, attention_mask=padding_mask,\n",
    "                                                        return_attention_scores=True)\n",
    "\n",
    "        # apply layer normalization (layernorm2) to the sum of the attention output and the output of the first block (~1 line)\n",
    "        mult_attn_out2 = self.layernorm2(Q1 + mult_attn_out2)\n",
    "\n",
    "        # BLOCK 3\n",
    "        # pass the output of the second block through a ffn\n",
    "        ffn_output = self.ffn(mult_attn_out2)\n",
    "\n",
    "        # apply a dropout layer to the ffn output\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "\n",
    "        # apply layer normalization (layernorm3) to the sum of the ffn output and the output of the second block\n",
    "        out3 = self.layernorm3(ffn_output + mult_attn_out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38372cadd9ec3a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:19.372035Z",
     "start_time": "2024-06-19T11:41:19.169153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding_dim=12 and num_heads=16:\n",
      "\n",
      "q has shape:(1, 15, 12)\n",
      "Output of encoder has shape:(1, 7, 8)\n",
      "\n",
      "Output of decoder layer has shape:(1, 15, 12)\n",
      "Att Weights Block 1 has shape:(1, 16, 15, 15)\n",
      "Att Weights Block 2 has shape:(1, 16, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "key_dim = 12\n",
    "n_heads = 16\n",
    "\n",
    "decoderLayer_test = DecoderLayer(embedding_dim=key_dim, num_heads=n_heads, fully_connected_dim=32)\n",
    "\n",
    "q = np.ones((1, 15, key_dim))\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(1, 7, 8))\n",
    "look_ahead_mask = create_look_ahead_mask(q.shape[1])\n",
    "out, attn_w_b1, attn_w_b2 = decoderLayer_test(\n",
    "                                              x=q, \n",
    "                                              enc_output=encoder_test_output, training=False,\n",
    "                                              look_ahead_mask=look_ahead_mask, padding_mask=None)\n",
    "\n",
    "print(f\"Using embedding_dim={key_dim} and num_heads={n_heads}:\\n\")\n",
    "print(f\"q has shape:{q.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder layer has shape:{out.shape}\")\n",
    "print(f\"Att Weights Block 1 has shape:{attn_w_b1.shape}\")\n",
    "print(f\"Att Weights Block 2 has shape:{attn_w_b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86829319c8e5e6",
   "metadata": {},
   "source": [
    "7.2 - Full Decoder\n",
    "You're almost there! Time to use your Decoder layer to build a full Transformer Decoder (Figure 3b). You will embed your output and add positional encodings. You will then feed your encoded embeddings to a stack of Decoder layers. \n",
    "\n",
    "\n",
    "<img src=\"transfomer_soubory/assign_decoder.png\" alt=\"Decoder\" width=\"300\"/>\n",
    "<caption><center><font color='purple'><b>Figure 3b: Transformer Decoder</font></center></caption>\n",
    "\n",
    "<a name='ex-3'></a>     \n",
    "Exercise 3 - Decoder\n",
    "\n",
    "Implement `Decoder()` using the `call()` method to embed your output, add positional encoding, and implement multiple decoder layers.\n",
    " \n",
    "In this exercise, you will initialize your Decoder with an Embedding layer, positional encoding, and multiple DecoderLayers. Your `call()` method will perform the following steps: \n",
    "1. Pass your generated output through the Embedding layer.\n",
    "2. Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type `tf.float32` before computing the square root.\n",
    "3. Add the position encoding: self.pos_encoding `[:, :seq_len, :]` to your embedding.\n",
    "4. Pass the encoded embedding through a dropout layer, remembering to use the `training` parameter to set the model training mode. \n",
    "5. Pass the output of the dropout layer through the stack of Decoding layers using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5592eff2f9d794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:21.717448Z",
     "start_time": "2024-06-19T11:41:21.710239Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the target input to an embedding layer\n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    decoder Layers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "                 maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps)\n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "             look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "\n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output (tf.Tensor):  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        # create word embeddings\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # scale embeddings by multiplying by the square root of their dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "\n",
    "        # add positional encodings to word embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # apply a dropout layer to x\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # use a for loop to pass x through a stack of decoder layers and update attention_weights (~4 lines total)\n",
    "        for i in range(self.num_layers):\n",
    "            # pass x and the encoder output through a stack of decoder layers and save the attention weights\n",
    "            # of block 1 and 2 (~1 line)\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training=training, look_ahead_mask=look_ahead_mask,\n",
    "                                                   padding_mask=padding_mask)\n",
    "\n",
    "            # update attention_weights dictionary with the attention weights of block 1 and block 2\n",
    "            attention_weights[f'decoder_layer{i + 1}_block1_self_att'] = block1\n",
    "            attention_weights[f'decoder_layer{i + 1}_block2_decenc_att'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35647da323bb6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:24.429803Z",
     "start_time": "2024-06-19T11:41:23.240896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
      "\n",
      "x has shape:(3, 4)\n",
      "Output of encoder has shape:(3, 7, 9)\n",
      "\n",
      "Output of decoder has shape:(3, 4, 13)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer1_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer2_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer2_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer3_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer3_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer4_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer4_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 5\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 16\n",
    "target_vocab_size = 300\n",
    "maximum_position_encoding = 6\n",
    "\n",
    "x = np.array([[3, 2, 1, 1], [2, 1, 1, 0], [2, 1, 1, 0]])\n",
    "\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(3, 7, 9))\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
    "\n",
    "decoder_test = Decoder(n_layers, emb_d, n_heads, fully_connected_dim, target_vocab_size, maximum_position_encoding)\n",
    "\n",
    "# Correct the call by passing 'training' as a keyword argument\n",
    "outd, att_weights = decoder_test(x, encoder_test_output, training=False, look_ahead_mask=look_ahead_mask, padding_mask=None)\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, embedding_dim={emb_d} and num_heads={n_heads}:\\n\")\n",
    "print(f\"x has shape:{x.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder has shape:{outd.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ab9655ea6775f",
   "metadata": {},
   "source": [
    "8 - Transformer\n",
    "\n",
    "Phew! This has been quite the assignment! Congratulations! You've done all the hard work, now it's time to put it all together.  \n",
    "\n",
    "<img src=\"transfomer_soubory/assign_transformer.png\" alt=\"Transformer\" width=\"550\"/>\n",
    "<caption><center><font color='purple'><b>Figure 4: Transformer</font></center></caption>\n",
    "    \n",
    "The flow of data through the Transformer Architecture is as follows:\n",
    "* First your input passes through an Encoder, which is just repeated Encoder layers that you implemented:\n",
    "    - embedding and positional encoding of your input\n",
    "    - multi-head attention on your input\n",
    "    - feed forward neural network to help detect features\n",
    "* Then the predicted output passes through a Decoder, consisting of the decoder layers that you implemented:\n",
    "    - embedding and positional encoding of the output\n",
    "    - multi-head attention on your generated output\n",
    "    - multi-head attention with the Q from the first multi-head attention layer and the K and V from the Encoder\n",
    "    - a feed forward neural network to help detect features\n",
    "* Finally, after the Nth Decoder layer, one dense layer and a softmax are applied to generate prediction for the next output in your sequence.\n",
    "\n",
    "<a name='ex-4'></a> \n",
    "Exercise 4 - Transformer\n",
    "\n",
    "Implement `Transformer()` using the `call()` method\n",
    "1. Pass the input through the Encoder with the appropiate mask.\n",
    "2. Pass the encoder output and the target through the Decoder with the appropiate mask.\n",
    "3. Apply a linear transformation and a softmax to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20d526339c34c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:28.854649Z",
     "start_time": "2024-06-19T11:41:28.837861Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size, \n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_sentence (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the input sentence\n",
    "            output_sentence (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            dec_padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output (tf.Tensor): The final output of the model\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        # call self.encoder with the appropriate arguments to get the encoder output\n",
    "        enc_output = self.encoder(x=input_sentence, training=training, mask=enc_padding_mask)\n",
    "        \n",
    "        # call self.decoder with the appropriate arguments to get the decoder output\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n",
    "        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training=training, \n",
    "                                                     look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n",
    "        \n",
    "        # pass decoder output through a linear layer and softmax (~1 line)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bc36da0169b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:41:38.574166Z",
     "start_time": "2024-06-19T11:41:34.526493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=3, target_vocab_size=350 and num_heads=17:\n",
      "\n",
      "sentence_a has shape:(1, 7)\n",
      "sentence_b has shape:(1, 7)\n",
      "\n",
      "Output of transformer (summary) has shape:(1, 7, 350)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer1_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block2_decenc_att has shape:(1, 17, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 3\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 8\n",
    "input_vocab_size = 300\n",
    "target_vocab_size = 350\n",
    "max_positional_encoding_input = 12\n",
    "max_positional_encoding_target = 12\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers = n_layers, \n",
    "    embedding_dim = emb_d, \n",
    "    num_heads = n_heads, \n",
    "    fully_connected_dim = fully_connected_dim, \n",
    "    input_vocab_size = input_vocab_size, \n",
    "    target_vocab_size = target_vocab_size, \n",
    "    max_positional_encoding_input = max_positional_encoding_input,\n",
    "    max_positional_encoding_target = max_positional_encoding_target)\n",
    "\n",
    "# 0 is the padding value\n",
    "sentence_a = np.array([[2, 3, 1, 3, 0, 0, 0]])\n",
    "sentence_b = np.array([[1, 3, 4, 0, 0, 0, 0]])\n",
    "\n",
    "enc_padding_mask = create_padding_mask(sentence_a)\n",
    "dec_padding_mask = create_padding_mask(sentence_a)\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(sentence_a.shape[1])\n",
    "\n",
    "test_summary, att_weights = transformer(\n",
    "    input_sentence = sentence_a,\n",
    "    output_sentence = sentence_b,\n",
    "    training = False,\n",
    "    enc_padding_mask = enc_padding_mask,\n",
    "    look_ahead_mask = look_ahead_mask,\n",
    "    dec_padding_mask = dec_padding_mask\n",
    ")\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, target_vocab_size={target_vocab_size} and num_heads={n_heads}:\\n\")\n",
    "print(f\"sentence_a has shape:{sentence_a.shape}\")\n",
    "print(f\"sentence_b has shape:{sentence_b.shape}\")\n",
    "\n",
    "print(f\"\\nOutput of transformer (summary) has shape:{test_summary.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999375bf82266163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:42:08.305951Z",
     "start_time": "2024-06-19T11:42:08.227674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers = 2\n",
    "embedding_dim = 128\n",
    "fully_connected_dim = 128\n",
    "num_heads = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "# Initialize the model\n",
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    embedding_dim, \n",
    "    num_heads, \n",
    "    fully_connected_dim,\n",
    "    vocab_size, \n",
    "    vocab_size, \n",
    "    positional_encoding_length, \n",
    "    positional_encoding_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad30552179401e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:42:21.168595Z",
     "start_time": "2024-06-19T11:42:21.131252Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(embedding_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc111556fefc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:42:23.779348Z",
     "start_time": "2024-06-19T11:42:23.382698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf1da589b3c764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:46:26.716862Z",
     "start_time": "2024-06-19T11:46:26.677979Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def masked_loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# Here you will store the losses, so you can later plot them\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936527c5f1a582b",
   "metadata": {},
   "source": [
    "Now you can define your custom training function. If you are not very advanced with tensorflow, you can understand this function as an alternative to using `model.compile()` and `model.fit()`, but with added extra flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee3a4cc88bb456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:47:26.417842Z",
     "start_time": "2024-06-19T11:47:26.401513Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inp, tar):\n",
    "    \"\"\"\n",
    "    One training step for the transformer\n",
    "    Arguments:\n",
    "        inp (tf.Tensor): Input data to summarize\n",
    "        tar (tf.Tensor): Target (summary)\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "    dec_padding_mask = create_padding_mask(inp) # Notice that both encoder and decoder padding masks are equal\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model(\n",
    "            input_sentence=inp,\n",
    "            output_sentence=tar_inp, \n",
    "            training=True, \n",
    "            enc_padding_mask=enc_padding_mask, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            dec_padding_mask=dec_padding_mask\n",
    "        )\n",
    "        loss = masked_loss(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee82a46d86a7fa8",
   "metadata": {},
   "source": [
    "11 - Summarization\n",
    "\n",
    "The last thing you will implement is inference. With this, you will be able to produce actual summaries of the documents. You will use a simple method called greedy decoding, which means you will predict one word at a time and append it to the output. You will start with an `[SOS]` token and repeat the word by word inference until the model returns you the `[EOS]` token or until you reach the maximum length of the sentence (you need to add this limit, otherwise a poorly trained model could give you infinite sentences without ever producing the `[EOS]` token.\n",
    "\n",
    "\n",
    "Exercise 5 - next_word\n",
    "Write a helper function that predicts the next word, so you can use it to write the whole sentences. Hint: this is very similar to what happens in the train_step, but you have to set the training of the model to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44e0e4c0ec9173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:43:57.027703Z",
     "start_time": "2024-06-19T11:43:56.994725Z"
    }
   },
   "outputs": [],
   "source": [
    "def next_word(model, encoder_input, output):\n",
    "    \"\"\"\n",
    "    Helper function for summarization that uses the model to predict just the next word.\n",
    "    Arguments:\n",
    "        encoder_input (tf.Tensor): Input data to summarize\n",
    "        output (tf.Tensor): (incomplete) target (summary)\n",
    "    Returns:\n",
    "        predicted_id (tf.Tensor): The id of the predicted word\n",
    "    \"\"\"\n",
    "    # Create a padding mask for the input (encoder)\n",
    "    enc_padding_mask = create_padding_mask(encoder_input)\n",
    "    # Create a look-ahead mask for the output\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
    "    # Create a padding mask for the input (decoder)\n",
    "    dec_padding_mask = create_padding_mask(encoder_input)\n",
    "\n",
    "    # Run the prediction of the next word with the transformer model\n",
    "    predictions, attention_weights = model(\n",
    "            input_sentence=encoder_input,\n",
    "            output_sentence=output, \n",
    "            training=False, \n",
    "            enc_padding_mask=enc_padding_mask, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            dec_padding_mask=dec_padding_mask\n",
    "    )\n",
    "\n",
    "    predictions = predictions[: ,-1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    return predicted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e72340fbd519ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:44:02.372729Z",
     "start_time": "2024-06-19T11:43:58.283188Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token: [[21906]]\n",
      "Predicted word: cardiologist\n"
     ]
    }
   ],
   "source": [
    "# Take a random sentence as an input\n",
    "input_document = tokenizer.texts_to_sequences([\"a random sentence\"])\n",
    "input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "# Take the start of sentence token as the only token in the output to predict the next word\n",
    "output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "\n",
    "# predict the next word with your function\n",
    "predicted_token = next_word(transformer, encoder_input, output)\n",
    "print(f\"Predicted token: {predicted_token}\")\n",
    "\n",
    "predicted_word = tokenizer.sequences_to_texts(predicted_token.numpy())[0]\n",
    "print(f\"Predicted word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2226e4c516674fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:47:43.566566Z",
     "start_time": "2024-06-19T11:47:43.547238Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(model, input_document):\n",
    "    \"\"\"\n",
    "    A function for summarization using the transformer model\n",
    "    Arguments:\n",
    "        input_document (tf.Tensor): Input data to summarize\n",
    "    Returns:\n",
    "        _ (str): The summary of the input_document\n",
    "    \"\"\"    \n",
    "    input_document = tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "    \n",
    "    output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        predicted_id = next_word(model, encoder_input, output)\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "        if predicted_id == tokenizer.word_index[\"[EOS]\"]:\n",
    "            break\n",
    "\n",
    "    return tokenizer.sequences_to_texts(output.numpy())[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24668113bf440947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:44:42.100594Z",
     "start_time": "2024-06-19T11:44:11.860057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set example:\n",
      "[SOS] amanda: i baked  cookies. do you want some?  jerry: sure!  amanda: i'll bring you tomorrow :-) [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
      "\n",
      "Model written summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[SOS] robe sapce 250cc crocheting foxx dean's roydon roydon fortnite autographs bergs sends leandra problem excesses attack josephs shuns bergs bergs  robe spotlight menaces icons dean's britanny prefere chelsea's bundle pushy peter's 110 giant giant barbuda vagabond roydon mobolity buttered want mendy would aggreements peter's freaked romaine yaaaaa hr stuation\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "summarize(transformer, document[training_set_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59907254dad6489f",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e0e3b4f69c8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:55:15.641477Z",
     "start_time": "2024-06-19T11:48:41.949430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 7.885031\n",
      "Time taken for one epoch: 203.08125686645508 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [SOS] and and [EOS]\n",
      "\n",
      "Epoch 2, Loss 6.571231\n",
      "Time taken for one epoch: 183.90123009681702 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] is going to the new the new new new new new new new new the new new new the new [EOS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take an example from the test set, to monitor it during training\n",
    "test_example = 0\n",
    "true_summary = summary_test[test_example]\n",
    "true_document = document_test[test_example]\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_loss.reset_state()\n",
    "    number_of_batches=len(list(enumerate(dataset)))\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        print(f'Epoch {epoch+1}, Batch {batch+1}/{number_of_batches}', end='\\r')\n",
    "        train_step(transformer, inp, tar)\n",
    "    \n",
    "    print (f'Epoch {epoch+1}, Loss {train_loss.result():.4f}')\n",
    "    losses.append(train_loss.result())\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "    print('Example summarization on the test set:')\n",
    "    print('  True summarization:')\n",
    "    print(f'    {true_summary}')\n",
    "    print('  Predicted summarization:')\n",
    "    print(f'    {summarize(transformer, true_document)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf8becfccb6a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:55:15.920318Z",
     "start_time": "2024-06-19T11:55:15.660858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12bf3103ada365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:55:26.954289Z",
     "start_time": "2024-06-19T11:55:24.016773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set example:\n",
      "[SOS] amanda: i baked  cookies. do you want some?  jerry: sure!  amanda: i'll bring you tomorrow :-) [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
      "\n",
      "Model written summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOS] is going to the new the new [EOS]\n"
     ]
    }
   ],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document[training_set_example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508e25cba34857a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:55:35.725804Z",
     "start_time": "2024-06-19T11:55:28.892745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set example:\n",
      "[SOS] will: hey babe, what do you want for dinner tonight?  emma:  gah, don't even worry about it tonight  will: what do you mean? everything ok?  emma: not really, but it's ok, don't worry about cooking though, i'm not hungry  will: well what time will you be home?  emma: soon, hopefully  will: you sure? maybe you want me to pick you up?  emma: no no it's alright. i'll be home soon, i'll tell you when i get home.   will: alright, love you.   emma: love you too.  [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] emma will be home soon and she will let will know. [EOS]\n",
      "\n",
      "Model written summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOS] is going to the new the new the new new new the new new the new new the new the new [EOS]\n"
     ]
    }
   ],
   "source": [
    "test_set_example = 3\n",
    "\n",
    "# Check a summary of a document from the test set\n",
    "print('Test set example:')\n",
    "print(document_test[test_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary_test[test_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document_test[test_set_example]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee199f20956fa0e",
   "metadata": {},
   "source": [
    "If you critically examine the output of the model, you can notice a few things:\n",
    " - In the training set the model output is (almost) identical to the real output (already after 20 epochs and even more so with more epochs). This might be because the training set is relatively small and the model is relatively big and has thus learned the sentences in the training set by heart (overfitting).\n",
    " - While the performance on the training set looks amazing, it is not so good on the test set. The model overfits, but fails to generalize. Again an easy candidate to blame is the small training set and a comparatively large model, but there might be a variety of other factors.\n",
    " - Look at the test set example 3 and its summarization. Would you summarize it the same way as it is written here? Sometimes the data may be ambiguous. And the training of **your model can only be as good as your data**.\n",
    "\n",
    "Here you only use a small dataset, to show that something can be learned in a reasonable amount of time in a relatively small environment. Generally, large transformers are trained on more than one task and on very large quantities of data to achieve superb performance. You will learn more about this in the rest of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e75efb3e3fff8",
   "metadata": {},
   "source": [
    "# 3. Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb8949810a3f0f",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1747bd90f3e0f3",
   "metadata": {},
   "source": [
    "Podivame se na dva modely - BERT, T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f459da5e33cbf",
   "metadata": {},
   "source": [
    "Question-Answering se da zhruba rozdelit na dva typy:\n",
    "- context-based\n",
    "- closed book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2ffd2",
   "metadata": {},
   "source": [
    "T5 is learnt on C4 dataset = Colosal Cleaned Crawled Corpus (800 GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a10ad488d64abb",
   "metadata": {},
   "source": [
    "1. Transfer learning comes in two basic forms:\n",
    "- feature based -> you learn word embeddings by training one model and then you use those word embeddings in a \n",
    "different model on a different task. \n",
    "- fune-tuning -> you can use the exact same model and just run it on a different task. Sometimes when fine tuning, \n",
    "you can keep the model weights fixed and just add a new layer that you will train. Other times you can slowly \n",
    "unfreeze the layers one at a time.  \n",
    "\n",
    "2. Pretrained data -> Model\n",
    "- labeled\n",
    "- unlabled\n",
    "\n",
    "3. Pretraining task\n",
    "- language modeling\n",
    "    - masked words\n",
    "        -  next sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967cd164dd0b502",
   "metadata": {},
   "source": [
    "General purpose learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbff4296da7a64",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/feature_vs_funetune.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84794d8a3cff82bd",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/self_supervise_tasks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61522a2c557950",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f04459565d564f",
   "metadata": {},
   "source": [
    "There are two steps in the BERT framework: pre-training and fine-tuning. During pre-training, the model is trained on unlabeled data over different pre-training tasks.  For fine tuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks. \n",
    "\n",
    "During pretraining:\n",
    "\n",
    "* Choose 15% of the tokens at random: mask them 80% of the time, replace them with a random token 10% of the time, or\n",
    " keep as is 10% of the time.   \n",
    "* There could be multiple masked spans in a sentence\n",
    "* Next sentence prediction is also used when pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fffaa5286f54f0",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/bert_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9c875d69f288",
   "metadata": {},
   "source": [
    "The input embeddings are the sum of the token embeddings, the segmentation embeddings and the position embeddings.\n",
    "\n",
    "**The input embeddings**: you have a [CLS] token to indicate the beginning of the sentence and a [SEP] to indicate the \n",
    "end \n",
    "of the sentence\n",
    "\n",
    "**The segment embeddings**: allows you to indicate whether it is sentence a or b.\n",
    "\n",
    "**Positional embeddings**: allows you to indicate the word's position in the sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4617c43dc2c9a",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/bert_input_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9b6544d492b33",
   "metadata": {},
   "source": [
    "The C token in the image above could be used for classification purposes. The unlabeled sentence A/B pair will depend\n",
    " on what you are trying to predict, it could range from question answering to sentiment. (in which case the second \n",
    " sentence could be just empty). The BERT objective is defined as follows:   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95be59b7332835",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/bert_objective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e555e9412a6d9f7",
   "metadata": {},
   "source": [
    "Pekny clanek na mediu: [Understanding BERT](https://medium.com/dissecting-bert/dissecting-bert-part2-335ff2ed9c73)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f21560176eb624",
   "metadata": {},
   "source": [
    "### Fine-tune BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e750e3a3ffea3",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/fine_tune_bert_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff9b0e24106154",
   "metadata": {},
   "source": [
    "Once you have a pre-trained model, you can fine tune it on different tasks. For example, given a hypothesis, you can\n",
    " identify the premise. Given a question, you can find the answer. You can also use it for named entity recognition, \n",
    " paraphrasing sentences, sequence tagging, classification and many more tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac80e9d8ff72b1b",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/fine_tune_bert_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b60845fb7cf7f3",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/fine_tune_bert_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a0437ce7b9ce8",
   "metadata": {},
   "source": [
    "### T5 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0ecb4e15cb74",
   "metadata": {},
   "source": [
    "T5 je multitask model, ktery se da pouzit pro nekolik ruznych uloh. Napriklad:\n",
    "* Text-to-text\n",
    "* Classification\n",
    "* Q&A\n",
    "* Machine Translation\n",
    "* Summarization\n",
    "* Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a392ae532bda4c",
   "metadata": {},
   "source": [
    "One of the major techniques that allowed the T5 model to reach state of the art is the concept of masking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0fd8322f6cf51",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_arch_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993e484c5cad91f",
   "metadata": {},
   "source": [
    "For example, you represent the for inviting with <X> and last with <Y> then the model predicts what the X should be\n",
    " and what the Y should be. This is exactly what we saw in the BERT loss. You can also mask out a few positions, not \n",
    " just one. The loss is only on the mask for BERT, for T5 it is on the target.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d08178b262bacb",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_arch_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81963aa6a1e5fc15",
   "metadata": {},
   "source": [
    "So we start with the basic encoder-decoder representation.  There you have a fully visible attention in the encoder \n",
    "and then causal attention in the decoder.  So light gray lines correspond to causal masking. And dark gray lines \n",
    "correspond to the fully visible masking.   \n",
    "\n",
    "In the middle we have the language model which consists of a single transformer layer stack. And it's being fed the \n",
    "concatenation of the inputs and the target. So it uses causal masking throughout as you can see because they're all \n",
    "gray lines. And you have X1 going inside, you get X2, X2 goes into the model and you get X3 and so forth.   \n",
    "\n",
    "To the right, we have prefix language model which corresponds to allowing fully visible masking over the inputs as \n",
    "you can see with the dark arrows. And then causal masking in the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dad653a3156cc",
   "metadata": {},
   "source": [
    "### Multi-task Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cabe957e0988b01",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_train_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dbfd35f04f3c2",
   "metadata": {},
   "source": [
    "You can see that you only have to add a small prefix to the input and the model as a result will solve the task for \n",
    "you. There are many tasks that the t5 model can do for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904ba4e77b80bca",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_train_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87767ee3eb589cc1",
   "metadata": {},
   "source": [
    "It is possible to formulate most NLP tasks in a text-to-text format  that is, a task where the model is fed some \n",
    "text for context or conditioning and is then asked to produce some output text. This framework provides a consistent \n",
    "training objective both for pre-training and fine-tuning. Specifically, the model is trained with a maximum \n",
    "likelihood objective (using teacher forcing ) regardless of the task.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ce385be6cd3bd",
   "metadata": {},
   "source": [
    "**Training data strategies**\n",
    "\n",
    "**Examples-proportional mixing**: sample in proportion to the size of each tasks dataset\n",
    "\n",
    "**Temperature scaled mixing**: adjust the temperature of the mixing rates. This temperature parameter allows you to \n",
    "weight certain examples more than others. To implement temperature scaling with temperature T, we raise each tasks \n",
    "mixing rate rm to the power of 1T and renormalize the rates so that they sum to 1. When T = 1, this approach is \n",
    "equivalent to examples-proportional mixing and as T increases the proportions become closer to equal mixing   \n",
    "\n",
    "**Equal mixing**: In this case, you sample examples from each task with equal probability. Specifically, each example\n",
    " in \n",
    "each batch is sampled uniformly at random from one of the datasets you train on. \n",
    "\n",
    "**Fine tuning example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29deb5cbb4e4420b",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_train_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181aae18963bd4d",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_train_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64293fa8cebbf54e",
   "metadata": {},
   "source": [
    "![Seq2Seq](../pomocne_soubory/t5_train_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff09f79528decc",
   "metadata": {},
   "source": [
    "### LAB: SentencePiece and BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad492d1746a4ce",
   "metadata": {},
   "source": [
    "#### Introduction to Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cd05216892b2",
   "metadata": {},
   "source": [
    "In order to process text in neural network models it is first required to **encode** text as numbers with ids, since \n",
    "the tensor operations act on numbers. Finally, if the output of the network is to be words, it is required to \n",
    "**decode** the predicted tokens ids back to text.  \n",
    "\n",
    "To encode text, the first decision that has to be made is to what level of granularity are we going to consider the \n",
    "text? Because ultimately, from these **tokens**, features are going to be created about them. Many different \n",
    "experiments have been carried out using *words*, *morphological units*, *phonemic units* or *characters* as tokens. \n",
    "For example,    \n",
    "\n",
    "- Tokens are tricky. (raw text)\n",
    "- Tokens are tricky . ([words](https://arxiv.org/pdf/1301.3781))\n",
    "- Token s _ are _ trick _ y . ([morphemes](https://arxiv.org/pdf/1907.02423.pdf))\n",
    "- t o k  n z _  _ t r  k i. ([phonemes](https://www.aclweb.org/anthology/W18-5812.pdf), for STT)\n",
    "- T o k e n s _ a r e _ t r i c k y . ([character](https://www.aclweb.org/anthology/C18-1139/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4c6ae1a668265",
   "metadata": {},
   "source": [
    "But how to identify these units, such as words, is largely determined by the language they come from. For example, in\n",
    " many European languages a space is used to separate words, while in some Asian languages there are no spaces between\n",
    "  words. Compare English and Mandarin.  \n",
    "\n",
    "- Tokens are tricky. (original sentence)\n",
    "-  (Mandarin)\n",
    "- Bioj hn jshu (pinyin)\n",
    "-    (Mandarin with spaces)\n",
    "\n",
    "\n",
    "So, the ability to **tokenize**, i.e. split text into meaningful fundamental units, is not always straight-forward.\n",
    "\n",
    "Also, there are practical issues of how large our *vocabulary* of words, `vocab_size`, should be, considering memory \n",
    "limitations vs. coverage. A compromise may be need to be made between:  \n",
    "* the finest-grained models employing characters which can be memory intensive and \n",
    "* more computationally efficient *subword* units such as [n-grams](https://arxiv.org/pdf/1712.09405) or larger units.\n",
    "\n",
    "In [SentencePiece](https://www.aclweb.org/anthology/D18-2012.pdf) unicode characters are grouped together using \n",
    "either a [unigram language model](https://www.aclweb.org/anthology/P18-1007.pdf) (used in this week's assignment) or \n",
    "[BPE](https://arxiv.org/pdf/1508.07909.pdf), **byte-pair encoding**. We will discuss BPE, since BERT and many of its \n",
    "variants use a modified version of BPE and its pseudocode is easy to implement and understand... hopefully!   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8ac09ac18d597",
   "metadata": {},
   "source": [
    "#### SentencePiece Preprocessing\n",
    "##### NFKC Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d581e2754a1df",
   "metadata": {},
   "source": [
    "Unsurprisingly, even using unicode to initially tokenize text can be ambiguous, e.g., "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d90f5959516f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:41.074648Z",
     "start_time": "2024-07-14T10:18:41.069927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = e : False\n"
     ]
    }
   ],
   "source": [
    "eaccent = '\\u00E9'\n",
    "e_accent = '\\u0065\\u0301'\n",
    "print(f'{eaccent} = {e_accent} : {eaccent == e_accent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de8c1a76379ca7",
   "metadata": {},
   "source": [
    "SentencePiece uses the Unicode standard normalization form, [NFKC](https://en.wikipedia.org/wiki/Unicode_equivalence)\n",
    ", so this isn't an issue. Looking at the example from above but with normalization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7950234c65c05a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:41.380856Z",
     "start_time": "2024-07-14T10:18:41.374850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =  : True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "norm_eaccent = normalize('NFKC', '\\u00E9')\n",
    "norm_e_accent = normalize('NFKC', '\\u0065\\u0301')\n",
    "print(f'{norm_eaccent} = {norm_e_accent} : {norm_eaccent == norm_e_accent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e909bd2795de4",
   "metadata": {},
   "source": [
    "Normalization has actually changed the unicode code point (unicode unique id) for one of these two characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b25f455666eda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:42.083106Z",
     "start_time": "2024-07-14T10:18:42.080366Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hex_encoding(s):\n",
    "    return ' '.join(hex(ord(c)) for c in s)\n",
    "\n",
    "def print_string_and_encoding(s):\n",
    "    print(f'{s} : {get_hex_encoding(s)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5b0d2eb43e70002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:43.160680Z",
     "start_time": "2024-07-14T10:18:43.158444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : 0xe9\n",
      "e : 0x65 0x301\n",
      " : 0xe9\n",
      " : 0xe9\n"
     ]
    }
   ],
   "source": [
    "for s in [eaccent, e_accent, norm_eaccent, norm_e_accent]:\n",
    "    print_string_and_encoding(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04a4a7cefdb2f9",
   "metadata": {},
   "source": [
    "This normalization has other side effects which may be considered useful such as converting curly quotes &ldquo; to \"\n",
    " their ASCII equivalent. (<sup>*</sup>Although we *now* lose directionality of the quote...) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5d38c0faf7c6",
   "metadata": {},
   "source": [
    "##### Lossless Tokenization\n",
    "\n",
    "SentencePiece also ensures that when you tokenize your data and detokenize your data the original position of white \n",
    "space is preserved. However, tabs and newlines are converted to spaces. \n",
    "\n",
    "To ensure this **lossless tokenization**, SentencePiece replaces white space with _ (U+2581). So that a simple join \n",
    "of the tokens by replacing underscores with spaces can restore the white space, even if there are consecutive symbols\n",
    ". But remember first to normalize and then replace spaces with _ (U+2581).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f093df87d83af52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:44.128435Z",
     "start_time": "2024-07-14T10:18:44.126409Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 'Tokenization is hard.'\n",
    "sn = normalize('NFKC', s)\n",
    "sn_ = sn.replace(' ', '\\u2581')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50249f6b47d681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:44.832619Z",
     "start_time": "2024-07-14T10:18:44.829145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x54 0x6f 0x6b 0x65 0x6e 0x69 0x7a 0x61 0x74 0x69 0x6f 0x6e 0x20 0x69 0x73 0x20 0x68 0x61 0x72 0x64 0x2e\n",
      "0x54 0x6f 0x6b 0x65 0x6e 0x69 0x7a 0x61 0x74 0x69 0x6f 0x6e 0x20 0x69 0x73 0x20 0x68 0x61 0x72 0x64 0x2e\n",
      "0x54 0x6f 0x6b 0x65 0x6e 0x69 0x7a 0x61 0x74 0x69 0x6f 0x6e 0x2581 0x69 0x73 0x2581 0x68 0x61 0x72 0x64 0x2e\n"
     ]
    }
   ],
   "source": [
    "print(get_hex_encoding(s))\n",
    "print(get_hex_encoding(sn))\n",
    "print(get_hex_encoding(sn_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b716dc68c4b44b4",
   "metadata": {},
   "source": [
    "#### BPE Algorithm\n",
    "\n",
    "After discussing the preprocessing that SentencePiece performs, you will get the data, preprocess it, and apply the \n",
    "BPE algorithm. You will see how this reproduces the tokenization produced by training SentencePiece on the example \n",
    "dataset (from this week's assignment).  \n",
    "\n",
    "##### Preparing our Data\n",
    "First, you get the Squad data and process it as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2f42718312b686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:45.317100Z",
     "start_time": "2024-07-14T10:18:45.314323Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_json_examples_to_text(filepath):\n",
    "    example_jsons = list(map(ast.literal_eval, open(filepath))) # Read in the json from the example file\n",
    "    texts = [example_json['text'].decode('utf-8') for example_json in example_jsons] # Decode the byte sequences\n",
    "    text = '\\n\\n'.join(texts)       # Separate different articles by two newlines\n",
    "    text = normalize('NFKC', text)  # Normalize the text\n",
    "\n",
    "    with open('example.txt', 'w') as fw:\n",
    "        fw.write(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a792f28ab92ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:45.865053Z",
     "start_time": "2024-07-14T10:18:45.860396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
      "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
      "\n",
      "Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012.\n",
      "I've got a 500gb internal drive and a 240gb SSD.\n",
      "When trying to restore using di\n"
     ]
    }
   ],
   "source": [
    "text = convert_json_examples_to_text('./pomocne_soubory/bpe/data.txt')\n",
    "print(text[:900])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d4d2db3feb8c6",
   "metadata": {},
   "source": [
    "In the algorithm the `vocab` variable is actually a frequency dictionary of the words. Those words have been \n",
    "prepended with an *underscore* to indicate that they are the beginning of a word. Finally, the characters have been \n",
    "delimited by spaces so that the BPE algorithm can group the most common characters together in the dictionary in a \n",
    "greedy fashion. You will see how that is done shortly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0cd68984ee57c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:46.001282Z",
     "start_time": "2024-07-14T10:18:45.998469Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter(['\\u2581' + word for word in text.split()])\n",
    "vocab = {' '.join([l for l in word]): freq for word, freq in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8e8225ed0622af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:46.395589Z",
     "start_time": "2024-07-14T10:18:46.392629Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_vocab(vocab, end='\\n', limit=20):\n",
    "    \"\"\"Show word frequencys in vocab up to the limit number of words\"\"\"\n",
    "    shown = 0\n",
    "    for word, freq in vocab.items():\n",
    "        print(f'{word}: {freq}', end=end)\n",
    "        shown +=1\n",
    "        if shown > limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e47ab0e91d254d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:47.053110Z",
     "start_time": "2024-07-14T10:18:47.050770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " B e g i n n e r s: 1\n",
      " B B Q: 3\n",
      " C l a s s: 2\n",
      " T a k i n g: 1\n",
      " P l a c e: 1\n",
      " i n: 15\n",
      " M i s s o u l a !: 1\n",
      " D o: 1\n",
      " y o u: 13\n",
      " w a n t: 1\n",
      " t o: 33\n",
      " g e t: 2\n",
      " b e t t e r: 2\n",
      " a t: 1\n",
      " m a k i n g: 2\n",
      " d e l i c i o u s: 1\n",
      " B B Q ?: 1\n",
      " Y o u: 1\n",
      " w i l l: 6\n",
      " h a v e: 4\n",
      " t h e: 31\n"
     ]
    }
   ],
   "source": [
    "show_vocab(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8960767e41d3a",
   "metadata": {},
   "source": [
    "You check the size of the vocabulary (frequency dictionary) because this is the one hyperparameter that BPE depends \n",
    "on crucially on how far it breaks up a word into SentencePieces. It turns out that for your trained model on the \n",
    "small dataset that 60% of 455 merges of the most frequent characters need to be done to reproduce the upperlimit of a\n",
    " 32K `vocab_size` over the entire corpus of examples.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a79ac35a57f208a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:47.298725Z",
     "start_time": "2024-07-14T10:18:47.291208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 455\n",
      "Number of merges required to reproduce SentencePiece training on the whole corpus: 273\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of unique words: {len(vocab)}')\n",
    "print(f'Number of merges required to reproduce SentencePiece training on the whole corpus: {int(0.60*len(vocab))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ba030ed1a5c48",
   "metadata": {},
   "source": [
    "##### BPE Algorithm\n",
    "Directly from the BPE paper you have the following algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac63fff773d3dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:48.715317Z",
     "start_time": "2024-07-14T10:18:48.710492Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, collections\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "def get_sentence_piece_vocab(vocab, frac_merges=0.60):\n",
    "    sp_vocab = vocab.copy()\n",
    "    num_merges = int(len(sp_vocab)*frac_merges)\n",
    "    \n",
    "    for i in range(num_merges):\n",
    "        pairs = get_stats(sp_vocab)\n",
    "        best = max(pairs, key=pairs.get)\n",
    "        sp_vocab = merge_vocab(best, sp_vocab)\n",
    "\n",
    "    return sp_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca271300ca92cb",
   "metadata": {},
   "source": [
    "To understand what's going on first take a look at the third function `get_sentence_piece_vocab`. It takes in the \n",
    "current `vocab` word-frequency dictionary and the fraction, `frac_merges`, of the total `vocab_size` to merge \n",
    "characters in the words of the dictionary, `num_merges` times. Then for each *merge* operation it `get_stats` on how \n",
    "many of each pair of character sequences there are. It gets the most frequent *pair* of symbols as the `best` pair. \n",
    "Then it merges that pair of symbols (removes the space between them) in each word in the `vocab` that contains this \n",
    "`best` (= `pair`). Consequently, `merge_vocab` creates a new `vocab`, `v_out`. This process is repeated `num_merges` \n",
    "times and the result is the set of SentencePieces (keys of the final `sp_vocab`).      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c2b9c95c35f",
   "metadata": {},
   "source": [
    "##### Additional Discussion of BPE Algorithm\n",
    "\n",
    "Please feel free to skip the below if the above description was enough.\n",
    "\n",
    "In a little more detail you can see in `get_stats` you initially create a list of bigram (two character sequence) \n",
    "frequencies from the vocabulary. Later, this may include trigrams, quadgrams, etc. Note that the key of the `pairs` \n",
    "frequency dictionary is actually a 2-tuple, which is just shorthand notation for a pair.  \n",
    "\n",
    "In `merge_vocab` you take in an individual `pair` (of character sequences, note this is the most frequency `best` \n",
    "pair) and the current `vocab` as `v_in`. You create a new `vocab`, `v_out`, from the old by joining together the \n",
    "characters in the pair (removing the space), if they are present in a word of the dictionary.  \n",
    "\n",
    "[Warning](https://regex101.com/): the expression `(?<!\\S)` means that either a whitespace character follows before \n",
    "the `bigram` or there is nothing before the bigram (it is the beginning of the word), similarly for `(?!\\S)` for \n",
    "preceding whitespace or the end of the word.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d951de972fe5ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:50.867293Z",
     "start_time": "2024-07-14T10:18:50.677191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B e g in n ers: 1\n",
      "BBQ: 3\n",
      "Cl ass: 2\n",
      "T ak ing: 1\n",
      "P la ce: 1\n",
      "in: 15\n",
      "M is s ou la !: 1\n",
      "D o: 1\n",
      "you: 13\n",
      "w an t: 1\n",
      "to: 33\n",
      "g et: 2\n",
      "be t ter: 2\n",
      "a t: 1\n",
      "mak ing: 2\n",
      "d e l ic i ou s: 1\n",
      "BBQ ?: 1\n",
      " Y ou: 1\n",
      "will: 6\n",
      "have: 4\n",
      "the: 31\n"
     ]
    }
   ],
   "source": [
    "sp_vocab = get_sentence_piece_vocab(vocab)\n",
    "show_vocab(sp_vocab) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2353d2212bca81c",
   "metadata": {},
   "source": [
    "#### Train SentencePiece BPE Tokenizer on Example Data\n",
    "##### Explore SentencePiece Model\n",
    "First, explore the SentencePiece model provided with this week's assignment. Remember you can always use Python's \n",
    "built in `help` command to see the documentation for any object or method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b85743b069ad077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:51.791214Z",
     "start_time": "2024-07-14T10:18:51.762189Z"
    }
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='./pomocne_soubory/bpe/sentencepiece.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c258047c6e9d60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:52.248996Z",
     "start_time": "2024-07-14T10:18:52.232487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SentencePieceProcessor in module sentencepiece object:\n",
      "\n",
      "class SentencePieceProcessor(builtins.object)\n",
      " |  SentencePieceProcessor(model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  CalculateEntropy(self, input, alpha, num_threads=None)\n",
      " |      Calculate sentence entropy\n",
      " |  \n",
      " |  Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |      Decode processed id or token sequences.\n",
      " |      \n",
      " |      Args:\n",
      " |        out_type: output type. str, bytes or 'serialized_proto' or 'immutable_proto' (Default = str)\n",
      " |        num_threads: the number of threads used in the batch processing (Default = -1).\n",
      " |  \n",
      " |  DecodeIds(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  DecodeIdsAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  DecodeIdsAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  DecodePieces(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  DecodePiecesAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  DecodePiecesAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  Detokenize = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |      Encode text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str.\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
      " |               reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      nbest_size: sampling parameters for unigram. Invalid in BPE-Dropout.\n",
      " |                  nbest_size = {0,1}: No sampling is performed.\n",
      " |                  nbest_size > 1: samples from the nbest_size results.\n",
      " |                  nbest_size < 0: assuming that nbest_size is infinite and samples\n",
      " |                  from the all hypothesis (lattice) using\n",
      " |                  forward-filtering-and-backward-sampling algorithm.\n",
      " |      alpha: Soothing parameter for unigram sampling, and merge probability for\n",
      " |             BPE-dropout (probablity 'p' in BPE-dropout paper).\n",
      " |      num_threads: the number of threads used in the batch processing (Default = -1).\n",
      " |  \n",
      " |  EncodeAsIds(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsImmutableProto(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsPieces(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsSerializedProto(self, input, **kwargs)\n",
      " |  \n",
      " |  GetPieceSize(self)\n",
      " |  \n",
      " |  GetScore = _batched_func(self, arg)\n",
      " |  \n",
      " |  IdToPiece = _batched_func(self, arg)\n",
      " |  \n",
      " |  Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |      Initialzie sentencepieceProcessor.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_file: The sentencepiece model file path.\n",
      " |        model_proto: The sentencepiece model serialized proto.\n",
      " |        out_type: output type. int or str.\n",
      " |        add_bos: Add <s> to the result (Default = false)\n",
      " |        add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
      " |          reversing (if enabled).\n",
      " |        reverse: Reverses the tokenized sequence (Default = false)\n",
      " |        emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |        nbest_size: sampling parameters for unigram. Invalid in BPE-Dropout.\n",
      " |                    nbest_size = {0,1}: No sampling is performed.\n",
      " |                    nbest_size > 1: samples from the nbest_size results.\n",
      " |                    nbest_size < 0: assuming that nbest_size is infinite and samples\n",
      " |                      from the all hypothesis (lattice) using\n",
      " |                      forward-filtering-and-backward-sampling algorithm.\n",
      " |        alpha: Soothing parameter for unigram sampling, and dropout probability of\n",
      " |               merge operations for BPE-dropout.\n",
      " |        num_threads: number of threads in batch processing (Default = -1, auto-detected)\n",
      " |  \n",
      " |  IsByte = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsControl = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsUnknown = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsUnused = _batched_func(self, arg)\n",
      " |  \n",
      " |  Load(self, model_file=None, model_proto=None)\n",
      " |      Overwride SentencePieceProcessor.Load to support both model_file and model_proto.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_file: The sentencepiece model file path.\n",
      " |        model_proto: The sentencepiece model serialized proto. Either `model_file`\n",
      " |          or `model_proto` must be set.\n",
      " |  \n",
      " |  LoadFromFile(self, arg)\n",
      " |  \n",
      " |  LoadFromSerializedProto(self, serialized)\n",
      " |  \n",
      " |  LoadVocabulary(self, filename, threshold)\n",
      " |  \n",
      " |  NBestEncode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, nbest_size=None)\n",
      " |      NBestEncode text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str.\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      nbest_size: nbest size\n",
      " |  \n",
      " |  NBestEncodeAsIds(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsImmutableProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsPieces(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsSerializedProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  Normalize(self, input, with_offsets=None)\n",
      " |  \n",
      " |  OverrideNormalizerSpec(self, **kwargs)\n",
      " |  \n",
      " |  PieceToId = _batched_func(self, arg)\n",
      " |  \n",
      " |  ResetVocabulary(self)\n",
      " |  \n",
      " |  SampleEncodeAndScore(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, num_samples=None, alpha=None, wor=None, include_best=None)\n",
      " |      SampleEncodeAndScore text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str or 'serialized_proto' or 'immutable_proto'\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      num_samples: How many samples to return (Default = 1)\n",
      " |      alpha: inverse temperature for sampling\n",
      " |      wor: whether to sample without replacement (Default = false)\n",
      " |      include_best: whether to include the best tokenization, requires wor=True (Default = false)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsIds(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsImmutableProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsPieces(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsSerializedProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsIds(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsImmutableProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsPieces(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsSerializedProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SetDecodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  SetEncodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  SetVocabulary(self, valid_vocab)\n",
      " |  \n",
      " |  Tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  __getitem__(self, piece)\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__ = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __repr__ = _swig_repr(self)\n",
      " |  \n",
      " |  __setstate__(self, serialized_model_proto)\n",
      " |  \n",
      " |  bos_id(self)\n",
      " |  \n",
      " |  calculate_entropy = CalculateEntropy(self, input, alpha, num_threads=None)\n",
      " |  \n",
      " |  decode = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  decode_ids = DecodeIds(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  decode_ids_as_immutable_proto = DecodeIdsAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  decode_ids_as_serialized_proto = DecodeIdsAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  decode_pieces = DecodePieces(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  decode_pieces_as_immutable_proto = DecodePiecesAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  decode_pieces_as_serialized_proto = DecodePiecesAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  detokenize = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  encode = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  encode_as_ids = EncodeAsIds(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_immutable_proto = EncodeAsImmutableProto(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_pieces = EncodeAsPieces(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_serialized_proto = EncodeAsSerializedProto(self, input, **kwargs)\n",
      " |  \n",
      " |  eos_id(self)\n",
      " |  \n",
      " |  get_piece_size = GetPieceSize(self)\n",
      " |  \n",
      " |  get_score = _batched_func(self, arg)\n",
      " |  \n",
      " |  id_to_piece = _batched_func(self, arg)\n",
      " |  \n",
      " |  init = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  is_byte = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_control = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_unknown = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_unused = _batched_func(self, arg)\n",
      " |  \n",
      " |  load = Load(self, model_file=None, model_proto=None)\n",
      " |  \n",
      " |  load_from_file = LoadFromFile(self, arg)\n",
      " |  \n",
      " |  load_from_serialized_proto = LoadFromSerializedProto(self, serialized)\n",
      " |  \n",
      " |  load_vocabulary = LoadVocabulary(self, filename, threshold)\n",
      " |  \n",
      " |  nbest_encode = NBestEncode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, nbest_size=None)\n",
      " |  \n",
      " |  nbest_encode_as_ids = NBestEncodeAsIds(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_immutable_proto = NBestEncodeAsImmutableProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_pieces = NBestEncodeAsPieces(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_serialized_proto = NBestEncodeAsSerializedProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  normalize = Normalize(self, input, with_offsets=None)\n",
      " |  \n",
      " |  override_normalizer_spec = OverrideNormalizerSpec(self, **kwargs)\n",
      " |  \n",
      " |  pad_id(self)\n",
      " |  \n",
      " |  piece_size(self)\n",
      " |  \n",
      " |  piece_to_id = _batched_func(self, arg)\n",
      " |  \n",
      " |  reset_vocabulary = ResetVocabulary(self)\n",
      " |  \n",
      " |  sample_encode_and_score = SampleEncodeAndScore(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, num_samples=None, alpha=None, wor=None, include_best=None)\n",
      " |  \n",
      " |  sample_encode_and_score_as_ids = SampleEncodeAndScoreAsIds(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_immutable_proto = SampleEncodeAndScoreAsImmutableProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_pieces = SampleEncodeAndScoreAsPieces(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_serialized_proto = SampleEncodeAndScoreAsSerializedProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_ids = SampleEncodeAsIds(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_immutable_proto = SampleEncodeAsImmutableProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_pieces = SampleEncodeAsPieces(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_serialized_proto = SampleEncodeAsSerializedProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  serialized_model_proto(self)\n",
      " |  \n",
      " |  set_decode_extra_options = SetDecodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  set_encode_extra_options = SetEncodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  set_vocabulary = SetVocabulary(self, valid_vocab)\n",
      " |  \n",
      " |  tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  unk_id(self)\n",
      " |  \n",
      " |  vocab_size(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __swig_destroy__ = delete_SentencePieceProcessor(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  thisown\n",
      " |      The membership flag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641324c944c7752d",
   "metadata": {},
   "source": [
    "Try it out on the first sentence of the example text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f024b687d90015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:53.725561Z",
     "start_time": "2024-07-14T10:18:53.723594Z"
    }
   },
   "outputs": [],
   "source": [
    "s0 = 'Beginners BBQ Class Taking Place in Missoula!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c7449c769c6e52f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:54.065222Z",
     "start_time": "2024-07-14T10:18:54.062565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beginn', 'ers', 'BBQ', 'Class', '', 'Taking', 'Place', 'in', 'Miss', 'oul', 'a', '!']\n",
      "[12847, 277, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 9, 55]\n",
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Beginners\n"
     ]
    }
   ],
   "source": [
    "# encode: text => id\n",
    "print(sp.encode_as_pieces(s0))\n",
    "print(sp.encode_as_ids(s0))\n",
    "\n",
    "# decode: id => text\n",
    "print(sp.decode_pieces(sp.encode_as_pieces(s0)))\n",
    "print(sp.decode_ids([12847, 277]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d58e2088123363",
   "metadata": {},
   "source": [
    "Notice how SentencePiece breaks the words into seemingly odd parts, but you have seen something similar with BPE. But\n",
    " how close was the model trained on the whole corpus of examples with a `vocab_size` of 32,000 instead of 455? Here \n",
    " you can also test what happens to white space, like '\\n'.   \n",
    "\n",
    "But first note that SentencePiece encodes the SentencePieces, the tokens, and has reserved some of the ids as can be \n",
    "seen in this week's assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a5c01c6ee9b9681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:55.385397Z",
     "start_time": "2024-07-14T10:18:55.382854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece for ID 15068: BBQ\n",
      "ID for Sentence Piece BBQ: 15068\n",
      "ID for unknown text __MUST_BE_UNKNOWN__: 2\n"
     ]
    }
   ],
   "source": [
    "uid = 15068\n",
    "spiece = \"\\u2581BBQ\"\n",
    "unknown = \"__MUST_BE_UNKNOWN__\"\n",
    "\n",
    "# id <=> piece conversion\n",
    "print(f'SentencePiece for ID {uid}: {sp.id_to_piece(uid)}')\n",
    "print(f'ID for Sentence Piece {spiece}: {sp.piece_to_id(spiece)}')\n",
    "\n",
    "# returns 0 for unknown tokens (we can change the id for UNK)\n",
    "print(f'ID for unknown text {unknown}: {sp.piece_to_id(unknown)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d94d8d3b9af77740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:56.079060Z",
     "start_time": "2024-07-14T10:18:56.076808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of sentence id: -1\n",
      "Pad id: 0\n",
      "End of sentence id: 1\n",
      "Unknown id: 2\n",
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning of sentence id: {sp.bos_id()}')\n",
    "print(f'Pad id: {sp.pad_id()}')\n",
    "print(f'End of sentence id: {sp.eos_id()}')\n",
    "print(f'Unknown id: {sp.unk_id()}')\n",
    "print(f'Vocab size: {sp.vocab_size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf830eda1fd050a",
   "metadata": {},
   "source": [
    "You can also check what are the ids for the first part and last part of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "735b01e8642c23f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:18:57.684389Z",
     "start_time": "2024-07-14T10:18:57.680985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Id\tSentP\tControl?\n",
      "------------------------\n",
      "0\t<pad>\tTrue\n",
      "1\t</s>\tTrue\n",
      "2\t<unk>\tFalse\n",
      "3\t\tFalse\n",
      "4\tX\tFalse\n",
      "5\t.\tFalse\n",
      "6\t,\tFalse\n",
      "7\ts\tFalse\n",
      "8\tthe\tFalse\n",
      "9\ta\tFalse\n"
     ]
    }
   ],
   "source": [
    "print('\\nId\\tSentP\\tControl?')\n",
    "print('------------------------')\n",
    "# <unk>, <s>, </s> are defined by default. Their ids are (0, 1, 2)\n",
    "# <s> and </s> are defined as 'control' symbol.\n",
    "for uid in range(10):\n",
    "    print(uid, sp.id_to_piece(uid), sp.is_control(uid), sep='\\t')\n",
    "    \n",
    "# for uid in range(sp.vocab_size()-10,sp.vocab_size()):\n",
    "#     print(uid, sp.id_to_piece(uid), sp.is_control(uid), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b272547a23e4b97",
   "metadata": {},
   "source": [
    "##### Train SentencePiece BPE model with our example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ee135e931241b",
   "metadata": {},
   "source": [
    "Finally, train your own BPE model directly from the SentencePiece library and compare it to the results of the \n",
    "implemention of the algorithm from the BPE paper itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1369c505b6831d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:19:00.827603Z",
     "start_time": "2024-07-14T10:19:00.808844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** BPE ***\n",
      "['B', 'e', 'ginn', 'ers', 'BBQ', 'Cl', 'ass', 'T', 'ak', 'ing', 'P', 'la', 'ce', 'in', 'M', 'is', 's', 'ou', 'la', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=example.txt --model_prefix=example_bpe --vocab_size=450 --model_type=bpe\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: example.txt\n",
      "  input_format: \n",
      "  model_prefix: example_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 450\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:   \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: example.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 26 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=4533\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9559% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=73\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999559\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 26 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 26\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 455\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=20 all=732 active=658 piece=w\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=40 all=937 active=863 piece=ch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=60 all=1014 active=940 piece=u\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=80 all=1110 active=1036 piece=me\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=100 all=1166 active=1092 piece=la\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=0\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=120 all=1217 active=1042 piece=SD\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=140 all=1272 active=1097 piece=bu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=160 all=1288 active=1113 piece=site\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=180 all=1315 active=1140 piece=ter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=200 all=1330 active=1155 piece=asure\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=0\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=220 all=1339 active=1008 piece=ge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=240 all=1371 active=1040 piece=sh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=260 all=1384 active=1053 piece=cost\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=280 all=1391 active=1060 piece=de\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=300 all=1405 active=1074 piece=000\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=0\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=320 all=1427 active=1021 piece=GB\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=340 all=1438 active=1032 piece=last\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=360 all=1441 active=1035 piece=let\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: example_bpe.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: example_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=example.txt --model_prefix=example_bpe --vocab_size=450 --model_type=bpe')\n",
    "sp_bpe = spm.SentencePieceProcessor()\n",
    "sp_bpe.load('example_bpe.model')\n",
    "\n",
    "print('*** BPE ***')\n",
    "print(sp_bpe.encode_as_pieces(s0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "397833fc6d0d8b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:19:02.078425Z",
     "start_time": "2024-07-14T10:19:02.075472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B e g in n ers: 1, BBQ: 3, Cl ass: 2, T ak ing: 1, P la ce: 1, in: 15, M is s ou la !: 1, D o: 1, you: 13, w an t: 1, to: 33, g et: 2, be t ter: 2, a t: 1, mak ing: 2, d e l ic i ou s: 1, BBQ ?: 1,  Y ou: 1, will: 6, have: 4, the: 31, "
     ]
    }
   ],
   "source": [
    "show_vocab(sp_vocab, end = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fd7390b2b2ad9",
   "metadata": {},
   "source": [
    "The implementation of BPE's code from the paper matches up pretty well with the library itself! The differences are \n",
    "probably accounted for by the `vocab_size`. There is also another technical difference in that in the SentencePiece \n",
    "implementation of BPE a priority queue is used to more efficiently keep track of the *best pairs*. Actually, there is\n",
    " a priority queue in the Python standard library called `heapq` if you would like to give that a try below!    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c985173400fb8bf",
   "metadata": {},
   "source": [
    "#### Optionally try to implement BPE using a priority queue below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f0f0c9033ee4bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:19:03.556203Z",
     "start_time": "2024-07-14T10:19:03.554287Z"
    }
   },
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f504252e877d5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:19:04.108474Z",
     "start_time": "2024-07-14T10:19:04.105794Z"
    }
   },
   "outputs": [],
   "source": [
    "def heapsort(iterable):\n",
    "    h = []\n",
    "    for value in iterable:\n",
    "        heappush(h, value)\n",
    "    return [heappop(h) for i in range(len(h))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "746310774d6be162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:19:04.718726Z",
     "start_time": "2024-07-14T10:19:04.714949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 2, 3, 3, 4, 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,4,3,1,3,2,1,4,2]\n",
    "heapsort(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b8b5c9fca1b74",
   "metadata": {},
   "source": [
    "For a more extensive example consider looking at the [SentencePiece repo](https://github\n",
    ".com/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb). The last few sections of \n",
    "this code were repurposed from that tutorial. Thanks for your participation! Next stop BERT and T5!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46be1fe987f6cd3",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a678054bbaead1",
   "metadata": {},
   "source": [
    "### LAB: Question Answering with HuggingFace - Using a base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b55993ec9f95c",
   "metadata": {},
   "source": [
    "**Question Answering with BERT and HuggingFace**\n",
    "\n",
    "You've seen how to use BERT and other transformer models for a wide range of natural language tasks, including \n",
    "machine translation, summarization, and question answering. Transformers have become the standard model for NLP, \n",
    "similar to convolutional models in computer vision. And all started with Attention!  \n",
    "\n",
    "In practice, you'll rarely train a transformer model from scratch.  Transformers tend to be very large, so they take \n",
    "time, money, and lots of data to train fully. Instead, you'll want to start with a pre-trained model and fine-tune it\n",
    " with your dataset if you need to.  \n",
    "\n",
    "[Hugging Face](https://huggingface.co/) () is the best resource for pre-trained transformers. Their open-source \n",
    "libraries simplify downloading and using transformer models like BERT, T5, and GPT-2. And the best part, you can use \n",
    "them alongside either TensorFlow, PyTorch or Flax.  \n",
    "\n",
    "In this notebook, you'll use   transformers to use the DistilBERT model for question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525eb083ce40631d",
   "metadata": {},
   "source": [
    "#### Pipelines\n",
    "\n",
    "Before fine-tuning a model, you will look at the pipelines from Hugging Face to use pre-trained transformer models for specific tasks. The `transformers` library provides pipelines for popular tasks like sentiment analysis, summarization, and text generation. A pipeline consists of a tokenizer, a model, and the model configuration. All these are packaged together into an easy-to-use object. Hugging Face makes life easier.\n",
    "\n",
    "Pipelines are intended to be used without fine-tuning and will often be immediately helpful in your projects. For example, `transformers` provides a pipeline for [question answering](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.QuestionAnsweringPipeline) that you can directly use to answer your questions if you give some context. Let's see how to do just that.\n",
    "\n",
    "You will import `pipeline` from `transformers` for creating pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3573f22deaac389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:05.187873Z",
     "start_time": "2024-07-14T17:56:52.581014Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8899816c6840551",
   "metadata": {},
   "source": [
    "Now, you will create the pipeline for question-answering, which uses the [DistilBert](https://hf\n",
    ".co/distilbert-base-cased-distilled-squad) model for extractive question answering (i.e., answering questions with \n",
    "the exact wording provided in the context).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e5e8038a14888f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.170356Z",
     "start_time": "2024-07-14T17:57:05.189153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# The task \"question-answering\" will return a QuestionAnsweringPipeline object\n",
    "question_answerer = pipeline(task=\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae177caf761f9f9",
   "metadata": {},
   "source": [
    "Notice that this environment already has the model stored in the directory `distilbert-base-cased-distilled-squad`. \n",
    "However if you were to run that exact code on your local computer, Huggingface will download the model for you, which\n",
    " is a great feature!  \n",
    "\n",
    "\n",
    "After running the last cell, you have a pipeline for performing question answering given a context string. The \n",
    "pipeline `question_answerer` you just created needs you to pass the question and context as strings. It returns an \n",
    "answer to the question from the context you provided. For example, here are the first few paragraphs from the \n",
    "[Wikipedia entry for tea](https://en.wikipedia.org/wiki/Tea) that you will use as the context.   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242fd2916f367107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.174578Z",
     "start_time": "2024-07-14T17:57:06.171348Z"
    }
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Tea is an aromatic beverage prepared by pouring hot or boiling water over cured or fresh leaves of Camellia sinensis,\n",
    "an evergreen shrub native to China and East Asia. After water, it is the most widely consumed drink in the world.\n",
    "There are many different types of tea; some, like Chinese greens and Darjeeling, have a cooling, slightly bitter,\n",
    "and astringent flavour, while others have vastly different profiles that include sweet, nutty, floral, or grassy\n",
    "notes. Tea has a stimulating effect in humans primarily due to its caffeine content.\n",
    "\n",
    "The tea plant originated in the region encompassing today's Southwest China, Tibet, north Myanmar and Northeast India,\n",
    "where it was used as a medicinal drink by various ethnic groups. An early credible record of tea drinking dates to\n",
    "the 3rd century AD, in a medical text written by Hua Tuo. It was popularised as a recreational drink during the\n",
    "Chinese Tang dynasty, and tea drinking spread to other East Asian countries. Portuguese priests and merchants\n",
    "introduced it to Europe during the 16th century. During the 17th century, drinking tea became fashionable among the\n",
    "English, who started to plant tea on a large scale in India.\n",
    "\n",
    "The term herbal tea refers to drinks not made from Camellia sinensis: infusions of fruit, leaves, or other plant\n",
    "parts, such as steeps of rosehip, chamomile, or rooibos. These may be called tisanes or herbal infusions to prevent\n",
    "confusion with 'tea' made from the tea plant.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0fbda52f0da4a",
   "metadata": {},
   "source": [
    "Now, you can ask your model anything related to that passage. For instance, \"Where is tea native to?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f5d88861dd17d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.269197Z",
     "start_time": "2024-07-14T17:57:06.176477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China and East Asia\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Where is tea native to?\", context=context)\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1542a27e1b362",
   "metadata": {},
   "source": [
    "You can also pass multiple questions to your pipeline within a list so that you can ask:\n",
    "\n",
    "*   \"Where is tea native to?\"\n",
    "*   \"When was tea discovered?\"\n",
    "*   \"What is the species name for tea?\"\n",
    "\n",
    "at the same time, and your `question-answerer` will return all the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28313eaf52947f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.504588Z",
     "start_time": "2024-07-14T17:57:06.270068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is tea native to? \n",
      ">> China and East Asia\n",
      "When was tea discovered? \n",
      ">> 3rd century AD\n",
      "What is the species name for tea? \n",
      ">> Camellia sinensis\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Where is tea native to?\",\n",
    "             \"When was tea discovered?\",\n",
    "             \"What is the species name for tea?\"]\n",
    "\n",
    "results = question_answerer(question=questions, context=context)\n",
    "\n",
    "for q, r in zip(questions, results):\n",
    "    print(f\"{q} \\n>> {r['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90376110f7a0d8e3",
   "metadata": {},
   "source": [
    "Although the models used in the Hugging Face pipelines generally give outstanding results, sometimes you will have \n",
    "particular examples where they don't perform so well. Let's use the following example with a context string about the\n",
    " Golden Age of Comic Books:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2819d30d2524560e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.508749Z",
     "start_time": "2024-07-14T17:57:06.505558Z"
    }
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "The Golden Age of Comic Books describes an era of American comic books from the\n",
    "late 1930s to circa 1950. During this time, modern comic books were first published\n",
    "and rapidly increased in popularity. The superhero archetype was created and many\n",
    "well-known characters were introduced, including Superman, Batman, Captain Marvel\n",
    "(later known as SHAZAM!), Captain America, and Wonder Woman.\n",
    "Between 1939 and 1941 Detective Comics and its sister company, All-American Publications,\n",
    "introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash,\n",
    "Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman.[7] Timely Comics,\n",
    "the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch,\n",
    "the Sub-Mariner, and Captain America.[8]\n",
    "As comic books grew in popularity, publishers began launching titles that expanded\n",
    "into a variety of genres. Dell Comics' non-superhero characters (particularly the\n",
    "licensed Walt Disney animated-character comics) outsold the superhero comics of the day.[12]\n",
    "The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck,\n",
    "Roy Rogers and Tarzan.[13] It was during this era that noted Donald Duck writer-artist\n",
    "Carl Barks rose to prominence.[14] Additionally, MLJ's introduction of Archie Andrews\n",
    "in Pep Comics #22 (December 1941) gave rise to teen humor comics,[15] with the Archie\n",
    "Andrews character remaining in print well into the 21st century.[16]\n",
    "At the same time in Canada, American comic books were prohibited importation under\n",
    "the War Exchange Conservation Act[17] which restricted the importation of non-essential\n",
    "goods. As a result, a domestic publishing industry flourished during the duration\n",
    "of the war which were collectively informally called the Canadian Whites.\n",
    "The educational comic book Dagwood Splits the Atom used characters from the comic\n",
    "strip Blondie.[18] According to historian Michael A. Amundson, appealing comic-book\n",
    "characters helped ease young readers' fear of nuclear war and neutralize anxiety\n",
    "about the questions posed by atomic power.[19] It was during this period that long-running\n",
    "humor comics debuted, including EC's Mad and Carl Barks' Uncle Scrooge in Dell's Four\n",
    "Color Comics (both in 1952).[20][21]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7e41b702a74cb",
   "metadata": {},
   "source": [
    "Let's ask the following question: \"What popular superheroes were introduced between 1939 and 1941?\" The answer is in \n",
    "the fourth paragraph of the context string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9079c83809dcda15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:06.634275Z",
     "start_time": "2024-07-14T17:57:06.509432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teen humor comics\n"
     ]
    }
   ],
   "source": [
    "question = \"What popular superheroes were introduced between 1939 and 1941?\"\n",
    "\n",
    "result = question_answerer(question=question, context=context)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0879916c38c2169",
   "metadata": {},
   "source": [
    "Here, the answer should be:\n",
    "\"Batman and Robin, Wonder Woman, the Flash,\n",
    "Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow, and Aquaman\". Instead, the pipeline returned a different \n",
    "answer.  You can even try different question wordings: \n",
    "\n",
    "*   \"What superheroes were introduced between 1939 and 1941?\"\n",
    "*   \"What comic book characters were created between 1939 and 1941?\"\n",
    "*   \"What well-known characters were created between 1939 and 1941?\"\n",
    "*   \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"\n",
    "\n",
    "and you will only get incorrect answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41b29dacd84b63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:57:07.238941Z",
     "start_time": "2024-07-14T17:57:06.635089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What popular superheroes were introduced between 1939 and 1941? \n",
      ">> teen humor comics\n",
      "What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company? \n",
      ">> Archie Andrews\n",
      "What comic book characters were created between 1939 and 1941? \n",
      ">> Archie\n",
      "Andrews\n",
      "What well-known characters were created between 1939 and 1941? \n",
      ">> Archie\n",
      "Andrews\n",
      "What well-known superheroes were introduced between 1939 and 1941 by Detective Comics? \n",
      ">> Archie Andrews\n"
     ]
    }
   ],
   "source": [
    "questions = [\"What popular superheroes were introduced between 1939 and 1941?\",\n",
    "             \"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\",\n",
    "             \"What comic book characters were created between 1939 and 1941?\",\n",
    "             \"What well-known characters were created between 1939 and 1941?\",\n",
    "             \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"]\n",
    "\n",
    "results = question_answerer(question=questions, context=context)\n",
    "\n",
    "for q, r in zip(questions, results):\n",
    "    print(f\"{q} \\n>> {r['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4158f442a7bf13",
   "metadata": {},
   "source": [
    "It seems like this model is a **huge fan** of Archie Andrews. It even considers him a superhero!\n",
    "\n",
    "The example that fooled your `question_answerer` belongs to the [TyDi QA dataset](https://ai.google.com/research/tydiqa), a dataset from Google for question/answering in diverse languages. To achieve better results when you know that the pipeline isn't working as it should, you need to consider fine-tuning your model.\n",
    "\n",
    "In the next ungraded lab, you will get the chance to fine-tune the DistilBert model using the TyDi QA dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834440d83fe44d46",
   "metadata": {},
   "source": [
    "### LAB: Question Answering with BERT and HuggingFace  (Fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76447c4228fd9bfb",
   "metadata": {},
   "source": [
    "In the previous Hugging Face ungraded lab, you saw how to use the pipeline objects to use transformer models for NLP tasks. In that lab, the model didn't output the desired answers to a series of precise questions for a context related to the history of comic books.\n",
    "\n",
    "In this lab, you will fine-tune the model from that lab to give better answers for that type of context. To do that, you'll be using the [TyDi QA dataset](https://ai.google.com/research/tydiqa) but on a filtered version with only English examples. Additionally, you will use a lot of the tools that Hugging Face has to offer.\n",
    "\n",
    "You have to note that, in general, you will fine-tune general-purpose transformer models to work for specific tasks. However, fine-tuning a general-purpose model can take a lot of time. That's why you will be using the model from the question answering pipeline in this lab.\n",
    "\n",
    "Begin by importing some libraries and/or objects you will use throughout the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c96cc3353f098c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.800918Z",
     "start_time": "2024-07-15T09:01:45.688064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/hugging_face/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:37: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1790ec66dd9887b",
   "metadata": {},
   "source": [
    "#### Fine-tuning a BERT model\n",
    "\n",
    "As you saw in the previous lab, you can use these pipelines as they are. But sometimes, you'll need something more \n",
    "specific to your problem, or maybe you need it to perform better on your production data. In these cases, you'll need\n",
    " to fine-tune a model.  \n",
    "\n",
    "Here, you'll fine-tune a pre-trained DistilBERT model on the TyDi QA dataset.\n",
    "\n",
    "To fine-tune your model, you will leverage three components provided by Hugging Face:\n",
    "\n",
    "* Datasets: Library that contains some datasets and different metrics to evaluate the performance of your models.\n",
    "* Tokenizer: Object in charge of preprocessing your text to be given as input for the transformer models.\n",
    "* Transformers: Library with the pre-trained model checkpoints and the trainer object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665bdec8ed82ac7",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "To get the dataset to fine-tune your model, you will use [ Datasets](https://huggingface.co/docs/datasets/), a \n",
    "lightweight and extensible library to share and access datasets and evaluation metrics for NLP easily. You can \n",
    "download Hugging Face datasets directly using the `load_dataset` function from the `datasets` library.   \n",
    "\n",
    "Hugging Face `datasets` allows to load data in several formats, such as CSV, JSON, text files and even parquet. You \n",
    "can see more about the supported formats in the [documentation](https://huggingface.co/docs/datasets/loading) \n",
    "\n",
    "A common approach is to use `load_dataset` and get the full dataset but **for this lab you will use a filtered \n",
    "version containing only the English examples**, which is already saved in this environment. Since this filtered \n",
    "dataset is saved using the Apache Arrow format, you can read it by using the `load_from_disk` function.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cc0ead9e2229",
   "metadata": {},
   "source": [
    "Nasledujici slozka ma 1.5 GB, takze neni v GITu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb9468828dc2168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.857859Z",
     "start_time": "2024-07-15T09:01:52.814252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "        num_rows: 9211\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "        num_rows: 1031\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The path where the dataset is stored\n",
    "path = './pomocne_soubory/hugging_face/tydiqa_data/' \n",
    "\n",
    "#Load Dataset\n",
    "tydiqa_data = load_from_disk(path)\n",
    "\n",
    "tydiqa_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49421eec74b2e139",
   "metadata": {},
   "source": [
    "<a id='datasets_type'></a>\n",
    "You can check below that the type of the loaded dataset is a `datasets.arrow_dataset.Dataset`. This object type corresponds to an Apache Arrow Table that allows creating a hash table that contains the position in memory where data is stored instead of loading the complete dataset into memory. But you don't have to worry too much about that. It is just an efficient way to work with lots of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459b49e6046b07fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.860793Z",
     "start_time": "2024-07-15T09:01:52.858510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the object type for one of the elements in the dataset\n",
    "type(tydiqa_data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f089afeaec4394",
   "metadata": {},
   "source": [
    "You can also check the structure of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc3797eb5a70222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.864278Z",
     "start_time": "2024-07-15T09:01:52.862072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "    num_rows: 9211\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tydiqa_data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d8151cb671b3d",
   "metadata": {},
   "source": [
    "You can see that each example is like a dictionary object. This dataset consists of questions, contexts, and indices \n",
    "that point to the start and end position of the answer inside the context. You can access the index using the \n",
    "`annotations` key, which is a kind of dictionary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d696d1d6ac466412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.871495Z",
     "start_time": "2024-07-15T09:01:52.864874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What mental effects can a mother experience after childbirth?\n",
      "\n",
      "Context (truncated): \n",
      "\n",
      "Postpartum depression (PPD), also called postnatal depression, is a type of mood disorder associated with childbirth, which can affect both sexes.[1][3] Symptoms may include extreme sadness, low energy, anxiety, crying episodes, irritability, and changes in sleeping or eating patterns.[1] Onset is typically between one week and one month following childbirth.[1] PPD can also negatively affect the newborn child.[2]\n",
      "\n",
      "While the exact cause of PPD is unclear, the cause is believed to be a combination of physi ...\n",
      "\n",
      "Answer: Postpartum depression (PPD)\n"
     ]
    }
   ],
   "source": [
    "idx = 600\n",
    "\n",
    "# start index\n",
    "start_index = tydiqa_data['train'][idx]['annotations']['minimal_answers_start_byte'][0]\n",
    "\n",
    "# end index\n",
    "end_index = tydiqa_data['train'][idx]['annotations']['minimal_answers_end_byte'][0]\n",
    "\n",
    "print(f\"Question: {tydiqa_data['train'][idx]['question_text']}\")\n",
    "print(f\"\\nContext (truncated): {tydiqa_data['train'][idx]['document_plaintext'][0:512]} ...\")\n",
    "print(f\"\\nAnswer: {tydiqa_data['train'][idx]['document_plaintext'][start_index:end_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b2e2457fee41",
   "metadata": {},
   "source": [
    "The question answering model predicts a start and endpoint in the context to extract as the answer. That's why this \n",
    "NLP task is known as extractive question answering. \n",
    "\n",
    "To train your model, you need to pass start and endpoints as labels. So, you need to implement a function that \n",
    "extracts the start and end positions from the dataset. \n",
    "\n",
    "The dataset contains unanswerable questions. For these, the start and end indices for the answer are equal to `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39cbfcf40b6facc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.875848Z",
     "start_time": "2024-07-15T09:01:52.872099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage_answer_candidate_index': [12],\n",
       " 'minimal_answers_start_byte': [8525],\n",
       " 'minimal_answers_end_byte': [8530],\n",
       " 'yes_no_answer': ['NONE']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tydiqa_data['train'][2]['annotations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21525893b822b488",
   "metadata": {},
   "source": [
    "Now, you have to flatten the dataset to work with an object with a table structure instead of a dictionary structure.\n",
    " This step facilitates the pre-processing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6309e6ca4c9497f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.882115Z",
     "start_time": "2024-07-15T09:01:52.876514Z"
    }
   },
   "outputs": [],
   "source": [
    "#Flattening the datasets\n",
    "flattened_train_data = tydiqa_data['train'].flatten()\n",
    "flattened_test_data =  tydiqa_data['validation'].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b7eb50723ec77",
   "metadata": {},
   "source": [
    "Also, to make the training more straightforward and faster, we will extract a subset of the train and test datasets. \n",
    "For that purpose, we will use the Hugging Face Dataset object's method called `select()`. This method allows you to \n",
    "take some data points by their index. Here, you will select the first 3000 rows but you can play with the number of \n",
    "data points, however, consider that this will increase the training time.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9872072b5e58562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:52.887668Z",
     "start_time": "2024-07-15T09:01:52.882814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting a subset of the train dataset\n",
    "flattened_train_data = flattened_train_data.select(range(3000))\n",
    "\n",
    "# Selecting a subset of the test dataset\n",
    "flattened_test_data = flattened_test_data.select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f2bb659631561",
   "metadata": {},
   "source": [
    "#### Tokenizers\n",
    "\n",
    "Now, you will use the [tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html) object from \n",
    "Hugging Face. You can load a tokenizer using different methods. Here, you will retrieve it from the pipeline object \n",
    "you created in the previous Hugging Face lab. With this tokenizer, you can ensure that the tokens you get for the \n",
    "dataset will match the tokens used in the original DistilBERT implementation.   \n",
    "\n",
    "When loading a tokenizer with any method, you must pass the model checkpoint that you want to fine-tune. Here, you \n",
    "are using the`'distilbert-base-cased-distilled-squad'` checkpoint. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87745733e87a6392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:54.435893Z",
     "start_time": "2024-07-15T09:01:54.140722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the AutoTokenizer from the transformers library\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "# Define max length of sequences in the tokenizer\n",
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e3877b2afe771",
   "metadata": {},
   "source": [
    "Given the characteristics of the dataset and the question-answering task, you will need to add some steps to \n",
    "pre-process the data after the tokenization: \n",
    "\n",
    "1. When there is no answer to a question given a context, you will use the `CLS` token, a unique token used to \n",
    "represent the start of the sequence. \n",
    "\n",
    "2.  Tokenizers can split a given string into substrings, resulting in a subtoken for each substring, creating \n",
    "misalignment between the list of dataset tags and the labels generated by the tokenizer. Therefore, you will need to \n",
    "align the start and end indices with the tokens associated with the target answer word.  \n",
    "\n",
    "3. Finally, a tokenizer can truncate a very long sequence. So, if the start/end position of an answer is `None`, you \n",
    "will assume that it was truncated and assign the maximum length of the tokenizer to those positions. \n",
    "\n",
    "Those three steps are done within the `process_samples` function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb940c255befd25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:55.541835Z",
     "start_time": "2024-07-15T09:01:55.538124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Processing samples using the 3 steps described above\n",
    "def process_samples(sample):\n",
    "    tokenized_data = tokenizer(sample['document_plaintext'], \n",
    "                               sample['question_text'], truncation=\"only_first\", padding=\"max_length\")\n",
    "\n",
    "    input_ids = tokenized_data[\"input_ids\"]\n",
    "\n",
    "    # We will label impossible answers with the index of the CLS token.\n",
    "    cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "    # If no answers are given, set the cls_index as answer.\n",
    "    if sample[\"annotations.minimal_answers_start_byte\"][0] == -1:\n",
    "        start_position = cls_index\n",
    "        end_position = cls_index\n",
    "    else:\n",
    "        # Start/end character index of the answer in the text.\n",
    "        gold_text = sample[\"document_plaintext\"][sample['annotations.minimal_answers_start_byte'][0]:sample['annotations.minimal_answers_end_byte'][0]]\n",
    "        start_char = sample[\"annotations.minimal_answers_start_byte\"][0]\n",
    "        end_char = sample['annotations.minimal_answers_end_byte'][0] #start_char + len(gold_text)\n",
    "\n",
    "        # sometimes answers are off by a character or two  fix this\n",
    "        if sample['document_plaintext'][start_char-1:end_char-1] == gold_text:\n",
    "            start_char = start_char - 1\n",
    "            end_char = end_char - 1     # When the gold label is off by one character\n",
    "        elif sample['document_plaintext'][start_char-2:end_char-2] == gold_text:\n",
    "            start_char = start_char - 2\n",
    "            end_char = end_char - 2     # When the gold label is off by two characters\n",
    "\n",
    "        start_token = tokenized_data.char_to_token(start_char)\n",
    "        end_token = tokenized_data.char_to_token(end_char - 1)\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_token is None:\n",
    "            start_token = tokenizer.model_max_length\n",
    "        if end_token is None:\n",
    "            end_token = tokenizer.model_max_length\n",
    "\n",
    "        start_position = start_token\n",
    "        end_position = end_token\n",
    "\n",
    "    return {'input_ids': tokenized_data['input_ids'],\n",
    "          'attention_mask': tokenized_data['attention_mask'],\n",
    "          'start_positions': start_position,\n",
    "          'end_positions': end_position}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5780df76deba8e6",
   "metadata": {},
   "source": [
    "To apply the `process_samples` function defined above to the whole  dataset, you can use the `map` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cfa26d7744d4bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:01:58.697400Z",
     "start_time": "2024-07-15T09:01:58.683085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizing and processing the flattened dataset\n",
    "processed_train_data = flattened_train_data.map(process_samples)\n",
    "processed_test_data = flattened_test_data.map(process_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0283fb21b85df1",
   "metadata": {},
   "source": [
    "#### Transformers\n",
    "\n",
    "The last component of Hugging Face that is useful for fine-tuning a transformer corresponds to the pre-trained models\n",
    " you can access in multiple ways.  \n",
    "\n",
    "For this lab, you will use the same model from the question-answering pipeline that you loaded in the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65a668a7b27325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:02:47.185712Z",
     "start_time": "2024-07-15T09:02:46.345418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the AutoModelForQuestionAnswering for the pre-trained model. You will only fine tune the head of the model\n",
    "import torch\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\").to(torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609146c97147a02e",
   "metadata": {},
   "source": [
    "Now, you can take the necessary columns from the datasets to train/test and return them as Pytorch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5d151d5e59c895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:02:48.405404Z",
     "start_time": "2024-07-15T09:02:48.402077Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n",
    "\n",
    "processed_train_data.set_format(type='pt', columns=columns_to_return)\n",
    "processed_test_data.set_format(type='pt', columns=columns_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d699f63cda53bf9",
   "metadata": {},
   "source": [
    "Here, we give you the F1 score as a metric to evaluate your model's performance. We will use this metric for \n",
    "simplicity, although it is based on the start and end values predicted by the model. If you want to dig deeper on \n",
    "other metrics that can be used for a question and answering task, you can also check [this colab notebook resource]\n",
    "(https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/question_answering.ipynb) from \n",
    "the Hugging Face team.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34f3ad7c0b67c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:02:49.594973Z",
     "start_time": "2024-07-15T09:02:49.592582Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_f1_metrics(pred):\n",
    "    start_labels = pred.label_ids[0]\n",
    "    start_preds = pred.predictions[0].argmax(-1)\n",
    "    end_labels = pred.label_ids[1]\n",
    "    end_preds = pred.predictions[1].argmax(-1)\n",
    "\n",
    "    f1_start = f1_score(start_labels, start_preds, average='macro')\n",
    "    f1_end = f1_score(end_labels, end_preds, average='macro')\n",
    "\n",
    "    return {\n",
    "        'f1_start': f1_start,\n",
    "        'f1_end': f1_end,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef580ed7ad22a0b7",
   "metadata": {},
   "source": [
    "Now, you will use the Hugging Face [Trainer](https://huggingface.co/transformers/main_classes/trainer.html) to \n",
    "fine-tune your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900f9bf007d299e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:02:51.013652Z",
     "start_time": "2024-07-15T09:02:50.865317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='model_results',     # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=20,                 # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_steps=50,\n",
    "    no_cuda=True                        # TOHLE VYPNI NA NEJAKY LEPSI GRAFICE\n",
    ")\n",
    "\n",
    "# Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,                        # the instantiated  Transformers model to be trained\n",
    "    args=training_args,                 # training arguments, defined above\n",
    "    train_dataset=processed_train_data, # training dataset\n",
    "    eval_dataset=processed_test_data,   # evaluation dataset\n",
    "    compute_metrics=compute_f1_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2eea842d1a72f3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T22:17:47.056130Z",
     "start_time": "2024-07-14T22:17:47.054340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb30a3697ac6b5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:04:37.984305Z",
     "start_time": "2024-07-15T09:02:58.532134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.1029562950134277,\n",
       " 'eval_f1_start': 0.005229441106591534,\n",
       " 'eval_f1_end': 0.007564053983152126,\n",
       " 'eval_runtime': 99.434,\n",
       " 'eval_samples_per_second': 10.057,\n",
       " 'eval_steps_per_second': 1.257}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(processed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a896c45cfb62ad",
   "metadata": {},
   "source": [
    "#### Using your Fine-Tuned Model\n",
    "\n",
    "After training and evaluating your fine-tuned model, you can check its results for the same questions from the previous lab.\n",
    "\n",
    "For that, you will tell Pytorch to use your GPU or your CPU to run the model. Additionally, you will need to tokenize your input context and questions. Finally, you need to post-process the output results to transform them from tokens to human-readable strings using the `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f046b898b8a32944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:08:06.796578Z",
     "start_time": "2024-07-15T09:08:06.227829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\n",
      "Answer: Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman\n",
      "\n",
      "Question: What comic book characters were created between 1939 and 1941?\n",
      "Answer: Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman\n",
      "\n",
      "Question: What well-known characters were created between 1939 and 1941?\n",
      "Answer: Superman, Batman, Captain Marvel ( later known as SHAZAM! ), Captain America, and Wonder Woman\n",
      "\n",
      "Question: What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\n",
      "Answer: Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = r\"\"\"\n",
    "The Golden Age of Comic Books describes an era of American comic books from the\n",
    "late 1930s to circa 1950. During this time, modern comic books were first published\n",
    "and rapidly increased in popularity. The superhero archetype was created and many\n",
    "well-known characters were introduced, including Superman, Batman, Captain Marvel\n",
    "(later known as SHAZAM!), Captain America, and Wonder Woman.\n",
    "Between 1939 and 1941 Detective Comics and its sister company, All-American Publications,\n",
    "introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash,\n",
    "Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman.[7] Timely Comics,\n",
    "the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch,\n",
    "the Sub-Mariner, and Captain America.[8]\n",
    "As comic books grew in popularity, publishers began launching titles that expanded\n",
    "into a variety of genres. Dell Comics' non-superhero characters (particularly the\n",
    "licensed Walt Disney animated-character comics) outsold the superhero comics of the day.[12]\n",
    "The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck,\n",
    "Roy Rogers and Tarzan.[13] It was during this era that noted Donald Duck writer-artist\n",
    "Carl Barks rose to prominence.[14] Additionally, MLJ's introduction of Archie Andrews\n",
    "in Pep Comics #22 (December 1941) gave rise to teen humor comics,[15] with the Archie\n",
    "Andrews character remaining in print well into the 21st century.[16]\n",
    "At the same time in Canada, American comic books were prohibited importation under\n",
    "the War Exchange Conservation Act[17] which restricted the importation of non-essential\n",
    "goods. As a result, a domestic publishing industry flourished during the duration\n",
    "of the war which were collectively informally called the Canadian Whites.\n",
    "The educational comic book Dagwood Splits the Atom used characters from the comic\n",
    "strip Blondie.[18] According to historian Michael A. Amundson, appealing comic-book\n",
    "characters helped ease young readers' fear of nuclear war and neutralize anxiety\n",
    "about the questions posed by atomic power.[19] It was during this period that long-running\n",
    "humor comics debuted, including EC's Mad and Carl Barks' Uncle Scrooge in Dell's Four\n",
    "Color Comics (both in 1952).[20][21]\n",
    "\"\"\"\n",
    "\n",
    "questions = [\"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\",\n",
    "             \"What comic book characters were created between 1939 and 1941?\",\n",
    "             \"What well-known characters were created between 1939 and 1941?\",\n",
    "             \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, return_tensors=\"pt\")\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    inputs.to(\"cpu\")\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_model = model(**inputs)\n",
    "    \n",
    "    start_logits = answer_model['start_logits'].cpu().detach().numpy()\n",
    "\n",
    "    answer_start = np.argmax(start_logits)  \n",
    "    \n",
    "    end_logits = answer_model['end_logits'].cpu().detach().numpy()\n",
    "    \n",
    "    # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = np.argmax(end_logits) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fff6a6fa7ca900",
   "metadata": {},
   "source": [
    "By fine-tuning the model for only 3 epochs you can already see an improvement!\n",
    "\n",
    "You can compare those results with those obtained using the base model (without fine-tuning), as you did in the previous lab. As a reminder, here are those results:\n",
    "\n",
    "```\n",
    "What popular superheroes were introduced between 1939 and 1941?\n",
    ">> teen humor comics\n",
    "What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\n",
    ">> Archie Andrews\n",
    "What comic book characters were created between 1939 and 1941?\n",
    ">> Archie\n",
    "Andrews\n",
    "What well-known characters were created between 1939 and 1941?\n",
    ">> Archie\n",
    "Andrews\n",
    "What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\n",
    ">> Archie Andrews\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e64873da2215a",
   "metadata": {},
   "source": [
    "## LAB: Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da896e968eab514d",
   "metadata": {},
   "source": [
    "<a name='0-1'></a>\n",
    "#### Overview\n",
    "\n",
    "This assignment will be different from the two previous ones. Due to memory constraints of this environment and for the sake of time, your model will be trained with small datasets, so you won't get models that you could use in production but you will gain the necessary knowledge about how the Generative Language models are trained and used. Also you won't spend too much time with the architecture of the models but you will instead take a model that is pre-trained on a larger dataset and fine tune it to get better results.\n",
    "\n",
    "After completing this labs you will:\n",
    "* Understand how the C4 dataset is structured.\n",
    "* Pretrain a transformer model using a Masked Language Model.\n",
    "* Understand how the \"Text to Text Transfer from Transformers\" or T5 model works. \n",
    "* Fine tune the T5 model for Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5920dc33edb5c2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:28.677189Z",
     "start_time": "2024-07-15T16:04:25.735835Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "from termcolor import colored\n",
    "import string\n",
    "import textwrap\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "\n",
    "import pomocne_soubory.transformer_utils_attention \n",
    "import pomocne_soubory.utils_attention\n",
    "\n",
    "# Will come in handy later\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbecd9ee2ff1dd",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "#### 1 -  Prepare the data for pretraining T5 \n",
    "\n",
    "<a name='1-1'></a>\n",
    "##### 1.1 - Pre-Training Objective\n",
    "\n",
    "In the initial phase of training a T5 model for a Question Answering task, the pre-training process involves leveraging a masked language model (MLM) on a very large dataset, such as the C4 dataset. The objective is to allow the model to learn contextualized representations of words and phrases, fostering a deeper understanding of language semantics. To initiate pre-training, it is essential to employ the Transformer architecture, which forms the backbone of T5. The Transformer's self-attention mechanism enables the model to weigh different parts of the input sequence dynamically, capturing long-range dependencies effectively.\n",
    "\n",
    "Before delving into pre-training, thorough data preprocessing is crucial. The C4 dataset, a diverse and extensive collection of web pages, provides a rich source for language understanding tasks. The dataset needs to be tokenized into smaller units, such as subwords or words, to facilitate model input. Additionally, the text is often segmented into fixed-length sequences or batches, optimizing computational efficiency during training.\n",
    "\n",
    "For the masked language modeling objective, a percentage of the tokenized input is randomly masked, and the model is trained to predict the original content of these masked tokens. This process encourages the T5 model to grasp contextual relationships between words and phrases, enhancing its ability to generate coherent and contextually appropriate responses during downstream tasks like question answering.\n",
    "\n",
    "In summary, the pre-training of the T5 model involves utilizing the Transformer architecture on a sizable dataset like C4, coupled with meticulous data preprocessing to convert raw text into a format suitable for training. The incorporation of a masked language modeling objective ensures that the model learns robust contextual representations, laying a solid foundation for subsequent fine-tuning on specific tasks such as question answering.\n",
    "\n",
    "**Note:** The word \"mask\" will be used throughout this assignment in context of hiding/removing word(s)\n",
    "\n",
    "You will be implementing the Masked language model (MLM) as shown in the following image. \n",
    "\n",
    "<img src = \"pomocne_soubory/loss.png\" width=\"600\" height = \"400\">\n",
    "\n",
    "Assume you have the following text: <span style = \"color:blue\"> **Thank you <span style = \"color:red\">for inviting </span> me to your party <span style = \"color:red\">last</span>  week** </span> \n",
    "\n",
    "\n",
    "Now as input you will mask the words in red in the text: \n",
    "\n",
    "<span style = \"color:blue\"> **Input:**</span> Thank you  **X** me to your party **Y** week.\n",
    "\n",
    "<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**. \n",
    "\n",
    "**[EOS]** will be used to mark the end of the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72520d79fb7eb0",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "##### 1.2 - C4 Dataset\n",
    "\n",
    "The [C4 dataset](https://www.tensorflow.org/datasets/catalog/c4), also known as the Common Crawl C4 (Common Crawl \n",
    "Corpus C4), is a large-scale dataset of web pages collected by the [Common Crawl organization](https://commoncrawl\n",
    ".org/). It is commonly used for various natural language processing tasks and machine learning research. Each sample \n",
    "in the C4 dataset follows a consistent format, making it suitable for pretraining models like BERT. Here's a short \n",
    "explanation and description of the C4 dataset:    \n",
    "\n",
    "- Format: Each sample in the C4 dataset is represented as a JSON object, containing several key-value pairs.\n",
    "\n",
    "- Content: The 'text' field in each sample contains the actual text content extracted from web pages. This text often\n",
    " includes a wide range of topics and writing styles, making it diverse and suitable for training language models. \n",
    "\n",
    "- Metadata: The dataset includes metadata such as 'content-length,' 'content-type,' 'timestamp,' and 'url,' providing\n",
    " additional information about each web page. 'Content-length' specifies the length of the content, 'content-type' \n",
    " describes the type of content (e.g., 'text/plain'), 'timestamp' indicates when the web page was crawled, and 'url' \n",
    " provides the source URL of the web page.   \n",
    "\n",
    "- Applications: The C4 dataset is commonly used for training and fine-tuning large-scale language models, such as \n",
    "BERT. It serves as a valuable resource for tasks like text classification, named entity recognition, question \n",
    "answering, and more.  \n",
    "\n",
    "- Size: The C4 dataset is containing more than 800 GiB of text data, making it suitable for training models with \n",
    "billions of parameters. \n",
    "\n",
    "Run the cell below to see how the C4 dataset looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2caaa2f9c3e2567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:28.744937Z",
     "start_time": "2024-07-15T16:04:28.678261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example number 1: \n",
      "\n",
      "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'} \n",
      "\n",
      "example number 2: \n",
      "\n",
      "{'text': 'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.'} \n",
      "\n",
      "example number 3: \n",
      "\n",
      "{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.'} \n",
      "\n",
      "example number 4: \n",
      "\n",
      "{'text': \"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\"} \n",
      "\n",
      "example number 5: \n",
      "\n",
      "{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about whats included in the mill levy measure.'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load example jsons\n",
    "with open('pomocne_soubory/attention_files/c4-en-10k.jsonl', 'r') as file:\n",
    "    example_jsons = [json.loads(line.strip()) for line in file]\n",
    "\n",
    "# Printing the examples to see how the data looks like\n",
    "for i in range(5):\n",
    "    print(f'example number {i+1}: \\n\\n{example_jsons[i]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bbb192e2db0a8",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "##### 1.3 - Process C4\n",
    "\n",
    "For the purpose of pretaining the T5 model, you will only use the `content` of each entry. In the following code, you\n",
    " filter only the field `text` from all the entries in the dataset. This is the data that you will use to create the \n",
    " `inputs` and `targets` of your language model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad75e106672226a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:28.749481Z",
     "start_time": "2024-07-15T16:04:28.745874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
      "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n"
     ]
    }
   ],
   "source": [
    "# Grab text field from dictionary\n",
    "natural_language_texts = [example_json['text'] for example_json in example_jsons]\n",
    "\n",
    "# Print the first text example\n",
    "print(natural_language_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e03ca5a24c0238",
   "metadata": {},
   "source": [
    "<a name='1-4'></a>\n",
    "##### 1.4 - Decode to Natural Language\n",
    "\n",
    "The [SentencePieceTokenizer](https://www.tensorflow.org/text/api_docs/python/text/SentencepieceTokenizer), used in \n",
    "the code snippet, tokenizes text into subword units, enhancing handling of complex word structures, out-of-vocabulary\n",
    " words, and multilingual support. It simplifies preprocessing, ensures consistent tokenization, and seamlessly \n",
    " integrates with machine learning frameworks.   \n",
    "\n",
    "In this task, a SentencePiece model is loaded from a file, which is used to tokenize text into subwords represented \n",
    "by integer IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee62e2bdb191763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:28.786676Z",
     "start_time": "2024-07-15T16:04:28.751192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "# PAD, EOS = 0, 1\n",
    "with open(\"./pomocne_soubory/attention_files/sentencepiece.model\", \"rb\") as f:\n",
    "    pre_trained_tokenizer = f.read()\n",
    "    \n",
    "tokenizer = tf_text.SentencepieceTokenizer(pre_trained_tokenizer, out_type=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe43753907fbbff",
   "metadata": {},
   "source": [
    "In this tokenizer the string `</s>` is used as `EOS` token. By default, the tokenizer does not add the `EOS` to the \n",
    "end of each sentence, so you need to add it manually when required. Let's verify what id correspond to this token: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f94d4d877962d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:28.793822Z",
     "start_time": "2024-07-15T16:04:28.787591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS: 1\n"
     ]
    }
   ],
   "source": [
    "eos = tokenizer.string_to_id(\"</s>\").numpy()\n",
    "\n",
    "print(\"EOS: \" + str(eos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc7b0e4c09151a",
   "metadata": {},
   "source": [
    "This code shows the process of tokenizing individual words from a given text, in this case, the first entry of the \n",
    "dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0a8a98e4678792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:29.144864Z",
     "start_time": "2024-07-15T16:04:29.132656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t-->\tTokenization\n",
      "----------------------------------------\n",
      "Foil    \t-->\t[4452, 173]\n",
      "plaid   \t-->\t[30772]\n",
      "lycra   \t-->\t[3, 120, 2935]\n",
      "and     \t-->\t[11]\n",
      "spandex \t-->\t[8438, 26, 994]\n",
      "shortall\t-->\t[710, 1748]\n",
      "with    \t-->\t[28]\n",
      "metallic\t-->\t[18813]\n",
      "slinky  \t-->\t[3, 7, 4907, 63]\n",
      "insets. \t-->\t[16, 2244, 7, 5]\n",
      "Attached\t-->\t[28416, 15, 26]\n",
      "metallic\t-->\t[18813]\n",
      "elastic \t-->\t[15855]\n",
      "belt    \t-->\t[6782]\n",
      "with    \t-->\t[28]\n",
      "O-ring. \t-->\t[411, 18, 1007, 5]\n",
      "Headband\t-->\t[3642, 3348]\n",
      "included.\t-->\t[1285, 5]\n",
      "Great   \t-->\t[1651]\n",
      "hip     \t-->\t[5436]\n",
      "hop     \t-->\t[13652]\n",
      "or      \t-->\t[42]\n",
      "jazz    \t-->\t[9948]\n",
      "dance   \t-->\t[2595]\n",
      "costume.\t-->\t[11594, 5]\n",
      "Made    \t-->\t[6465]\n",
      "in      \t-->\t[16]\n",
      "the     \t-->\t[8]\n",
      "USA.    \t-->\t[2312, 5]\n"
     ]
    }
   ],
   "source": [
    "# printing the encoding of each word to see how subwords are tokenized\n",
    "tokenized_text = [(list(tokenizer.tokenize(word).numpy()), word) for word in natural_language_texts[2].split()]\n",
    "\n",
    "print(\"Word\\t\\t-->\\tTokenization\")\n",
    "print(\"-\"*40)\n",
    "for element in tokenized_text:\n",
    "    print(f\"{element[1]:<8}\\t-->\\t{element[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc399db514f2e9",
   "metadata": {},
   "source": [
    "And as usual, the library provides a function to turn numeric tokens into human readable text. Look how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b74da57b8ee910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:30.481223Z",
     "start_time": "2024-07-15T16:04:30.468014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized: [12847   277]\n",
      "detokenized: b'Beginners'\n"
     ]
    }
   ],
   "source": [
    "# We can see that detokenize successfully undoes the tokenization\n",
    "print(f\"tokenized: {tokenizer.tokenize('Beginners')}\\ndetokenized: {tokenizer.detokenize(tokenizer.tokenize('Beginners'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da318fc12e5ab7",
   "metadata": {},
   "source": [
    "As you can see above, you were able to take a piece of string and tokenize it. \n",
    "\n",
    "Now you will create `input` and `target` pairs that will allow you to train your model. T5 uses the ids at the end of\n",
    " the vocab file as sentinels. For example, it will replace:  \n",
    "   - `vocab_size - 1` by `<Z>`\n",
    "   - `vocab_size - 2` by `<Y>`\n",
    "   - and so forth. \n",
    "   \n",
    "It assigns every word a `chr`.\n",
    "\n",
    "The `pretty_decode` function below, which you will use in a bit, helps in handling the type when decoding. Take a \n",
    "look and try to understand what the function is doing. \n",
    "\n",
    "\n",
    "Notice that:\n",
    "```python\n",
    "string.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "```\n",
    "\n",
    "**NOTE:** Targets may have more than the 52 sentinels we replace, but this is just to give you an idea of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1601573ca326dcd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:31.872513Z",
     "start_time": "2024-07-15T16:04:31.869167Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentinels(tokenizer, display=False):\n",
    "    sentinels = {}\n",
    "    vocab_size = tokenizer.vocab_size(name=None)\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = tokenizer.detokenize([vocab_size - i]).numpy().decode(\"utf-8\")\n",
    "        \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'    \n",
    "    \n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "\n",
    "    return sentinels\n",
    "\n",
    "def pretty_decode(encoded_str_list, sentinels, tokenizer):\n",
    "    # If already a string, just do the replacements.\n",
    "    if tf.is_tensor(encoded_str_list) and encoded_str_list.dtype == tf.string:\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = tf.strings.regex_replace(encoded_str_list, token, char)\n",
    "        return encoded_str_list\n",
    "  \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(tokenizer.detokenize(encoded_str_list), sentinels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f1104f3e342dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:32.942692Z",
     "start_time": "2024-07-15T16:04:32.791643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentinel is <Z> and the decoded token is: Internaional\n",
      "The sentinel is <Y> and the decoded token is: erwachsene\n",
      "The sentinel is <X> and the decoded token is: Cushion\n",
      "The sentinel is <W> and the decoded token is: imunitar\n",
      "The sentinel is <V> and the decoded token is: Intellectual\n",
      "The sentinel is <U> and the decoded token is: traditi\n",
      "The sentinel is <T> and the decoded token is: disguise\n",
      "The sentinel is <S> and the decoded token is: exerce\n",
      "The sentinel is <R> and the decoded token is: nourishe\n",
      "The sentinel is <Q> and the decoded token is: predominant\n",
      "The sentinel is <P> and the decoded token is: amiti\n",
      "The sentinel is <O> and the decoded token is: erkennt\n",
      "The sentinel is <N> and the decoded token is: dimension\n",
      "The sentinel is <M> and the decoded token is: infrieur\n",
      "The sentinel is <L> and the decoded token is: refugi\n",
      "The sentinel is <K> and the decoded token is: cheddar\n",
      "The sentinel is <J> and the decoded token is: unterlieg\n",
      "The sentinel is <I> and the decoded token is: garanteaz\n",
      "The sentinel is <H> and the decoded token is: fcute\n",
      "The sentinel is <G> and the decoded token is: rglage\n",
      "The sentinel is <F> and the decoded token is: pedepse\n",
      "The sentinel is <E> and the decoded token is: Germain\n",
      "The sentinel is <D> and the decoded token is: distinctly\n",
      "The sentinel is <C> and the decoded token is: Schraub\n",
      "The sentinel is <B> and the decoded token is: emanat\n",
      "The sentinel is <A> and the decoded token is: trimestre\n",
      "The sentinel is <z> and the decoded token is: disrespect\n",
      "The sentinel is <y> and the decoded token is: Erasmus\n",
      "The sentinel is <x> and the decoded token is: Australia\n",
      "The sentinel is <w> and the decoded token is: permeabil\n",
      "The sentinel is <v> and the decoded token is: deseori\n",
      "The sentinel is <u> and the decoded token is: manipulated\n",
      "The sentinel is <t> and the decoded token is: suggr\n",
      "The sentinel is <s> and the decoded token is: corespund\n",
      "The sentinel is <r> and the decoded token is: nitro\n",
      "The sentinel is <q> and the decoded token is: oyons\n",
      "The sentinel is <p> and the decoded token is: Account\n",
      "The sentinel is <o> and the decoded token is: chan\n",
      "The sentinel is <n> and the decoded token is: laundering\n",
      "The sentinel is <m> and the decoded token is: genealogy\n",
      "The sentinel is <l> and the decoded token is: QuickBooks\n",
      "The sentinel is <k> and the decoded token is: constituted\n",
      "The sentinel is <j> and the decoded token is: Fertigung\n",
      "The sentinel is <i> and the decoded token is: goutte\n",
      "The sentinel is <h> and the decoded token is: regul\n",
      "The sentinel is <g> and the decoded token is: overwhelmingly\n",
      "The sentinel is <f> and the decoded token is: merg\n",
      "The sentinel is <e> and the decoded token is: broyeur\n",
      "The sentinel is <d> and the decoded token is: poveti\n",
      "The sentinel is <c> and the decoded token is: emulator\n",
      "The sentinel is <b> and the decoded token is: halloween\n",
      "The sentinel is <a> and the decoded token is: combustibil\n"
     ]
    }
   ],
   "source": [
    "sentinels = get_sentinels(tokenizer, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bf385065978d6",
   "metadata": {},
   "source": [
    "Now, let's use the `pretty_decode` function in the following sentence. Note that all the words listed as sentinels, \n",
    "will be replaced by the function with the corresponding sentinel. It could be a drawback of this method, but don't \n",
    "worry about it now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb8abded86706a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:33.140778Z",
     "start_time": "2024-07-15T16:04:33.123534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'I want to dress up as an <V> this <b>.'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(tf.constant(\"I want to dress up as an Intellectual this halloween.\"), sentinels, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a77bf09530a6e3a",
   "metadata": {},
   "source": [
    "The functions above make your `inputs` and `targets` more readable. For example, you might see something like this \n",
    "once you implement the masking function below.  \n",
    "\n",
    "- <span style=\"color:red\"> Input sentence: </span> Younes and Lukasz were working together in the lab yesterday after lunch.  \n",
    "- <span style=\"color:red\">Input: </span> Younes and Lukasz  **Z** together in the **Y** yesterday after lunch.\n",
    "- <span style=\"color:red\">Target: </span> **Z** were working **Y** lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fdb0048e9d6b0d",
   "metadata": {},
   "source": [
    "<a name='1-5'></a>\n",
    "##### 1.5 - Tokenizing and Masking\n",
    "\n",
    "In this task, you will implement the `tokenize_and_mask` function, which tokenizes and masks input words based on a \n",
    "given probability. The probability is controlled by the `noise` parameter, typically set to mask around `15%` of the \n",
    "words in the input text. The function will generate two lists of tokenized sequences following the algorithm outlined\n",
    " below:   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace95f1ebe62939",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "##### Exercise 1 - tokenize_and_mask\n",
    "\n",
    "- Start with two empty lists: `inps` and `targs`\n",
    "- Tokenize the input text using the given tokenizer.\n",
    "- For each `token` in the tokenized sequence:\n",
    "  - Generate a random number(simulating a weighted coin toss)\n",
    "  - If the random value is greater than the given threshold(noise):\n",
    "    - Add the current token to the `inps` list\n",
    "  - Else:\n",
    "    - If a new sentinel must be included(read note **):\n",
    "      - Compute the next sentinel ID using a progression.\n",
    "      - Add a sentinel into the `inps` and `targs` to mark the position of the masked element.\n",
    "    - Add the current token to the `targs` list.\n",
    "\n",
    "** There's a special case to consider. If two or more consecutive tokens get masked during the process, you don't \n",
    "need to add a new sentinel to the sequences. To account for this, use the `prev_no_mask` flag, which starts as `True`\n",
    " but is turned to `False` each time you mask a new element. The code that adds sentinels will only be executed if, \n",
    " before masking the token, the flag was in the `True` state.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f6519daa81b306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:33.478184Z",
     "start_time": "2024-07-15T16:04:33.474220Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_mask(text, \n",
    "                      noise=0.15, \n",
    "                      randomizer=np.random.uniform, \n",
    "                      tokenizer=None):\n",
    "    \"\"\"Tokenizes and masks a given input.\n",
    "\n",
    "    Args:\n",
    "        text (str or bytes): Text input.\n",
    "        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n",
    "        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n",
    "        tokenizer (function, optional): Tokenizer function. Defaults to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        inps, targs: Lists of integers associated to inputs and targets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Current sentinel number (starts at 0)\n",
    "    cur_sentinel_num = 0\n",
    "    \n",
    "    # Inputs and targets\n",
    "    inps, targs = [], []\n",
    "\n",
    "    # Vocab_size\n",
    "    vocab_size = int(tokenizer.vocab_size())\n",
    "    \n",
    "    # EOS token id \n",
    "    # Must be at the end of each target!\n",
    "    eos = tokenizer.string_to_id(\"</s>\").numpy()\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n",
    "    # set prev_no_mask to True\n",
    "    prev_no_mask = True\n",
    "    \n",
    "    # Loop over the tokenized text\n",
    "    for token in tokenizer.tokenize(text).numpy():\n",
    "        \n",
    "        # Generate a random value between 0 and 1\n",
    "        rnd_val = randomizer() \n",
    "        \n",
    "        # Check if the noise is greater than a random value (weighted coin flip)\n",
    "        if noise > rnd_val:\n",
    "            \n",
    "            # Check if previous token was NOT masked\n",
    "            if prev_no_mask:\n",
    "                \n",
    "                # Current sentinel increases by 1\n",
    "                cur_sentinel_num += 1\n",
    "                \n",
    "                # Compute end_id by subtracting current sentinel value out of the total vocabulary size\n",
    "                end_id = vocab_size - cur_sentinel_num\n",
    "                \n",
    "                # Append end_id at the end of the targets\n",
    "                targs.append(end_id)\n",
    "                \n",
    "                # Append end_id at the end of the inputs\n",
    "                inps.append(end_id)\n",
    "                \n",
    "            # Append token at the end of the targets\n",
    "            targs.append(token)\n",
    "            \n",
    "            # set prev_no_mask accordingly\n",
    "            prev_no_mask = False\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Append token at the end of the inputs\n",
    "            inps.append(token)\n",
    "            \n",
    "            # Set prev_no_mask accordingly\n",
    "            prev_no_mask = True\n",
    "    \n",
    "    \n",
    "    # Add EOS token to the end of the targets\n",
    "    targs.append(eos)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inps, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7e40f11a48623a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:33.934511Z",
     "start_time": "2024-07-15T16:04:33.930125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized inputs - shape=53:\n",
      "\n",
      "[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5]\n",
      "\n",
      "targets - shape=19:\n",
      "\n",
      "[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 1]\n"
     ]
    }
   ],
   "source": [
    "# Some logic to mock a np.random value generator\n",
    "# Needs to be in the same cell for it to always generate same output\n",
    "def testing_rnd():\n",
    "    def dummy_generator():\n",
    "        vals = np.linspace(0, 1, 10)\n",
    "        cyclic_vals = itertools.cycle(vals)\n",
    "        for _ in range(100):\n",
    "            yield next(cyclic_vals)\n",
    "\n",
    "    dumr = itertools.cycle(dummy_generator())\n",
    "\n",
    "    def dummy_randomizer():\n",
    "        return next(dumr)\n",
    "    \n",
    "    return dummy_randomizer\n",
    "\n",
    "input_str = 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.'\n",
    "\n",
    "inps, targs = tokenize_and_mask(input_str, randomizer=testing_rnd(), tokenizer=tokenizer)\n",
    "print(f\"tokenized inputs - shape={len(inps)}:\\n\\n{inps}\\n\\ntargets - shape={len(targs)}:\\n\\n{targs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2781420f9eb6de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:34.136388Z",
     "start_time": "2024-07-15T16:04:34.123205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "\n",
      " b'<Z> BBQ Class Taking Place in Missoul <Y> Do you want to get better at making <X>? You will have the opportunity, put <W> your calendar now. Thursday, September 22 <V> World Class BBQ Champion, Tony Balay <U>onestar Smoke Rangers.'\n",
      "\n",
      "Targets: \n",
      "\n",
      " b'<Z> Beginners <Y>a! <X> delicious BBQ <W> this on <V>nd join <U> from L'\n"
     ]
    }
   ],
   "source": [
    "print('Inputs: \\n\\n', pretty_decode(inps, sentinels, tokenizer).numpy())\n",
    "print('\\nTargets: \\n\\n', pretty_decode(targs, sentinels, tokenizer).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada675ae3f7ca98f",
   "metadata": {},
   "source": [
    "<a name='1-6'></a>\n",
    "##### 1.6 - Creating the Pairs\n",
    "\n",
    "You will now create pairs using your dataset. You will iterate over your data and create (inp, targ) pairs using the \n",
    "functions that we have given you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1658bc15b7e58c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:36.552788Z",
     "start_time": "2024-07-15T16:04:34.589027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply tokenize_and_mask\n",
    "inputs_targets_pairs = [tokenize_and_mask(text.encode('utf-8', errors='ignore').decode('utf-8'), tokenizer=tokenizer) \n",
    "                        for text in natural_language_texts[0:2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91290299f504c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:36.582226Z",
     "start_time": "2024-07-15T16:04:36.553933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "\n",
      "inputs:\n",
      "<Z>il plaid <Y>lycra <X> spandex shortall with metallic slinky\n",
      "<W>sets. Attache <V> metallic elastic belt with O <U>ring. Head <T>\n",
      "included. Great hip hop<S> jazz dance costume.<R> in the USA.\n",
      "\n",
      "targets:\n",
      "<Z> Fo <Y>  <X> and <W> in <V>d <U>- <T>band<S> or<R> Made\n",
      "\n",
      "\n",
      "\n",
      "[2]\n",
      "\n",
      "inputs:\n",
      "I thought I was going to <Z> 3rd season <Y> Wire tonight. <X> there\n",
      "was a commentary <W> 11, so I had to re <V>watch <U> Ground with <T>\n",
      "commentary. Hopefully<S> can finish<R> season <Q>.\n",
      "\n",
      "targets:\n",
      "<Z> finish the <Y> of the <X> But <W> on episode <V>- <U> Middle <T>\n",
      "the<S> I<R> the <Q> next weekend\n",
      "\n",
      "\n",
      "\n",
      "[3]\n",
      "\n",
      "inputs:\n",
      "Pencarian <Z>FILM Untuk \" <Y>eace <X>er 2017 <W> yuk mampir ke channel\n",
      "say <V>. Edges <U> provides the l.. A corrupt cop makes one w.. <T>er\n",
      "2017   <S>   .. No Lo  n - Peace Break.. Please subscribe and hit\n",
      "..<R> in HD at http://.. <Q> cannot believe I manage..\n",
      "\n",
      "targets:\n",
      "<Z>  <Y>P <X> Break <W>\" <V>. <U> East <T> Peace Break<S> <R> uploaded\n",
      "<Q> I\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper=textwrap.TextWrapper(width=70), tokenizer=tokenizer):\n",
    "    for i, inp_tgt_pair in enumerate(inputs_targets_pairs, 1):\n",
    "        inps, tgts = inp_tgt_pair\n",
    "        inps = str(pretty_decode(inps, sentinels, tokenizer).numpy(), encoding='utf-8')\n",
    "        tgts = str(pretty_decode(tgts, sentinels, tokenizer).numpy(), encoding='utf-8')\n",
    "        print(f'[{i}]\\n\\n'\n",
    "              f'inputs:\\n{wrapper.fill(text=inps)}\\n\\n'\n",
    "              f'targets:\\n{wrapper.fill(text=tgts)}\\n\\n\\n')\n",
    "\n",
    "# Print 3 samples. We print inputs with less than 100 tokens. It is just to give you and idea of the process\n",
    "display_input_target_pairs(filter(lambda x: len(x[0]) < 100, inputs_targets_pairs[0:12]), sentinels, wrapper, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e6f3691f71599",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "#### 2 - Pretrain a T5 model using C4\n",
    "\n",
    "Now you are going to use the Transformer's architecture that you coded in the previous assignment to summarize text, \n",
    "but this time to answer questions. Instead of training the question answering model from scratch, you will first \n",
    "\"pre-train\" the model using the C4 data set you just processed. This will help the model to learn the general \n",
    "structure of language from a large dataset. This is much easier to do, as you don't need to label any data, but just \n",
    "use the masking, which is done automatically. You will then use the data from the SQuAD set to teach the model to \n",
    "answer questions given a context. To start let's review the Transformer's architecture.      \n",
    "\n",
    "<img src = \"pomocne_soubory/fulltransformer.png\" width=\"300\" height=\"600\">\n",
    "\n",
    "<a name='2-1'></a>\n",
    "##### 2.1 - Instantiate a new transformer model\n",
    "\n",
    "We have packaged the code implemented in the previous week into the `Transformer.py` file. You can import it here, \n",
    "and setup with the same configuration used there.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d89d6f92a4bf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:36.611098Z",
     "start_time": "2024-07-15T16:04:36.583148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers = 2\n",
    "embedding_dim = 128\n",
    "fully_connected_dim = 128\n",
    "num_heads = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "encoder_vocab_size = int(tokenizer.vocab_size())\n",
    "decoder_vocab_size = encoder_vocab_size\n",
    "\n",
    "# Initialize the model\n",
    "transformer = pomocne_soubory.transformer_utils_attention .Transformer(\n",
    "    num_layers=num_layers, \n",
    "    embedding_dim=embedding_dim, \n",
    "    num_heads=num_heads, \n",
    "    fully_connected_dim=fully_connected_dim,\n",
    "    input_vocab_size=encoder_vocab_size, \n",
    "    target_vocab_size=decoder_vocab_size, \n",
    "    max_positional_encoding_input=positional_encoding_length, \n",
    "    max_positional_encoding_target=positional_encoding_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df81b20aea2fcee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:36.688884Z",
     "start_time": "2024-07-15T16:04:36.612226Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = pomocne_soubory.transformer_utils_attention.CustomSchedule(embedding_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# Here you will store the losses, so you can later plot them\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79692fa24de0a51",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "##### 2.2 - C4 pretraining\n",
    "\n",
    "For training a Tensorflow model you need to arrange the data into datasets. Now, you will get the `inputs` and the \n",
    "`targets` for the transformer model from the `inputs_targets_pairs`. Before creating the dataset, you need to be sure\n",
    " that all `inputs` have the same length by truncating the longer sequences and padding the shorter ones with `0`. The\n",
    "  same must be done for the targets. The function `tf.keras.preprocessing.sequence.pad_sequences` will help you here,\n",
    "   as in the previous week assignment.    \n",
    "\n",
    "You will use a `BATCH_SIZE = 64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee6ba49079ab8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:04:36.713849Z",
     "start_time": "2024-07-15T16:04:36.689925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data so this can run in this environment\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences([x[0] for x in inputs_targets_pairs], maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences([x[1] for x in inputs_targets_pairs], maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7c88d8659cf99",
   "metadata": {},
   "source": [
    "Now, you can run the training loop for 10 epochs. Running it with a big dataset such as C4 on a good computer with \n",
    "enough memory and a good GPU could take more than 24 hours. Here, you will run few epochs using a small portion of \n",
    "the C4 dataset for illustration. It will only take a few minutes, but the model won't be very powerful.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a443037337bf7440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:55.284436Z",
     "start_time": "2024-07-15T16:04:36.795930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1/32\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/basic/lib/python3.9/site-packages/keras/src/backend/tensorflow/nn.py:602: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 10.1055\n",
      "Time taken for one epoch: 34.988292932510376 sec\n",
      "Epoch 2, Loss 9.8063\n",
      "Time taken for one epoch: 14.203985929489136 sec\n",
      "Epoch 3, Loss 9.5111\n",
      "Time taken for one epoch: 11.679851055145264 sec\n",
      "Epoch 4, Loss 9.2266\n",
      "Time taken for one epoch: 11.096784114837646 sec\n",
      "Epoch 5, Loss 8.9565\n",
      "Time taken for one epoch: 10.370763778686523 sec\n",
      "Epoch 6, Loss 8.7024\n",
      "Time taken for one epoch: 11.303286075592041 sec\n",
      "Epoch 7, Loss 8.4645\n",
      "Time taken for one epoch: 11.141732215881348 sec\n",
      "Epoch 8, Loss 8.2440\n",
      "Time taken for one epoch: 11.235822916030884 sec\n",
      "Epoch 9, Loss 8.0425\n",
      "Time taken for one epoch: 11.232058763504028 sec\n",
      "Epoch 10, Loss 7.8615\n",
      "Time taken for one epoch: 11.230502843856812 sec\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    # train_loss.reset_states()\n",
    "    number_of_batches=len(list(enumerate(dataset)))\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        print(f'Epoch {epoch+1}, Batch {batch+1}/{number_of_batches}', end='\\r')\n",
    "        pomocne_soubory.transformer_utils_attention .train_step(\n",
    "            inp=inp, tar=tar, model=transformer, \n",
    "            loss_object=loss_object, \n",
    "            optimizer=optimizer, train_loss=train_loss)\n",
    "\n",
    "    print (f'Epoch {epoch+1}, Loss {train_loss.result():.4f}')\n",
    "    losses.append(train_loss.result())\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "\n",
    "# Save the pretrained model\n",
    "# transformer.save_weights('./model_c4_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e218ee2deb5a836",
   "metadata": {},
   "source": [
    "**Load a pretrained model**\n",
    "\n",
    "To show how powerful this model actually is, we trained it for several epochs with the full dataset in Colab and \n",
    "saved the weights for you. You can load them using the cell below. For the rest of the notebook, you will see the \n",
    "power of the transfer learning in action.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d0de54b8540bf",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "#### 3. Fine tune the T5 model for Question Answering\n",
    "\n",
    "Now,  you are going to fine tune the pretrained model for Question Answering using the [SQUad 2.0 dataset](https://rajpurkar.github.io/SQuAD-explorer/).\n",
    "\n",
    "SQuAD, short for Stanford Question Answering Dataset, is a dataset designed for training and evaluating question \n",
    "answering systems. It consists of real questions posed by humans on a set of Wikipedia articles, where the answer to \n",
    "each question is a specific span of text within the corresponding article.  \n",
    "\n",
    "SQuAD 1.1, the previous version of the SQuAD dataset, contains 100,000+ question-answer pairs on about 500 articles.\n",
    "SQuAD 2.0, contains 50.000 additional questions that are not meant to be answered. This extra set of questions can \n",
    "help to train models to detect unanswerable questions.  \n",
    "\n",
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c041467767d31fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:56.055741Z",
     "start_time": "2024-07-15T16:06:55.288488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 442\n"
     ]
    }
   ],
   "source": [
    "with open('pomocne_soubory/attention_files/train-v2.0.json', 'r') as f:\n",
    "    example_jsons = json.load(f)\n",
    "\n",
    "example_jsons = example_jsons['data']\n",
    "\n",
    "print('Number of articles: ' + str(len(example_jsons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c4aa2c1660af2",
   "metadata": {},
   "source": [
    "The structure of each article is as follows:\n",
    "- `title`: The article title\n",
    "- `paragraphs`: A list of paragraphs and questions related to them\n",
    "    - `context`: The actual paragraph text\n",
    "    - `qas`: A set of question related to the paragraph\n",
    "        - `question`: A question\n",
    "        - `id`: The question unique identifier\n",
    "        - `is_imposible`: Boolean, specifies if the question can be answered or not\n",
    "        - `answers`: A set of possible answers for the question\n",
    "            - `text`: The answer\n",
    "            - `answer_start`: The index of the character that starts the sentence containing the explicit answer to the question\n",
    "            \n",
    "Take a look at an article by running the next cell. Notice that the `context` is usually the last element for every paragraph:           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb8561f8fb03957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:56.059032Z",
     "start_time": "2024-07-15T16:06:56.056620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyonc\n",
      "{'qas': [{'question': 'When did Beyonce start becoming popular?', 'id': '56be85543aeaaa14008c9063', 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}], 'is_impossible': False}, {'question': 'What areas did Beyonce compete in when she was growing up?', 'id': '56be85543aeaaa14008c9065', 'answers': [{'text': 'singing and dancing', 'answer_start': 207}], 'is_impossible': False}, {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\", 'id': '56be85543aeaaa14008c9066', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'In what city and state did Beyonce  grow up? ', 'id': '56bf6b0f3aeaaa14008c9601', 'answers': [{'text': 'Houston, Texas', 'answer_start': 166}], 'is_impossible': False}, {'question': 'In which decade did Beyonce become famous?', 'id': '56bf6b0f3aeaaa14008c9602', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': 'In what R&B group was she the lead singer?', 'id': '56bf6b0f3aeaaa14008c9603', 'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}], 'is_impossible': False}, {'question': 'What album made her a worldwide known artist?', 'id': '56bf6b0f3aeaaa14008c9604', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': \"Who managed the Destiny's Child group?\", 'id': '56bf6b0f3aeaaa14008c9605', 'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}], 'is_impossible': False}, {'question': 'When did Beyonc rise to fame?', 'id': '56d43c5f2ccc5a1400d830a9', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': \"What role did Beyonc have in Destiny's Child?\", 'id': '56d43c5f2ccc5a1400d830aa', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': 'What was the first album Beyonc released as a solo artist?', 'id': '56d43c5f2ccc5a1400d830ab', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': 'When did Beyonc release Dangerously in Love?', 'id': '56d43c5f2ccc5a1400d830ac', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'How many Grammy awards did Beyonc win for her first solo album?', 'id': '56d43c5f2ccc5a1400d830ad', 'answers': [{'text': 'five', 'answer_start': 590}], 'is_impossible': False}, {'question': \"What was Beyonc's role in Destiny's Child?\", 'id': '56d43ce42ccc5a1400d830b4', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': \"What was the name of Beyonc's first solo album?\", 'id': '56d43ce42ccc5a1400d830b5', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}], 'context': 'Beyonc Giselle Knowles-Carter (/bijnse/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyonc\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}\n"
     ]
    }
   ],
   "source": [
    "example_article = example_jsons[0]\n",
    "example_article\n",
    "\n",
    "print(\"Title: \" + example_article[\"title\"])\n",
    "print(example_article[\"paragraphs\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a462e64f447dbcb",
   "metadata": {},
   "source": [
    "The previous article might be difficult to navigate so here is a nicely formatted example paragraph:\n",
    "```python\n",
    "{\n",
    "  \"context\": \"Beyonc Giselle Knowles-Carter (/bijnse/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles 'Crazy in Love' and 'Baby Boy'\",\n",
    "  \"qas\": [\n",
    "    {\n",
    "      \"question\": \"When did Beyonce start becoming popular?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9063\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"in the late 1990s\",\n",
    "          \"answer_start\": 269\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What areas did Beyonce compete in when she was growing up?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9065\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"singing and dancing\",\n",
    "          \"answer_start\": 207\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d66689d17799de",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "##### 3.1 - Creating a list of paired question and answers \n",
    "\n",
    "You are tasked with generating input/output pairs for a Question Answering (QA) model using the SQuAD 2.0 dataset. Each pair follows the structure:\n",
    "\n",
    "- inputs: `question: <Q> context: <P>`\n",
    "- targets: `answer: <A>`\n",
    "    \n",
    "Here, `<Q>` represents the question in the context of the given paragraph `<P>`, and `<A>` is a possible answer.\n",
    "\n",
    "In this notebook, we will focus on a single answer per question. However, it's essential to note that the dataset contains questions with multiple answers. When training a model in real-life scenarios, consider including all available information.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "##### Exercise 2 - Parse the SQuaD 2.0 Dataset\n",
    "\n",
    "Your task is to implement the parse_squad function, which iterates over all the articles, paragraphs, and questions in the SQuAD dataset. Extract pairs of inputs and targets for the QA model using the provided code template.\n",
    "- Start with two empty lists: `inputs` and `targets`.\n",
    "- Loop over all the articles in the dataset.\n",
    "- For each article, loop over each paragraph.\n",
    "- Extract the context from the paragraph.\n",
    "- Loop over each question in the given paragraph.\n",
    "- Check if the question is not impossible and has at least one answer.\n",
    "- If the above condition is met, create the `question_context` sequence as described in the input structure.\n",
    "- Create the `answer` sequence using the first answer from the available answers.\n",
    "- Append the `question_context` to the `inputs` list.\n",
    "- Append the `answer` to the `targets` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c7be252849e707f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:56.065962Z",
     "start_time": "2024-07-15T16:06:56.062690Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: parse_squad\n",
    "def parse_squad(dataset):\n",
    "    \"\"\"Extract all the answers/questions pairs from the SQuAD dataset\n",
    "\n",
    "    Args:\n",
    "        dataset (dict): The imported JSON dataset\n",
    "\n",
    "    Returns:\n",
    "        inputs, targets: Two lists containing the inputs and the targets for the QA model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Loop over all the articles\n",
    "    for article in dataset:\n",
    "        \n",
    "        # Loop over each paragraph of each article\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            \n",
    "            # Extract context from the paragraph\n",
    "            context = paragraph[\"context\"]\n",
    "            \n",
    "            #Loop over each question of the given paragraph\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                \n",
    "                # If this question is not impossible and there is at least one answer\n",
    "                if len(qa['answers']) > 0 and not(qa['is_impossible']):\n",
    "                    \n",
    "                    # Create the question/context sequence\n",
    "                    question_context = 'question: ' + qa[\"question\"] + ' context: ' + context\n",
    "                    \n",
    "                    # Create the answer sequence. Use the text field of the first answer\n",
    "                    answer = 'answer: ' + qa[\"answers\"][0][\"text\"]\n",
    "                    \n",
    "                    # Add the question_context to the inputs list\n",
    "                    inputs.append(question_context)\n",
    "                    \n",
    "                    # Add the answer to the targets list\n",
    "                    targets.append(answer)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688fba8d878a3218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:56.264006Z",
     "start_time": "2024-07-15T16:06:56.067060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question/answer pairs: 86821\n",
      "\n",
      "First Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: When did Beyonce start becoming popular? context: Beyonc Giselle Knowles-Carter (/bijnse/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: in the late 1990s\u001b[0m\n",
      "\n",
      "Last Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: What is KMC an initialism of? context: Kathmandu Metropolitan City (KMC), in order to promote international relations has established an International Relations Secretariat (IRC). KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States. This activity has been further enhanced by establishing formal relationships with 8 other cities: Motsumoto City of Japan, Rochester of the USA, Yangon (formerly Rangoon) of Myanmar, Xi'an of the People's Republic of China, Minsk of Belarus, and Pyongyang of the Democratic Republic of Korea. KMC's constant endeavor is to enhance its interaction with SAARC countries, other International agencies and many other major cities of the world to achieve better urban management and developmental programs for Kathmandu.\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: Kathmandu Metropolitan City\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inputs, targets =  parse_squad(example_jsons)          \n",
    "print(\"Number of question/answer pairs: \" + str(len(inputs)))\n",
    "\n",
    "print('\\nFirst Q/A pair:\\n\\ninputs: ' + colored(inputs[0], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[0], 'green'))\n",
    "print('\\nLast Q/A pair:\\n\\ninputs: ' + colored(inputs[-1], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[-1], 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c3e33581410875b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:06:56.271320Z",
     "start_time": "2024-07-15T16:06:56.265114Z"
    }
   },
   "outputs": [],
   "source": [
    "# 40K pairs for training\n",
    "inputs_train = inputs[0:40000] \n",
    "targets_train = targets[0:40000]  \n",
    "\n",
    "# 5K pairs for testing\n",
    "inputs_test = inputs[40000:45000] \n",
    "targets_test =  targets[40000:45000] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edda0545bd67d72",
   "metadata": {},
   "source": [
    "Now, you can create the batch dataset of padded sequences. You will first tokenize the inputs and the targets. Then, \n",
    "using the function `tf.keras.preprocessing.sequence.pad_sequences`, you will ensure that the inputs and the outputs \n",
    "have the required lengths. Remember that the sequences longer than the required size will be truncated and the \n",
    "shorter ones will be padded with `0`. This setup is very similar to the other one used in this and the previous notebook.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48558dace2046c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:07:15.374003Z",
     "start_time": "2024-07-15T16:06:56.272253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data so this can run in this environment\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "inputs_str = [tokenizer.tokenize(s) for s in inputs_train]\n",
    "targets_str = [tf.concat([tokenizer.tokenize(s), [1]], 0) for s in targets_train]\n",
    "\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs_str, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets_str, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f310cfbdca0d",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "##### 3.2 Fine tune the T5 model\n",
    "\n",
    "Now, you will train the model for 2 epochs. In the T5 model, all the weights are adjusted during the fine tuning. As \n",
    "usual, fine tuning this model to get state of the art results would require more time and resources than there are \n",
    "available in this environment, but you are welcome to train the model for more epochs and with more data using Colab \n",
    "GPUs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693a616d9ace2698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:18.016291Z",
     "start_time": "2024-07-15T16:07:15.375441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 6.214925\n",
      "Time taken for one epoch: 225.01644277572632 sec\n",
      "Epoch 2, Loss 5.354525\n",
      "Time taken for one epoch: 257.6185917854309 sec\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 1\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_loss.reset_state()\n",
    "    number_of_batches=len(list(enumerate(dataset)))\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        print(f'Epoch {epoch+1}, Batch {batch+1}/{number_of_batches}', end='\\r')\n",
    "        pomocne_soubory.transformer_utils_attention .train_step(inp, tar, transformer, loss_object, optimizer, train_loss)\n",
    "    \n",
    "    print (f'Epoch {epoch+1}, Loss {train_loss.result():.4f}')\n",
    "    losses.append(train_loss.result())\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "    #if epoch % 15 == 0:\n",
    "        #transformer.save_weights('./pretrained_models/model_qa_temp')\n",
    "# Save the final model\n",
    "#transformer.save_weights('./pretrained_models/model_qa_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445aa31a201ea9fd",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "##### 3.3 - Implement your Question Answering model\n",
    "In this final step, you will implement the answer_question function, utilizing a pre-trained transformer model for \n",
    "question answering. \n",
    "\n",
    "To help you out the `transformer_utils.next_word` function is provided. This function receives the question and \n",
    "beginning of the answer (both in tensor format) alongside the model to predict the next token in the answer. The next\n",
    " cell shows how to use this:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd569487270d8fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:19.458128Z",
     "start_time": "2024-07-15T16:15:18.019556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word is: 'the'\n",
      "Answer so far: 'answer: the'\n"
     ]
    }
   ],
   "source": [
    "# Define an example question\n",
    "example_question = \"question: What color is the sky? context: Sky is blue\"\n",
    "\n",
    "# Question is tokenized and padded\n",
    "# Note that this is hardcoded here but you must implement this in the upcoming exercise\n",
    "tokenized_padded_question = tf.constant([[822, 10, 363, 945, 19, 8, 5796, 58, 2625, 10, 5643, 19, 1692, 0, 0]])\n",
    "\n",
    "# All answers begin with the string \"answer: \"\n",
    "# Feel free to check that this is indeed the tokenized version of that string\n",
    "tokenized_answer = tf.constant([[1525,   10]])\n",
    "\n",
    "# Predict the next word using the transformer_utils.next_word function\n",
    "# Notice that it expects the question, answer and model (in that order)\n",
    "next_word = pomocne_soubory.transformer_utils_attention.next_word(tokenized_padded_question, tokenized_answer, transformer)\n",
    "\n",
    "print(f\"Predicted next word is: '{tokenizer.detokenize(next_word).numpy()[0].decode('utf-8')}'\")\n",
    "\n",
    "# Concatenate predicted word with answer so far\n",
    "answer_so_far = tf.concat([tokenized_answer, next_word], axis=-1)\n",
    "\n",
    "print(f\"Answer so far: '{tokenizer.detokenize(answer_so_far).numpy()[0].decode('utf-8')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5076dce0637209e",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>\n",
    "##### Exercise 3 - Implement the question answering function\n",
    "\n",
    "Implement the `answer_question` function. Here are the steps:\n",
    "- **Question Setup:**\n",
    "\n",
    "  - Tokenize the given question using the provided tokenizer.\n",
    "  - Add an extra dimension to the tensor for compatibility.\n",
    "  - Pad the question tensor using `pad_sequences` to ensure the sequence has the specified max length. This function \n",
    "  will truncate the sequence if it is larger or pad with zeros if it is shorter.  \n",
    "- **Answer Setup:**\n",
    "  - Tokenize the initial answer, noting that all answers begin with the string \"answer: \".\n",
    "  - Add an extra dimension to the tensor for compatibility.\n",
    "  - Get the id of the `EOS` token, typically represented by 1.\n",
    "- **Generate Answer:**\n",
    "  - Loop for `decoder_maxlen` iterations.\n",
    "  - Use the `transformer_utils.next_word` function, which predicts the next token in the answer using the model, \n",
    "  input document, and the current state of the output. \n",
    "  - Concatenate the predicted next word to the output tensor.\n",
    "- **Stop Condition:**\n",
    "  - The text generation stops if the model predicts the `EOS` token.\n",
    "  - If the `EOS` token is predicted, break out of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "727ce995ae1c37a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:19.470724Z",
     "start_time": "2024-07-15T16:15:19.463690Z"
    }
   },
   "outputs": [],
   "source": [
    "def answer_question(question, model, tokenizer, encoder_maxlen=150, decoder_maxlen=50):\n",
    "    \"\"\"\n",
    "    A function for question answering using the transformer model\n",
    "    Arguments:\n",
    "        question (tf.Tensor): Input data with question and context\n",
    "        model (tf.keras.model): The transformer model\n",
    "        tokenizer (function): The SentencePiece tokenizer\n",
    "        encoder_maxlen (number): Max length of the encoded sequence\n",
    "        decoder_maxlen (number): Max length of the decoded sequence\n",
    "    Returns:\n",
    "        _ (str): The answer to the question\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # QUESTION SETUP\n",
    "    \n",
    "    # Tokenize the question\n",
    "    tokenized_question = tokenizer.tokenize(question)\n",
    "    \n",
    "    # Add an extra dimension to the tensor\n",
    "    tokenized_question = tf.expand_dims(tokenized_question, 0) \n",
    "    \n",
    "    # Pad the question tensor\n",
    "    padded_question = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question,\n",
    "                                                                    maxlen=encoder_maxlen,\n",
    "                                                                    padding='post', \n",
    "                                                                    truncating='post') \n",
    "    # ANSWER SETUP\n",
    "    \n",
    "    # Tokenize the answer\n",
    "    # Hint: All answers begin with the string \"answer: \"\n",
    "    tokenized_answer = tokenizer.tokenize(\"answer: \")\n",
    "    \n",
    "    # Add an extra dimension to the tensor\n",
    "    tokenized_answer = tf.expand_dims(tokenized_answer, 0)\n",
    "    \n",
    "    # Get the id of the EOS token\n",
    "    eos = tokenizer.string_to_id(\"</s>\") \n",
    "    \n",
    "    # Loop for decoder_maxlen iterations\n",
    "    for i in range(decoder_maxlen):\n",
    "        \n",
    "        # Predict the next word using the model, the input document and the current state of output\n",
    "        next_word = pomocne_soubory.transformer_utils_attention.next_word(padded_question, tokenized_answer, model)\n",
    "        \n",
    "        # Concat the predicted next word to the output \n",
    "        tokenized_answer = tf.concat([tokenized_answer, next_word], axis=1)\n",
    "        \n",
    "        # The text generation stops if the model predicts the EOS token\n",
    "        if next_word == eos:\n",
    "            break \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return tokenized_answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d0d3a8724cd55a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:36.967798Z",
     "start_time": "2024-07-15T16:15:19.471728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mb'answer: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the'\u001b[0m\n",
      "\n",
      "question: When was the Chechen-Ingush Autonomous Soviet Socialist Republic transferred from the Georgian SSR? context: On January 9, 1957, Karachay Autonomous Oblast and Chechen-Ingush Autonomous Soviet Socialist Republic were restored by Khrushchev and they were transferred from the Georgian SSR back to the Russian SFSR.\n",
      "\u001b[32manswer: January 9, 1957\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "idx = 10408\n",
    "\n",
    "result = answer_question(inputs_train[idx], transformer, tokenizer)\n",
    "print(colored(pretty_decode(result, sentinels, tokenizer).numpy()[0], 'blue'))\n",
    "print()\n",
    "print(inputs_train[idx])\n",
    "print(colored(targets_train[idx], 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3bdf3b7549b8cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:37.678636Z",
     "start_time": "2024-07-15T16:15:36.969702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mb'answer: aaa'\u001b[0m\n",
      "\n",
      "question:  What percentage of the vote was recorded as approving Napoleon's constitution? context: Napoleon established a political system that historian Martyn Lyons called \"dictatorship by plebiscite.\" Worried by the democratic forces unleashed by the Revolution, but unwilling to ignore them entirely, Napoleon resorted to regular electoral consultations with the French people on his road to imperial power. He drafted the Constitution of the Year VIII and secured his own election as First Consul, taking up residence at the Tuileries. The constitution was approved in a rigged plebiscite held the following January, with 99.94 percent officially listed as voting \"yes.\" Napoleon's brother, Lucien, had falsified the returns to show that 3 million people had participated in the plebiscite; the real number was 1.5 million. Political observers at the time assumed the eligible French voting public numbered about 5 million people, so the regime artificially doubled the participation rate to indicate popular enthusiasm for the Consulate. In the first few months of the Consulate, with war in Europe still raging and internal instability still plaguing the country, Napoleon's grip on power remained very tenuous.\n",
      "\u001b[32manswer: 99.94\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "idx = 110\n",
    "result = answer_question(inputs_test[idx], transformer, tokenizer)\n",
    "print(colored(pretty_decode(result, sentinels, tokenizer).numpy()[0], 'blue'))\n",
    "print()\n",
    "print(inputs_test[idx])\n",
    "print(colored(targets_test[idx], 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c676fa37a1b57f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:15:38.040358Z",
     "start_time": "2024-07-15T16:15:37.679698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mb'answer: aaa'\u001b[0m\n",
      "\n",
      "question:  On what date was a state funeral held for Napoleon? context: In 1840, Louis Philippe I obtained permission from the British to return Napoleon's remains to France. On 15 December 1840, a state funeral was held. The hearse proceeded from the Arc de Triomphe down the Champs-lyses, across the Place de la Concorde to the Esplanade des Invalides and then to the cupola in St Jrme's Chapel, where it remained until the tomb designed by Louis Visconti was completed. In 1861, Napoleon's remains were entombed in a porphyry sarcophagus in the crypt under the dome at Les Invalides.\n",
      "\u001b[32manswer: 15 December 1840\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "idx = 311\n",
    "result = answer_question(inputs_test[idx], transformer, tokenizer)\n",
    "print(colored(pretty_decode(result, sentinels, tokenizer).numpy()[0], 'blue'))\n",
    "print()\n",
    "print(inputs_test[idx])\n",
    "print(colored(targets_test[idx], 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8457649c8a33aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
