{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticstack\n",
    "Úvodem bych rád poznamenal, že tento notebook slouží primárně jako soukromá sbírka poznámek. Není to podklad pro nějaký workshop, neboť na něco takového mi v době psání těchto řádků zkrátka chybí zkušenosti.\n",
    "\n",
    "## Obsah\n",
    "1. [Terminologie](#Terminologie)  \n",
    "2. [Elasticsearch](#Elasticsearch)  \n",
    "  1. [Indexy](#Indexy)  \n",
    "  2. [Vkládání dokumentů do indexu](#Vkládání-dokumentů-do-indexu)  \n",
    "  3. [Vyhledávání v dokumentech](#Vyhledávání-v-dokumentech)  \n",
    "    1. [Query](#Query)  \n",
    "      1. [match a match_phrase](#match-a-match_phrase)  \n",
    "      2. [multi_match](#multi_match)  \n",
    "      3. [bool](#bool)  \n",
    "    2. [Agregace](#Agregace)  \n",
    "  4. [Updaty a mazání záznamů](#Updaty-a-mazání-záznamů)  \n",
    "  5. [Elastic a curl](#Elastic-a-curl)  \n",
    "  6. [Elastic a Python](#Elastic-a-Python)  \n",
    "3. [Kibana](#Kibana)  \n",
    "4. [Logstash](#Logstash)  \n",
    "  1. [grok](#grok)\n",
    "\n",
    "\n",
    "## Terminologie\n",
    "Elasticsearch sice umožňuje ukládat strukturovaná data, spíše než o databázi se ale jedná o search engine. To na jedné straně znamená, že je Elastic ideální pro full textová prohledávání, na druhé straně ale například nepodporuje joinování či transakce. Nicméně určité paralely mezi ním a klasickou databází se najít dají.  \n",
    "Základním stavebním kamenem, ekvivalentním řádku v tabulce, je dokument. Tento objekt je reprezentován jsonem. Na základě logiky dat se pak dokumenty sdružují do indexů. U těchto indexů ale narozdíl od databázových tabulkek nic nevynucuje schéma. Tj. různé dokumenty-jsony umístěné v témže indexu mohou mít různé klíče a mohou mít i různý počet klíčů.  \n",
    "Měli bychom poznamenat, že indexy v sobě reálně jednotlivé dokumenty neobsahují. To, co se v indexech nachází, jsou *reference* na dokumenty. Fakticky jsou data dokumentů uloženy v tzv. shardech. O co se jedná a jak vůbec vypadá HW hierarchie Elasticu? Nejvýše stojí cluster. Pod ním se nacházejí ve vztahu one-to-many jednotlivé nody, bydlící obvykle na různých serverech. Na jednotlivých nodech jsou pak umístěny shardy. Aby se při pádu serveru neztratila data, má každý primární shard několik replik bydlících na odlišných nodech, které primární shard v případě nutnosti zastoupí.  \n",
    "Když je vytvořen nový index, defaultně se vytvoří nový shard. Ten postupně roste a tak by mohla nastat situace, kdy by byl onen shard větší než prostor na nodu. Proto se v takovém případě na jiném nodu vytvoří nový shard, do něhož se další dokumenty spadající pod stejný index budou ukládat. Jednou z výhod takového řešení je i skutečnost, že se takto zmenší doba zpracování dotazů. Pokud by totiž data byla rozdělena ve dvou shardech bydlících na dvou různých nodech, ony nody data prohledají rychleji, než by to zvládl node jeden zkoumající data všechna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticstack se skládá z následujících částí:\n",
    "- Elasticsearch - search engine alias jádro Elasticu\n",
    "- Kibana - webové rozhraní umožňující vizualizovat data\n",
    "- Logstash - data procesující pipelina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nejprve musíme spustit Elasticsearch (elasticsearch-7.13.3/bin/elasticsearch.bat) coby jádro vyhledávacího enginu a posléze Kibanu (kibana-7.13.3-windows-x86_64/bin/kibana.bat), jejímž prostřednictvím budeme s elasticem primárně pracovat. Defaultně se Elasticsearch nalézá na localhost:9200 a Kibana na localhost:5601. Vlezeme právě na kibaní URL a jakmile se v prohlížeči Kibana načte, klikneme na tři vodorovné čáry vlevo nahoře a v menu vybereve \"Dev Tools (je až úplně dole v sekci \"Management\"). Otevře se konzole, kde v levé čáasti zadáváme příkazy (spouští se trojúhelníkem na pravém okraji levé sekce) a v pravé sekci se pak díváme na výstupy.  \n",
    "### Indexy\n",
    "Když chceme vytvořit nový index, máme na výběr několik možných přístupů. Nejkratší z nich je asi\n",
    "```\n",
    "PUT jmeno-indexu\n",
    "```\n",
    "tedy např.\n",
    "```\n",
    "PUT pokusny_index_1\n",
    "```\n",
    "V takovémto případě se vrátí zpráva\n",
    "```\n",
    "{\n",
    "  \"acknowledged\" : true,\n",
    "  \"shards_acknowledged\" : true,\n",
    "  \"index\" : \"pokusny_index_1\"\n",
    "}\n",
    "```\n",
    "V rámci PUT requestu máme možnost specifikovat pole i jejich typy. \n",
    "```\n",
    "PUT pokusny_index_3\n",
    "{\n",
    "  \"mappings\":{\n",
    "    \"properties\": {\n",
    "      \"jmeno_produktu\":{\"type\":\"text\"},\n",
    "      \"pocet\":{\"type\":\"long\"},\n",
    "      \"cena\":{\"type\":\"float\"}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Nicméně pozor - pokud do takovéhoto indexu posléze zkusíme vložit záznam s jinými poli, projde to - schéma se o nová pole zkrátka rozšíří. Pouze v případě, kdy bychom do již specifikovaného pole zkoušeli vložit nekompatibilní obsah (např. do čísleného pole \"cena\" text \"nazdar\"), vrátila by se nám chyba \n",
    "```\n",
    "{\n",
    "  \"error\" : {\n",
    "    \"root_cause\" : [\n",
    "      {\n",
    "        \"type\" : \"mapper_parsing_exception\",\n",
    "        \"reason\" : \"failed to parse field [cena] of type [float] in document with id 'O9QDSnsBNZx_bel0v5mI'. Preview of field's value: 'nazdar'\"\n",
    "      }\n",
    "    ],\n",
    "    \"type\" : \"mapper_parsing_exception\",\n",
    "    \"reason\" : \"failed to parse field [cena] of type [float] in document with id 'O9QDSnsBNZx_bel0v5mI'. Preview of field's value: 'nazdar'\",\n",
    "    \"caused_by\" : {\n",
    "      \"type\" : \"number_format_exception\",\n",
    "      \"reason\" : \"For input string: \\\"nazdar\\\"\"\n",
    "    }\n",
    "  },\n",
    "  \"status\" : 400\n",
    "}\n",
    "\n",
    "```\n",
    "Datových typů existuje celá řada. Nicméně pro začátek je asi nejdůležitější naučit se rozlišovat mezi dvěma určenými pro textové řetězce - \"text\" a \"keyword\". Zdůrazněme, že na jedno pole mohou být napojené oba typy, nicméně počítejme s tím, že pro importovaný dataset (viz dále) si elastic obvykle vybere buďto jeden, nebo druhý typ. Text se používá na full-text prohledávání, zatímco keyword se hodí pro přesné vyhledávání termínů, sortování a agregace. Pakliže je pole označeno jako text, jeho obsah projde analyzátorem, který zajistí tokenizaci, lowercasování a odstranění interpunkce. Navíc se vytvoří tzv. \"inverted index\", který mapuje slova na id dokumetu. To má poté využití v dotazech typu \"Ukaž všechny dokumenty obsahující slova X, Y a Z\". I keyword search má svou vlastní meta-tabulku - tzv. \"doc values\". Zde je na každém řádku id dokumentu a termín. Pokud se termín objeví v jiném dokumentu, je z toho nový řádek, nikoli další položka v buňce id dokumentu, jako je tomu u inverted indexu.  \n",
    "\n",
    "Další možností pro vytvoření indexu je využít POST request, kdy v rámci jednoho příkazu index vytvoříme i naplníme prvním záznamem. Obecný předpis je\n",
    "```\n",
    "POST jmeno-indexu/_doc\n",
    "{\n",
    "  \"jmeno_pole\": hodnota_pole\n",
    "}\n",
    "```\n",
    "Konkrétní příklad:\n",
    "```\n",
    "POST pokusny_index_2/_doc\n",
    "{\n",
    "  \"prvni_pole\": 1,\n",
    "  \"druhe_pole\": 100\n",
    "}\n",
    "```\n",
    "Vrátí se zpráva o následujícím obsahu:\n",
    "```\n",
    "{\n",
    "  \"_index\" : \"pokusny_index_2\",\n",
    "  \"_type\" : \"_doc\",\n",
    "  \"_id\" : \"N9TsSXsBNZx_bel0upmB\",\n",
    "  \"_version\" : 1,\n",
    "  \"result\" : \"created\",\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 2,\n",
    "    \"successful\" : 1,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"_seq_no\" : 0,\n",
    "  \"_primary_term\" : 1\n",
    "}\n",
    "```\n",
    "\n",
    "Pokud chceme vidět \"schéma\" indexu, použijeme \n",
    "```\n",
    "GET jmeno_indexu\n",
    "```\n",
    "Resp. pokud bychom chtěli opravdu jen mapping bez dodatečných informací, použili bychom \n",
    "```\n",
    "GET historic_events/_mapping\n",
    "```\n",
    "Pro index, který zatím schéma nikterak definované nemá, vrátí \"krátký\" GET následující\n",
    "```\n",
    "{\n",
    "  \"pokusny_index_1\" : {\n",
    "    \"aliases\" : { },\n",
    "    \"mappings\" : { },\n",
    "    \"settings\" : {\n",
    "      \"index\" : {\n",
    "        \"routing\" : {\n",
    "          \"allocation\" : {\n",
    "            \"include\" : {\n",
    "              \"_tier_preference\" : \"data_content\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"number_of_shards\" : \"1\",\n",
    "        \"provided_name\" : \"pokusny_index_1\",\n",
    "        \"creation_date\" : \"1629032521954\",\n",
    "        \"number_of_replicas\" : \"1\",\n",
    "        \"uuid\" : \"et9_E9CXQJuIyV4OtEEBlA\",\n",
    "        \"version\" : {\n",
    "          \"created\" : \"7130399\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Pro index s již vytvořeným schématem dostaneme toto\n",
    "```\n",
    "{\n",
    "  \"pokusny_index_2\" : {\n",
    "    \"aliases\" : { },\n",
    "    \"mappings\" : {\n",
    "      \"properties\" : {\n",
    "        \"druhe_pole\" : {\n",
    "          \"type\" : \"long\"\n",
    "        },\n",
    "        \"prvni_pole\" : {\n",
    "          \"type\" : \"long\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"settings\" : {\n",
    "      \"index\" : {\n",
    "        \"routing\" : {\n",
    "          \"allocation\" : {\n",
    "            \"include\" : {\n",
    "              \"_tier_preference\" : \"data_content\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"number_of_shards\" : \"1\",\n",
    "        \"provided_name\" : \"pokusny_index_2\",\n",
    "        \"creation_date\" : \"1629032852067\",\n",
    "        \"number_of_replicas\" : \"1\",\n",
    "        \"uuid\" : \"d5UL-uBJT3qjaTz_sKQ4IA\",\n",
    "        \"version\" : {\n",
    "          \"created\" : \"7130399\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmiňme ještě, že jednou vytvořené indexy se nedají měnit. Tj. pokud bychom u nějak specifikovaného pole chtěli změnit typ hodnoty, která je v něm uložena, musíme vytvořit index nový a data do něj přelít."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co se týče mazání indexu, syntax je následující:\n",
    "```\n",
    "DELETE jmeno-indexu\n",
    "```\n",
    "Návratová hodnota má podobu\n",
    "```\n",
    "{\n",
    "  \"acknowledged\" : true\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakonec ještě uveďmě dotaz zobrazující přehled již vytvořených indexů:\n",
    "```\n",
    "GET _cat/indices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vkládání dokumentů do indexu\n",
    "Dokument můžeme do indexu vložit buďto pomocí POSTu, jako jsme to už udělali výše, anebo pomocí PUTu.\n",
    "Výše uvedenou POSTovskou syntax můžeme použít i když chceme vložit dokument do již existujícího indexu.\n",
    "```\n",
    "POST jmeno-indexu/_doc\n",
    "{\n",
    "  \"jmeno_pole\": hodnota_pole\n",
    "}\n",
    "```\n",
    "Když se podíváme na návratovou zprávu, vidíme, že se pro dokument vytvořilo automaticky IDčko.\n",
    "```\n",
    "{\n",
    "  \"_index\" : \"pokusny_index_2\",\n",
    "  \"_type\" : \"_doc\",\n",
    "  \"_id\" : \"VBJhS3sBihumCpkYEcp1\",\n",
    "  \"_version\" : 1,\n",
    "  \"result\" : \"created\",\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 2,\n",
    "    \"successful\" : 1,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"_seq_no\" : 2,\n",
    "  \"_primary_term\" : 2\n",
    "}\n",
    "```\n",
    "Nicméně IDčko můžeme specifikovat i explicitně a to tak, že za \\_doc přidáme dopředné lomítko a ID, tj.\n",
    "```\n",
    "POST jmeno-indexu/_doc/zvolene_idcko\n",
    "{\n",
    "  \"jmeno_pole\": hodnota_pole\n",
    "}\n",
    "```\n",
    "Pakliže ale na to samé IDčko pošleme jiný záznam, provede se update - nahrazení starého záznamu novým. V návratové zprávě se pole \"result\" z \"created\" změní na \"updated\" a číslo u položky \"\\_version\" se zvýší o jedna.\n",
    "```\n",
    "{\n",
    "  \"_index\" : \"pokusny_index_2\",\n",
    "  \"_type\" : \"_doc\",\n",
    "  \"_id\" : \"5\",\n",
    "  \"_version\" : 3,\n",
    "  \"result\" : \"updated\",\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 2,\n",
    "    \"successful\" : 1,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"_seq_no\" : 7,\n",
    "  \"_primary_term\" : 2\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pakliže si chceme být jisti, že k přepisu stávajícího dokumentu nedopatřením nedojde, musíme použít lehce odlišný endpoint - namísto \"\\_doc\" aplikujeme \"\\_create\", například takto:\n",
    "```\n",
    "POST pokusny_index_2/_create/6\n",
    "{\n",
    "  \"prvni_pole\": 6,\n",
    "  \"druhe_pole\": 600\n",
    "}\n",
    "```\n",
    "Pokud není příslušné IDčko zabrané, dokument se uloží. Pokud už ale dané IDčko používáno je, vrátí se návratový kód 409 a chybová zpráva\n",
    "```\n",
    "{\n",
    "  \"error\" : {\n",
    "    \"root_cause\" : [\n",
    "      {\n",
    "        \"type\" : \"version_conflict_engine_exception\",\n",
    "        \"reason\" : \"[6]: version conflict, document already exists (current version [1])\",\n",
    "        \"index_uuid\" : \"d5UL-uBJT3qjaTz_sKQ4IA\",\n",
    "        \"shard\" : \"0\",\n",
    "        \"index\" : \"pokusny_index_2\"\n",
    "      }\n",
    "    ],\n",
    "    \"type\" : \"version_conflict_engine_exception\",\n",
    "    \"reason\" : \"[6]: version conflict, document already exists (current version [1])\",\n",
    "    \"index_uuid\" : \"d5UL-uBJT3qjaTz_sKQ4IA\",\n",
    "    \"shard\" : \"0\",\n",
    "    \"index\" : \"pokusny_index_2\"\n",
    "  },\n",
    "  \"status\" : 409\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do jisté míry se POSTu podobá PUT. Jeho základní syntaxí je \n",
    "```\n",
    "PUT jmeno-indexu/_doc/zvolene_idcko\n",
    "{\n",
    "  \"jmeno_pole\": hodnota_pole\n",
    "}\n",
    "```\n",
    "Stejně jako v POSTu funguje výměna \\_doc za \\_create. Co ale nefunguje je použití PUTu bez specifikování IDčka - tehdy obdržíme chybu \n",
    "```\n",
    "{\n",
    "  \"error\" : \"Incorrect HTTP method for uri [/pokusny_index_2/_doc?pretty=true] and method [PUT], allowed: [POST]\",\n",
    "  \"status\" : 405\n",
    "}\n",
    "```\n",
    "Obecně by asi bylo nejčistější použít POST na vytvoření nového dokumentu a PUT na jeho případný update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatím jsme řešili manuální vkládání dokumentů do elasticu jeden po druhém. Kibana ale dovoluje vložit najednou celý soubor. To se provádí tlačítkem \"Upload a file\" na úvodní stránce Kibany (tlačítko je pod velkou modrou Kibana dlaždicí). Sluší se podotknout, že i když elastic dokumenty ukládá jako jsony, srovná se i s tím, když mu člověk podhodí csvčko (data si na json sám zkonvertuje). Nicméně je zde jedna zrada - jsony musí být ve formátu ndjson. To znamená, že na každém řádku je validní json a tyto jsony jsou odděleny pouze znakem nového řádku (tj. žádná čárka). Příkladem budiž toto:\n",
    "```\n",
    "{\"date\": \"-300\", \"description\": \"Pilgrims travel to the healing temples of Asclepieion to be cured of their ills. After a ritual purification the followers bring offerings or sacrifices.\", \"lang\": \"en\", \"category1\": \"By place\", \"category2\": \"Greece\", \"granularity\": \"year\"}\n",
    "{\"date\": \"-300\", \"description\": \"Pyrrhus, the King of Epirus, is taken as a hostage to Egypt after the Battle of Ipsus and makes a diplomatic marriage with the princess Antigone, daughter of Ptolemy and Berenice.\", \"lang\": \"en\", \"category1\": \"By place\", \"category2\": \"Egypt\", \"granularity\": \"year\"}\n",
    "{\"date\": \"-300\", \"description\": \"Ptolemy concludes an alliance with King Lysimachus of Thrace and gives him his daughter Arsinoe II in marriage.\", \"lang\": \"en\", \"category1\": \"By place\", \"category2\": \"Egypt\", \"granularity\": \"year\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vyhledávání v dokumentech "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro příklady vyhledávání v dokumentech použijeme dataset \"Historical events\" [https://github.com/jdorfman/awesome-json-datasets#historical-events](odtud). Je zde ale drobná komplikace - tento json není ve formátu ndjson. Aby ho elastic byl schopen zpracovat, musí se jednak ze začátku souboru odstranit\n",
    "```\n",
    "{\"result\": {\"count\": \"37859\" \n",
    "```\n",
    "a dále musí zmizet dvě uzavírající složené závorky na konci souboru. Hlavně ale musí být každý výskyt\n",
    "```\n",
    ", \"event\": \n",
    "```\n",
    "nahrazen znakem nového řádku.  \n",
    "Pro čtení záznamů existují dva endpointy - \\_doc a \\_search. Význam \\_doc spočívá v tom, že nám umožňuje najít záznam na základě jeho id - připomeňme, že pokud id nezadáme explicitně při vzniku záznamu, vytvoří si ho Elastic sám. A to i při nahrávání souboru s hromadou záznamů. Podoba requestu je následující\n",
    "```\n",
    "GET jmeno-indexu/_doc/zvolene-idcko\n",
    "```\n",
    "v praxi tedy například\n",
    "```\n",
    "GET historic_events/_doc/gNEWansB2kiDSx5Po1A5\n",
    "```\n",
    "přičemž výsledkem je\n",
    "```\n",
    "{\n",
    "  \"_index\" : \"historic_events\",\n",
    "  \"_type\" : \"_doc\",\n",
    "  \"_id\" : \"gNEWansB2kiDSx5Po1A5\",\n",
    "  \"_version\" : 1,\n",
    "  \"_seq_no\" : 0,\n",
    "  \"_primary_term\" : 1,\n",
    "  \"found\" : true,\n",
    "  \"_source\" : {\n",
    "    \"date\" : \"-300\",\n",
    "    \"description\" : \"Pilgrims travel to the healing temples of Asclepieion to be cured of their ills. After a ritual purification the followers bring offerings or sacrifices.\",\n",
    "    \"lang\" : \"en\",\n",
    "    \"category1\" : \"By place\",\n",
    "    \"category2\" : \"Greece\",\n",
    "    \"granularity\" : \"year\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "Search endpoint má využití širší. Jeho použití bez čehokoli dalšího vede k ukázání základních statistických informací a (defaultně) deseti prvních záznamů z indexu. Tj. člověk zadá např.\n",
    "```\n",
    "GET historic_events/_search\n",
    "```\n",
    "a vrátí se mu následující (pro přehlednost jsou druhý až desátý záznam odstraněny)\n",
    "```\n",
    "{\n",
    "  \"took\" : 6,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 10000,\n",
    "      \"relation\" : \"gte\"\n",
    "    },\n",
    "    \"max_score\" : 1.0,\n",
    "    \"hits\" : [\n",
    "      {\n",
    "        \"_index\" : \"historic_events\",\n",
    "        \"_type\" : \"_doc\",\n",
    "        \"_id\" : \"gNEWansB2kiDSx5Po1A5\",\n",
    "        \"_score\" : 1.0,\n",
    "        \"_source\" : {\n",
    "          \"date\" : \"-300\",\n",
    "          \"description\" : \"Pilgrims travel to the healing temples of Asclepieion to be cured of their ills. After a ritual purification the followers bring offerings or sacrifices.\",\n",
    "          \"lang\" : \"en\",\n",
    "          \"category1\" : \"By place\",\n",
    "          \"category2\" : \"Greece\",\n",
    "          \"granularity\" : \"year\"\n",
    "        }\n",
    "      },\n",
    "...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "Co se to vlastně v úvodu odpovědi objevuje? Took říká, kolik milisekund zpracování dotazu na straně Elasticu zabralo. Time_out odpoví na dotaz, zda došlo k time outu. Sekce \\_shards se týká toho, s kolika shardy (a s jakým úspěchem) se při práci na dotazu muselo pracovat. V sekci \"hits\" máme položku value. Ta by měla říkat, kolik záznamu odpovídá požadavkům v search requestu. Nicméně 10000 je až podezřele kulaté číslo. Jak moc mu můžeme věřit říká položka \"relations\". Pokud je rovna \"eq\", je hodnota \"value\" přesná, pokud má ale hodnotu \"gte\", je faktický počet záznamu větší než (greather than) číslo ve \"value\". Pokud bychom chtěli znát přesný počet záznamů u větších datasetů, museli bychom použít flag \"track_total_hits\":\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"track_total_hits\": true\n",
    "}\n",
    "```\n",
    "Poté by v sekci \"hits\" bylo něco ve stylu\n",
    "```\n",
    "    \"total\" : {\n",
    "      \"value\" : 37858,\n",
    "      \"relation\" : \"eq\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query\n",
    "##### match a match_phrase\n",
    "Pro vyhledávání slov a frází se dá použít kombinace klíčových slov query a match resp. match_phrase. Template pro syntax je následující \n",
    "```\n",
    "GET jmeno-indexu/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\":{\n",
    "      \"jmeno-prohledavaneho-pole\":{\n",
    "        \"query\": \"hledana slova\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "V praxi to vypadá takto:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman empire\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Poznamenejme, že matchnuty jsou záznamy, které obsahují aspoň jedno slovo z druhé \"query\", a že velikost písmen nehraje roli.  \n",
    "Všimněme si, že výstup - prvních X záznamů - je seřazen podle \\_score. Veličina \\_score zde představuje více méně TF-IDF metriku (viz notebook o zpracování textu v tomto repozitáři). Pakliže bychom hledali namísto \"Roman empire\" řetězec \"empire Roman\", výsledek by byl totožný. To je umožněno tím, že pole \"description\" má datový typ \"text\". Pokud bychom stejnou věc chtěli vyzkoušet u pole \"category2\" mající typ keyword, tak by byl v druhém případě počet odpovídajících dokumentů 0.  \n",
    "Pokud chceme vidět problémy této query, nesmíme koukat na záznamy s nějvětším skore, ale na ty se skorem nejnižším. Tj. musíme podle \\_score provést ascending sortění. To uskutečníme tak, že na úroveň query dáme další klíčové slovo a to sice \"sort\":\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"sort\": { \"_score\": { \"order\": \"asc\" }}\n",
    "}\n",
    "```\n",
    "Vidíme, že záznamy s nízkým skore se Římského impéria netýkají. Nicméně jelikož se v nich vyskytují slova \"Roman\" a \"Empire\" (často v jiných větách, někdy dokonce jedno z nich absentuje), jsou tyto dokumenty stále matchnuty. Pokud ale chceme nalézt jen dokumenty určitou frázi (např. \"Roman empire\") obsahující, musíme \"match\" zaměnit za \"match_phrase\".\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match_phrase\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"sort\": { \"_score\": { \"order\": \"asc\" }}\n",
    "}\n",
    "```\n",
    "Vidíme, že počet záznamů klesnul na cca desetinu, ale i ty záznamy s nejnižším skorem sousloví \"Roman empire\" obsahují (i když se jedná o Svatou říši římskou, což je přeci jen jiný státní útvar). Samozřejmě u match_phrase prohození \"Roman\" a \"Empire\" povede k nulovému počtu nalezených dokumentů.  \n",
    "Vraťme se ale od \"match_phrase\" zpět k \"match\". Viděli jsme, že při zpracování slov v poli \"query\" jsou tato slova oddělena podle mezer a následně se matchnou dokumenty obsahující aspoň jedno z těchto slov. Co ale máme dělat v případě, kdy chceme matchnut pouze dokumenty obsahující *všechna* slova z query, avšak netrváme na tom, aby se tato slvoa nacházela těsně vedle sebe? V takovém případě obohatíme dotaz o pole \"operator\" s hodnotou \"and\", které bude na stejné úrovni jako druhé \"query\":\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\",\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"sort\": { \"_score\": { \"order\": \"asc\" }}\n",
    "}\n",
    "```\n",
    "Existuje ještě třetí cesta, kdy specifikujeme, že chceme dokumenty obsahující aspoň X slov z query. Pro to použijeme pole \"minimum_should_match\" mající za hodnotu právě ono číslo X.\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire republic\",\n",
    "        \"minimum_should_match\": \"2\"\n",
    "        \n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"sort\": { \"_score\": { \"order\": \"asc\" }}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Všimněme si, že pro matchnuté dokumenty se zobrazily všechny pole (všechny fieldy) a to sice v skeci \"\\_source\". Pokud chceme mít ve výsledku pouze určitá pole, musíme do dotazu na tu samou úroveň, na které se nalézá \"query\", přidat sekci \"fields\". Do té poté do hranatých závorek vložíme názvy chtěných polí. \n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match_phrase\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"fields\": [\"date\", \"category2\", \"nonexisting_field\"]\n",
    "}\n",
    "```\n",
    "Nyní ve výstupu vidíme sekci fields, které obsahuje ty informace, které potřebujeme. Nicméně krom toho jsou ve výstupu i všechna pole v sekci \"\\_source\". Abychom se toho zbavili, musíme do dotazu na úroveň stejnou s \"query\" a \"fields\" přidat \"\\_source\" s hodnotou false:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"_source\":false,\n",
    "  \"query\": {\n",
    "    \"match_phrase\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"fields\": [\"date\", \"category2\", \"nonexisting_field\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### multi_match\n",
    "Může natat situace, kdy budeme slova hledat ve více polích. Tehdy namísto matche použijeme multi_match. Základní struktura takového dotazu vypadá takto:\n",
    "```\n",
    "GET jmeno-indexu/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "        \"query\": \"chtena slova\",\n",
    "        \"fields\": [\"prvni_pole\", \"druhe_pole\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Praktický příklad:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "        \"query\": \"Hamburg Prussia\",\n",
    "        \"fields\": [\"category2\", \"description\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Může se stát, že budeme chtít dát jednomu poli větší váhu než polím jiným. To zrealizujeme tak, že v sekci \"fields\" vložíme za jméno pole \"umocňovátko\" (stříšku) a za to stupeň \"umocnění\" (stříška i číslo bude pořád v dvojitých závorkách příslušejících jménu pole).\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "        \"query\": \"Hamburg Prussia\",\n",
    "        \"fields\": [\"category2^2\", \"description\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Co ale v případě, kdy potřebujeme ve více polích hledát fráze? Nemusíme vymýšlet žádné multi_match_phrase, pořád nám vystačí multi_match, pouze do něj přidáme nové pole \"type\" s hodnotou \"phrase\".\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "        \"query\": \"Roman Republic\",\n",
    "        \"fields\": [\"category2^2\", \"description\"],\n",
    "        \"type\": \"phrase\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bool\n",
    "Co když ale chceme ještě složitější dotazy - například co když požadujeme přítomnost uručtého slova v jednom poli a přítomnost slova jiného v jiném poli? Tehdy musíme použít bool query. Podsekcí boolu bude \"must\", které v sobě může obsahovat jak \"match\", tak \"match_phrase\". Platí přitom, že vnitřnosti \"must\" jsou v hranatých závorkách.\n",
    "```\n",
    "GET jmeno-indexu/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"match_phrase\": {\n",
    "          \"jmeno_pole\": \"fraze\"\n",
    "        }},\n",
    "        {\"match\": {\n",
    "          \"jmeno_jineho_pole\": \"hledana slova\"\n",
    "        }}\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Praktický příklad:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"match_phrase\": {\n",
    "          \"description\": \"civil war\"\n",
    "        }},\n",
    "        {\"match\": {\n",
    "          \"category2\": \"Roman Empire\"\n",
    "        }}\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Současně lze i specifikovat slova/fráze, která ve vrácených dokumentech být nemají:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"match_phrase\": {\n",
    "          \"description\": \"Roman Empire\"\n",
    "        }}\n",
    "      ],\n",
    "      \"must_not\": [\n",
    "         {\"match_phrase\": {\n",
    "          \"description\": \"Roman Republic\"\n",
    "        }}\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "K \"must\" a \"must_not\" je příbuzné klíčové slovo \"should\". Slova a fráze v \"should\" nejsou povinná, nicméně dokumenty je obsahující dostanou vyšší skore.\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"match_phrase\": {\n",
    "          \"description\": \"Roman Republic\"\n",
    "        }}\n",
    "      ],\n",
    "      \"should\": [\n",
    "         {\"match\": {\n",
    "          \"description\": \"war\"\n",
    "        }}\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should může fakticky fungovat v ještě jednom módu. Zatímco podmínky v must jsou de facto svázány tak, jako by mezi sebou měly AND vztah, podmínky v should se mohou chovat, jako by byly spojeny OR vztahem. To se dá vynutit parametrem \"minimum_should_match\" s hodnotou 1, kterýžto je na stejné úrovni jako \"should\" sekce:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"match_phrase\": {\n",
    "          \"description\": \"civil war\"\n",
    "        }}\n",
    "      ], \n",
    "      \"should\":[\n",
    "        {\"match\": {\"category1\": \"September\"}},\n",
    "        {\"match\": {\"category1\": \"May\"}}\n",
    "        ],\n",
    "      \"minimum_should_match\":1  \n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "BTW pakliže není v query přítomno must (či filter), chová se defaultně should, jako by minimum_should_match bylo rovno jedné. Jinak je defaultní hodnota tohoto parametru 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregace\n",
    "Někdy nepotřebujeme znát obsah záznamů vyhovujících nějaké podmínce, ale musíme vědět, kolik takových záznamů v daném indexu vlastně existuje. Případně chceme spočítat průměr, sumu či nějakou další metriku odvoditelnou z hodnot nějakého sloupce. Tehdy mluvíme o agregacích.  \n",
    "Pro spočítání záznamů s určitou hodnotou sloupce se použije předpis\n",
    "```\n",
    "GET jmeno-indexu/_search\n",
    "{\n",
    "  \"aggs\": {\n",
    "    \"nazev_sekce_odpovedi\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"jmeno-sloupce-podle-ktereho-se-agreguje\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Praktický příklad:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"category2\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Odpověď Elasticu se skládá ze tří částí. Nejprve jsou zobrazena metadata, potom je v sekci \"hits\" defaultně ukázáno 10 záznamů z indexu až poté se k sekci \"aggregations\" objeví deset nejzastoupenějších záznamů. No, jo, ale co dělat, když \"hits\" zobrazovat nechceme a počet ukázaných zagregovaných tříd si chceme nastavit sami?  \n",
    "Abychom se zbavili ukázek záznamů, musíme před \"aggs\" na stejnou úroveň přidat parametr \"size\" s hodnotou 0:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"category2\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Pokud chceme specifikovat maximální počet ukázaných tříd, opět použijeme parametr \"size\", který ale tentokrát umístíme na úroveň pole \"field\":\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"category2\",\n",
    "        \"size\": 3\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Výsledkem je pak následující odpověď Elasticu:\n",
    "```\n",
    "{\n",
    "  \"took\" : 2,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 10000,\n",
    "      \"relation\" : \"gte\"\n",
    "    },\n",
    "    \"max_score\" : null,\n",
    "    \"hits\" : [ ]\n",
    "  },\n",
    "  \"aggregations\" : {\n",
    "    \"pocty_zaznamu\" : {\n",
    "      \"doc_count_error_upper_bound\" : 0,\n",
    "      \"sum_other_doc_count\" : 4078,\n",
    "      \"buckets\" : [\n",
    "        {\n",
    "          \"key\" : \"Europe\",\n",
    "          \"doc_count\" : 2182\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"Roman Empire\",\n",
    "          \"doc_count\" : 1820\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"Asia\",\n",
    "          \"doc_count\" : 1506\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Dosti rozumný je požadavek, aby agregace proběhly na už předfiltrované množině dat. Jazykem SQLka to znamená použít GROUP BY současně s WHERE podmínkou. Například pokud bychom z nějakého záhadného důvodu chtěli odfiltrovat všechny třídy až na jednu a nad výsledkem této selekce udělat agregaci, provedli bychom to takto:\n",
    "```\n",
    "GET historic_events/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"category2\": \"Roman Republic\"\n",
    "    }\n",
    "  },\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"category2\",\n",
    "        \"size\": 30\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Jelikož index s historickými událostmi neobsahuje žádná čísla, u kterých by artimetické operace dávaly smysl, budeme chvíli pracovat s indexem iris_from_csv. Pokud chceme spočítat průměrnou hodnotou nějakého sloupce, použijeme následující šablonu:\n",
    "```\n",
    "GET jmeno-indexu/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"nazev_sekce_odpovedi\": {\n",
    "      \"avg\": {\n",
    "        \"field\": \"jmeno-sloupce-podle-ktereho-se-agreguje\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Praktická ukázka:\n",
    "```\n",
    "GET iris_from_csv/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"prumer_sepa_width\": {\n",
    "      \"avg\": {\n",
    "        \"field\": \"sepal_width\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Na místě \"avg\" by mohly být i \"sum\", \"min\", \"max\" či třeba \"cardinality\" (ukáže počet unikátních hodnot). Pokud bychom chtěli najednou ukázat počet záznamů, jejich sumu a nejmenší, největší a  průměrný záznam, použili bychom \"stats\". Pakliže ale chceme mít vedle sebe jen některé agregace (které ani nemusí být součástí \"stats\"), umístíme bloky dvou pojmenovaných agregací na stejnou úroveň. Na příkladu níže se jednak počítá výskyt hodnot ve sloupečku \"species\", jednak se (přes všechny \"species\") spočítá průměrný \"sepal_length\":\n",
    "```\n",
    "GET iris_from_csv/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"species\"\n",
    "      }\n",
    "    },\n",
    "    \"prumer_sepal_length\": {\n",
    "      \"avg\": {\n",
    "        \"field\": \"sepal_length\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Takto vypadá výsledek:\n",
    "```\n",
    "{\n",
    "  \"took\" : 2,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 149,\n",
    "      \"relation\" : \"eq\"\n",
    "    },\n",
    "    \"max_score\" : null,\n",
    "    \"hits\" : [ ]\n",
    "  },\n",
    "  \"aggregations\" : {\n",
    "    \"pocty_zaznamu\" : {\n",
    "      \"doc_count_error_upper_bound\" : 0,\n",
    "      \"sum_other_doc_count\" : 0,\n",
    "      \"buckets\" : [\n",
    "        {\n",
    "          \"key\" : \"setosa\",\n",
    "          \"doc_count\" : 50\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"versicolor\",\n",
    "          \"doc_count\" : 50\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"virginica\",\n",
    "          \"doc_count\" : 49\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"prumer_sepal_length\" : {\n",
    "      \"value\" : 5.842953020134228\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Pokud bychom ale chtěli spočítat průměrnou \"sepal_length\" pro každý typ kosatce, musíme do prvního \"aggs\" vložit druhé \"aggs\" na úroveň prvního uživatelem pojmenovaného pole:\n",
    "```\n",
    "GET iris_from_csv/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"pocty_zaznamu\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"species\"\n",
    "      },\n",
    "      \"aggs\": {\n",
    "        \"prumer_sepal_length\": {\n",
    "          \"avg\": {\n",
    "            \"field\": \"sepal_length\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Výsledná odpověď:\n",
    "```\n",
    "{\n",
    "  \"took\" : 1,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 149,\n",
    "      \"relation\" : \"eq\"\n",
    "    },\n",
    "    \"max_score\" : null,\n",
    "    \"hits\" : [ ]\n",
    "  },\n",
    "  \"aggregations\" : {\n",
    "    \"pocty_zaznamu\" : {\n",
    "      \"doc_count_error_upper_bound\" : 0,\n",
    "      \"sum_other_doc_count\" : 0,\n",
    "      \"buckets\" : [\n",
    "        {\n",
    "          \"key\" : \"setosa\",\n",
    "          \"doc_count\" : 50,\n",
    "          \"prumer_sepal_length\" : {\n",
    "            \"value\" : 5.006\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"versicolor\",\n",
    "          \"doc_count\" : 50,\n",
    "          \"prumer_sepal_length\" : {\n",
    "            \"value\" : 5.936\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"virginica\",\n",
    "          \"doc_count\" : 49,\n",
    "          \"prumer_sepal_length\" : {\n",
    "            \"value\" : 6.6020408163265305\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Proberme ještě range agregaci. Ta funguje tím způsobem, že uživatel specifikuje sloupec a intervaly hodnot v něm a Elastic spočítá, kolik záznamů patří do jakého intervalu:\n",
    "```\n",
    "GET iris_from_csv/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"range_sepal_length\": {\n",
    "      \"range\": {\n",
    "        \"field\": \"sepal_length\",\n",
    "        \"ranges\": [\n",
    "          {\n",
    "            \"to\": 2\n",
    "          },\n",
    "          {\n",
    "            \"from\": 2.01,\n",
    "            \"to\": 5\n",
    "          },\n",
    "          {\n",
    "            \"from\": 5.01\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Odpověď Elasticu:\n",
    "```\n",
    "{\n",
    "  \"took\" : 102,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 149,\n",
    "      \"relation\" : \"eq\"\n",
    "    },\n",
    "    \"max_score\" : null,\n",
    "    \"hits\" : [ ]\n",
    "  },\n",
    "  \"aggregations\" : {\n",
    "    \"range_sepal_length\" : {\n",
    "      \"buckets\" : [\n",
    "        {\n",
    "          \"key\" : \"*-2.0\",\n",
    "          \"to\" : 2.0,\n",
    "          \"doc_count\" : 0\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"2.01-5.0\",\n",
    "          \"from\" : 2.01,\n",
    "          \"to\" : 5.0,\n",
    "          \"doc_count\" : 22\n",
    "        },\n",
    "        {\n",
    "          \"key\" : \"5.01-*\",\n",
    "          \"from\" : 5.01,\n",
    "          \"doc_count\" : 117\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Pokud nechceme specifikovat kraje intervalů, ale pouze jejich velikost, můžeme použít typ agregace zvaný histogram:\n",
    "```\n",
    "GET iris_from_csv/_search\n",
    "{\n",
    "  \"size\": 0,\n",
    "  \"aggs\": {\n",
    "    \"histogram_sepal_length\": {\n",
    "      \"histogram\": {\n",
    "        \"field\": \"sepal_length\",\n",
    "        \"interval\": 1.5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Odezva Elasticu:\n",
    "```\n",
    "{\n",
    "  \"took\" : 1,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "      \"value\" : 149,\n",
    "      \"relation\" : \"eq\"\n",
    "    },\n",
    "    \"max_score\" : null,\n",
    "    \"hits\" : [ ]\n",
    "  },\n",
    "  \"aggregations\" : {\n",
    "    \"histogram_sepal_length\" : {\n",
    "      \"buckets\" : [\n",
    "        {\n",
    "          \"key\" : 3.0,\n",
    "          \"doc_count\" : 4\n",
    "        },\n",
    "        {\n",
    "          \"key\" : 4.5,\n",
    "          \"doc_count\" : 78\n",
    "        },\n",
    "        {\n",
    "          \"key\" : 6.0,\n",
    "          \"doc_count\" : 61\n",
    "        },\n",
    "        {\n",
    "          \"key\" : 7.5,\n",
    "          \"doc_count\" : 6\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T14:14:55.028969Z",
     "start_time": "2021-10-29T14:14:55.013351Z"
    }
   },
   "source": [
    "#### Scroll\n",
    "Maximální dovolené množství záznamů, které Elastic vrátí (a které se nastavuje s pomocí \"size\": cislena_hodnota), je 10 000. Co ale když potřebujeme záznamů více? Co když chceme určitá pole z celého indexu vyexportovat do Pythonu a tam s nimi pracovat? Tehdy musíme použít \\_search endpoint s parametrem **scroll**. Díky němu můžeme data z indexu postupně po jednotlivých batchích vytahat.  \n",
    "Prvotní provolání vypadá jako normální volání, pouze se za searchem objevuje \"scroll=delka_sessiony\". Co to ta délka sessiony je? Napojení na index v tomto případě není po jednom volání ukončeno, ale po určitý čas existuje a čeká na případná další provolání. Po uplynutí uživatelem specifikovaného času se napojení automaticky uzavře. Zdůrazněme, že tento odpočet se resetuje při každém dodatečném volání - není to tak, že by všechna volání musela doběhnout za čas uvedený ve volání prvotním.\n",
    "Příklad provolání:\n",
    "```\n",
    "GET historic_events/_search?scroll=15s\n",
    "{\n",
    "  \"size\": 3,\n",
    "  \"_source\": false,\n",
    "  \"query\": {\n",
    "    \"match_phrase\":{\n",
    "      \"description\":{\n",
    "        \"query\": \"Roman Empire\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"fields\": [\"date\", \"category2\", \"nonexisting_field\"]\n",
    "}\n",
    "```\n",
    "Ve výstupu pak vidíme krom obvyklých polí i scroll_id. To je právě identifikátor sessiony, který budeme potřebovat pro provolání následná.\n",
    "```\n",
    "{\n",
    "  \"_scroll_id\" : \"FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFmVEQjcyNlFDU0lHQVA0RVdvdUlFVGcAAAAAAAAGfxZzSkZZYW1WNFFHT0s3SUgxT3IyQTVB\",\n",
    "  \"took\" : 2,\n",
    "  \"timed_out\" : false,\n",
    "  \"_shards\" : {\n",
    "    \"total\" : 1,\n",
    "    \"successful\" : 1,\n",
    "    \"skipped\" : 0,\n",
    "    \"failed\" : 0\n",
    "  },\n",
    "  \"hits\" : {\n",
    "    \"total\" : {\n",
    "  dál jako obvykle\n",
    "```\n",
    "Následná provolání pak vypadají takto:\n",
    "```\n",
    "GET _search/scroll\n",
    "{\n",
    "  \"scroll\":\"15s\",\n",
    "  \"scroll_id\":\"FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFmVEQjcyNlFDU0lHQVA0RVdvdUlFVGcAAAAAAAAI0xZzSkZZYW1WNFFHT0s3SUgxT3IyQTVB\"\n",
    "}\n",
    "```\n",
    "Tj. endpointem je scroll, nikoli \\_search, a žádné dodatečné parametry tu nevystupují. V těle volání je pouze scroll_id identifikující sessionu a scroll, který říká, jak dlouho po konci tohoto volání má být sessiona ještě otevřená. Všechny ostatní informace - jméno indexu, specifikace query atd. jsou už uloženy v sessioně.  \n",
    "Pakliže není v čase určeném v parametru \"scroll\" další volání uskutečněno a objeví se až ex post, dostane člověk místo dat následující errorovou hlášku:\n",
    "```\n",
    "{\n",
    "  \"error\" : {\n",
    "    \"root_cause\" : [\n",
    "      {\n",
    "        \"type\" : \"search_context_missing_exception\",\n",
    "        \"reason\" : \"No search context found for id [1663]\"\n",
    "      }\n",
    "    ],\n",
    "    \"type\" : \"search_phase_execution_exception\",\n",
    "    \"reason\" : \"all shards failed\",\n",
    "    \"phase\" : \"query\",\n",
    "    \"grouped\" : true,\n",
    "    \"failed_shards\" : [\n",
    "      {\n",
    "        \"shard\" : -1,\n",
    "        \"index\" : null,\n",
    "        \"reason\" : {\n",
    "          \"type\" : \"search_context_missing_exception\",\n",
    "          \"reason\" : \"No search context found for id [1663]\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"caused_by\" : {\n",
    "      \"type\" : \"search_context_missing_exception\",\n",
    "      \"reason\" : \"No search context found for id [1663]\"\n",
    "    }\n",
    "  },\n",
    "  \"status\" : 404\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updaty a mazání záznamů\n",
    "Pro updatování záznamů se použije předpis\n",
    "```\n",
    "POST jmeno-indexu/_update/id-dokumentu\n",
    "{\n",
    "  \"doc\":{\n",
    "     \"prvni_updatovane_pole\":\"prvni_updatovana_hodnota\",\n",
    "     \"druhe_updatovane_pole\":\"druha_updatovana_hodnota\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "Například tedy:\n",
    "```\n",
    "POST pokusny_index_2/_update/5\n",
    "{\n",
    "  \"doc\": {\n",
    "    \"druhe_pole\": 412\n",
    "  }\n",
    "}\n",
    "```\n",
    "Zdůrazněme, že pro PUT výše uvedený postup nefunguje a že pokud pole upravit nechceme, prostě ho v příkazu nezmíníme. Rozdíl \\_update a \\_doc spočívá v tom, že s pomocím druhého zmíněného endpointu se upraví celý záznam, zatímco \\_update mění jen explicitně zmíněná pole.   \n",
    "Mazaní se provede prostřednictvím\n",
    "```\n",
    "DELETE jmeno-indexu/_doc/id-dokumentu\n",
    "```\n",
    "Tj. třeba:\n",
    "```\n",
    "DELETE pokusny_index_2/_doc/5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic a curl\n",
    "Curl je program spouštěný z příkazové řádky, který dokáže provolávat endpointy. To znamená, že jeho prostřednictvím můžeme pracovat s Elasticem i bez konzole v Kibaně.  \n",
    "Asi nejjednodušší je dotázat se s jeho pomocí na obsah dokumentu, známe-li jeho IDčko. Tehdy stačí napsat\n",
    "```\n",
    "curl http://localhost:9200/historic_events/_doc/gNEWansB2kiDSx5Po1A5\n",
    "```\n",
    "a jako odpověď obdržíme\n",
    "```\n",
    "{\"_index\":\"historic_events\",\"_type\":\"_doc\",\"_id\":\"gNEWansB2kiDSx5Po1A5\",\"_version\":1,\"_seq_no\":0,\"_primary_term\":1,\"found\":true,\"_source\": {\"date\": \"-300\", \"description\": \"Pilgrims travel to the healing temples of Asclepieion to be cured of their ills. After a ritual purification the followers bring offerings or sacrifices.\", \"lang\": \"en\", \"category1\": \"By place\", \"category2\": \"Greece\", \"granularity\": \"year\"}}\n",
    "```\n",
    "Co když ale chceme provést nějaké vyhledávání? Tehdy je řešením bohužel trochu nepřehledná variace na \n",
    "```\n",
    "curl -XGET --header \"Content-Type: application/json\" http://localhost:9200/historic_events/_search -d \"{\\\"query\\\" : {\\\"match\\\" : { \\\"description\\\": \\\"Roman empire\\\" }}}\"\n",
    "```\n",
    "Zdůrazněme, že výše uvedený kód by měl být jednořádkový (ve smyslu neměl by obsahovat znak nového řádku). Všiměte si, že je většina dvojitých uvozovek escapovaná zpětným lomítkem - neescapované uvozovky totiž specifikují, kde začíná a končí jsony, a bohužel kombinování jednoduchých a dvojitých uvozovek minimálně na Windowsech k cíly nevede. Stejně tak nepomohla snaha použít k nalepení jednotlivých řádků na sebe prostřednictvím znaků stříšky.     \n",
    "Co vlastně znamenají jednotlivé parametry curlu? Parametr -d prozrazuje, že za ním nacházející se věc jsou data. Header pak obsahuje informaci o tom, v jakém formátu ona data vlastně jsou. Jelikož posíláme json, musíme to zde i napsat, jinak bychom obdrželi chybu *{\"error\":\"Content-Type header [application/x-www-form-urlencoded] is not supported\",\"status\":406}*.  \n",
    "\n",
    "S parametrem -XGET je to trochu složitější. Provolání elasticu by totiž fungovalo i bez něho. Curl se totiž snaží na základě parametrů rozpoznat, o jaký typ requestu vlastně jde. Například první aplikace curlu na začátku této kapitoly žádný parametr neměla a tak curl usoudil, že se bude jednat o GET (můžeme ověřit přidáním nepovinného parametru --verbose). Nicméně u druhého příkladu si curl všiml, že používáme parametr -d, a tak usoudil, že se jedná o POST. Při aplikaci \\_search endpointu naštěstí GET a POST dávají stejné výsledky (viz [dokumentace](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html)), ale už z hlediska konzistence s předcházející části bychom přeci jen raději použili GET. No a to obstarává parametr -X s hodnotou GET (alias -XGET).  \n",
    "\n",
    "Pro přidání záznamu do indexu použijeme\n",
    "```\n",
    "curl --header \"Content-Type: application/json\" http://localhost:9200/pokusny_index_2/_doc -d \"{\\\"prvni_pole\\\": 7, \\\"druhe_pole\\\": 700}\"\n",
    "```\n",
    "Naopak pro smazání musíme použít volání\n",
    "```\n",
    "curl -XDELETE http://localhost:9200/pokusny_index_2/_doc/YSTVoXsB-GS4cL4lD-pI \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic a Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ačkoli pro Elastic existují v Pythonu dedikované knihovny, podíváme se zde na způsob, jak s tímto vyhledávacím enginem komunikovat standardním způsobem - prostřednictvím balíčku requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T13:21:46.616730Z",
     "start_time": "2021-09-02T13:21:43.484135Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro \"bezparametrové\" dotazy stačí zkonstruovat url, která bude předána jako parametr funkci get. Takto získaný výstup bude nejčitelnější při použití metody json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T13:21:55.041091Z",
     "start_time": "2021-09-02T13:21:53.852280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'historic_events',\n",
       " '_type': '_doc',\n",
       " '_id': 'gNEWansB2kiDSx5Po1A5',\n",
       " '_version': 1,\n",
       " '_seq_no': 0,\n",
       " '_primary_term': 1,\n",
       " 'found': True,\n",
       " '_source': {'date': '-300',\n",
       "  'description': 'Pilgrims travel to the healing temples of Asclepieion to be cured of their ills. After a ritual purification the followers bring offerings or sacrifices.',\n",
       "  'lang': 'en',\n",
       "  'category1': 'By place',\n",
       "  'category2': 'Greece',\n",
       "  'granularity': 'year'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticsearch_url = \"http://localhost:9200\"\n",
    "index_name = \"historic_events\"\n",
    "document_id = \"gNEWansB2kiDSx5Po1A5\"\n",
    "whole_url = elasticsearch_url + \"/\" + index_name + \"/_doc/\" + document_id\n",
    "response = requests.get(whole_url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro složitější dotazy bude potřeba jednak zkonstruovat query, která bude funkci *get* předána v parametru data, a jednak informaci o formátu dat, která se předá v parametru header. Zdůrazněme, že zatímco data pro hlavičku requestu mají podobu slovníku, query je reprezentována stringem, jehož vnitřek json pravda připomíná."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T13:43:58.632346Z",
     "start_time": "2021-09-02T13:43:58.604349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 6,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 2142, 'relation': 'eq'},\n",
       "  'max_score': 9.734037,\n",
       "  'hits': [{'_index': 'historic_events',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'M9EWansB2kiDSx5Po1tP',\n",
       "    '_score': 9.734037,\n",
       "    '_source': {'date': '172',\n",
       "     'description': 'Montanism spreads through the Roman Empire.',\n",
       "     'lang': 'en',\n",
       "     'category1': 'By topic',\n",
       "     'category2': 'Religion',\n",
       "     'granularity': 'year'}},\n",
       "   {'_index': 'historic_events',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'V9EWansB2kiDSx5Po1ZJ',\n",
       "    '_score': 9.469765,\n",
       "    '_source': {'date': '-16',\n",
       "     'description': 'Noricum is incorporated into the Roman Empire.',\n",
       "     'lang': 'en',\n",
       "     'category1': 'By place',\n",
       "     'category2': 'Roman Empire',\n",
       "     'granularity': 'year'}}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticsearch_url = \"http://localhost:9200\"\n",
    "query_params = '{\"size\":2, \"query\" : {\"match\" : {\"description\": \"Roman empire\"}}}'\n",
    "index_name = \"historic_events\"\n",
    "whole_url = elasticsearch_url + \"/\" + index_name + \"/_search\"\n",
    "header_json = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.get(whole_url, data=query_params, headers=header_json)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obdobným způsobem funguje i přidávání dokumentů do indexů, i jejich mazání."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T14:12:40.233653Z",
     "start_time": "2021-09-02T14:12:39.571610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'pokusny_index_2',\n",
       " '_type': '_doc',\n",
       " '_id': 'J-vapnsB2tj4EOjbwu4f',\n",
       " '_version': 1,\n",
       " 'result': 'created',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 16,\n",
       " '_primary_term': 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticsearch_url = \"http://localhost:9200\"\n",
    "new_document = '{\"prvni_pole\": 8, \"druhe_pole\": 800}'\n",
    "index_name = \"pokusny_index_2\"\n",
    "whole_url = elasticsearch_url + \"/\" + index_name + \"/_doc\"\n",
    "header_json = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(whole_url, data=new_document, headers=header_json)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T14:15:57.985376Z",
     "start_time": "2021-09-02T14:15:57.525377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'pokusny_index_2',\n",
       " '_type': '_doc',\n",
       " '_id': 'J-vapnsB2tj4EOjbwu4f',\n",
       " '_version': 2,\n",
       " 'result': 'deleted',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 17,\n",
       " '_primary_term': 14}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticsearch_url = \"http://localhost:9200\"\n",
    "document_id = \"J-vapnsB2tj4EOjbwu4f\"\n",
    "index_name = \"pokusny_index_2\"\n",
    "whole_url = elasticsearch_url + \"/\" + index_name + \"/_doc/\" + document_id\n",
    "response = requests.delete(whole_url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kibana\n",
    "#### Export obsahu indexu do csvčka\n",
    "Pokud chceme převést obsah indexu do csv souboru, můžeme pro to použít Kibanu. Nejprve musíme v hlavním menu (tři vodorovné čáry vlevo nahoře) kliknout na \"Discover\" (sekce \"Analytics\").\n",
    "![index_to_csv_1](elastic_figures/csv_1.png)\n",
    "Následně vybereme index a jeho pole, které chceme do csvčka dostat. Máme přitom i možnost použít KQL (Kibaní dotazovací jazyk) - to se zapisuje do řádku vedle diskety. Například pokud chceme mít v csvčku pouze položky, u kterých bylo v poli \"species\" zapsáno \"versicolor\", napíšeme do tohoto řádku\n",
    "```\n",
    "species:\"versicolor\"\n",
    "```\n",
    "![index_to_csv_2](elastic_figures/csv_2.png)\n",
    "Následně je třeba tuto věc uložit - bez toho vytvoření csvčka nebude umožněno. Posléze už lze pomocí tlačítka \"Share\" ->\"CSV Reports\" csvčko stáhnout.\n",
    "![index_to_csv_3](elastic_figures/csv_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logstash\n",
    "Asi nejpoužívánější způsob, jak dostat do Elasticsearche data, je spojen s aplikací Logstash. Nicméně modus operandi není takový, že se Logstash spustí, do Elasticu se s jeho pomocí obsah uričtého souboru naleje a následně se Logstash vypne. Spíš to funguje tak, že Logstash sleduje určitý soubor a jakmile se v onom souboru objeví nová řádka, Logstash ji zpracuje a pošle dál do Elasticu.  \n",
    "Nejjednodušší způsob, jak Logstash spustit, spočívá v napsání následujícího řádku do konzole:\n",
    "```\n",
    "logstash.bat -e \"input { stdin { } } output { stdout {} }\"  \n",
    "```\n",
    "Zde -e říká, že se konfigurace Logstashe bude brát z příkazová řádky. Touto konfigurací se v příkladu výše myslí textový řetězec obklopený uvozovkami. V něm se říká, že vstup se bude brát z konzole, do které bude směřován i výstup. Tj. když Logstash pustíme, počkáme si na hlášku\n",
    "```\n",
    "[2021-11-21T15:38:36,280][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}  \n",
    "```\n",
    "a poté do konzole napíšeme\n",
    "```\n",
    "ahoj\n",
    "```\n",
    "dostaneme nazpátek\n",
    "```\n",
    "{\n",
    "      \"@version\" => \"1\",\n",
    "    \"@timestamp\" => 2021-11-21T14:41:01.882Z,\n",
    "       \"message\" => \"ahoj\\r\",\n",
    "          \"host\" => \"LAPTOP-ABCDEFG1234\"\n",
    "}  \n",
    "```\n",
    "Pakliže chceme Logstash ukončit a nechceme konzoli zavřít, použijeme klávesovou zkratku CTRL+C.\n",
    "Psát celé naastavení do konzole by vedlo k mnoha zbytečným chybám pošlým z překlepů, navíc by to zabíralo příliš mnoho času. Proto se nastavení píše jednorázově do konfiguračního souboru, jehož adresářová cesta je následně uvedena při spouštění Logstashe za parametrem -f:\n",
    "```\n",
    "logstash.bat -f c:\\programy\\pokusy_logstash\\pokus_conf.config\n",
    "```\n",
    "Jak takový konfigurační soubor může vypadat? Příkladem budiž třeba\n",
    "```\n",
    "input {\n",
    "    file {\n",
    "        path => \"c:/vs/programy/pokusy_logstash/pokus_logstash.txt\"\n",
    "        start_position => \"beginning\"\n",
    "        sincedb_path => \"c:/vs/programy/pokusy_logstash/nejaka_datab.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "filter {\n",
    "    csv {\n",
    "        separator => \";\"\n",
    "        columns => [\"cislo\", \"jednotky\", \"stovky\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "output {\n",
    "    stdout {}\n",
    "}\n",
    "```\n",
    "Vidíme, že se konfigurace skládá ze tří částí. První - input - specifikuje, kde má Logstash hledat vstupní data. Druhá - filter - říká, jak se mají tyto data zpracovat. Nakonec třetí - output - prozrazuje, kam má být poslán výsledek. Položky nacházející se v hierarchii o patro níže (file, csv, stdout) se nazývají pluginy.  \n",
    "Podívejme se na pluginy uvedené v příkladu. Parametr **path** u pluginu výše vypadá jednoduše. Zdání ale klame - pokud člověk použije windosovská zpětná lomítka, Logstash soubor nenajde! I na Windowsech se tak musí používat linuxovská dopředná lomítka. Parametr **start_position** říká, jestli se má u otevíraných souborů začínat od jejich začátku nebo zda má Logstash skočit na jejich konec a nasosávat pouze nové řádky. Defaultní je druhá možnost. Počítá se s tím, že když Logstash spadne, aby se po chvíli znova spustil, nebude chtěné načítat do Elasticu už jednou načtené logy. Nicméně pokud chceme od začátku zpracovat už částečně naplněný log, musíme pro tento parametr nastavit hodnotu \"beginning\". Nakonec **sincedb_path** říká, kde se nalézá soubor s informací, které řádky už přečtené byly a tudíž od které pozice v souboru se mají záznamy zpracovávat. Tj. když nastavíme start_position jako \"beginning\", logstash spustíme a pak ho ukončíme, tak při následném spuštění nebude soubor zpracován znova od začátku, ale zpracovány budou jen nové záznamy. Bacha, když tento parametr neuvedeme, tam se sincedb soubor vytvoří někde na defaultním místě a my se budeme škrábat na hlavě, proč Logstash nic nedělá. Nocméně pokud chceme ten samý soubor zpracovávat pořád od začátku (třeba pro potřeby seznamování se s Logstashem), tak bude neustále mazání sincedb souboru docela nepohodlné. Proto do parametru sincedb_path namísto normální cesty k souboru raději napíšeme /dev/null (Linux) resp. NUL (Windows).  \n",
    "Filter sekce sice není povinná, bez její přítomnosti ale půjdou do outputu řádky tak, jak jsou. Obvykle ale vstupní řádky chceme naparsovat a do outputu posílat jen některé jejich části. Proto musíme vybrat pro naše potřeby vhodný plugin. Příkladem budiž plugin **csv**, který řádky rozděluje podle znaku separátoru (resp. znaků separátoru - není to sice moc typické, ale separátor může být víceznakový). Pakliže separátor na řádku nebude, vloží se obsah řádku do prvního pole. Defaultně nesou pole názvy typu \"column1\", \"column2\" atd. Pokud chceme používat nedefaultní názvy, musíme aplikovat parametr \"columns\". Pakliže data obsahují více sloupců než je položek v \"columns\", ponesou \"nadbytečné\" sloupce opět názvy typu \"column7\".  \n",
    "Může nastat situace, kdy bychom chtěli mít v Elasticsearchi sloupce nikoli ve strinzích, ale ve správných datových typech odpovídající obsahu záznamů - například celá čísla bychom chtěli mít v datovém typu integer. V takovém případě do sekce filter přidáme plugin **mutate**, do jehož parametru convert přiřadíme dvojici \\[jmeno_sloupce, datovy_typ_v_uvozovkach\\]:\n",
    "```\n",
    "mutate {\n",
    "    convert => [\"sloupec_s_cisly\", \"integer\"]\n",
    "}\n",
    "```  \n",
    "Bacha - pokud Logstash narazí na řádek, u kterého konverze nedává smysl, zpracuje ho po svém. Například když načteme csvčko s hlavičkou, převede se popisek sloupce s celými čísly na nulu.  \n",
    "\n",
    "S největší pravděpodobností nebudeme chtít výsledky házet pouze do konzole, ale rádi bychom je viděli v Elasticsearchi. V takovém případě v outputu vyměníme **stdout** plugin za **elasticsearch** plugin, který nastavíme nějak takto:\n",
    "```\n",
    "elasticsearch {\n",
    "    hosts => \"localhost\"\n",
    "    index => \"pokus_logs3\"\n",
    "}\n",
    "```\n",
    "Zde host představuje adresu elasticového serveru (vč. portu, pokud není defaultní) a index zase jméno (klidně nového) indexu. Pro jistotu zopakujme, že pokud se logstash se stejným konfigurákem (a s start_position => \"beginning\") spustí znova, přidají se ty samé záznamy do stejného indexu podruhé. Co by se vlastně stalo, kdybychom outputovací pluginy nenahradily, nýbrž k stdoutu elastisearch přidali? Použily by se současně oba dva, tj. výsledek by šel jak do konzole, tak do Elasticsearche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grok  \n",
    "Výše jsme v sekci filter použili plugin csv, který předpokládal, že jednotlivá pole budou oddělena znakem separátoru. Co když ale budou vstupní data komplikovanější? Co když bude potřeba na jejich zpracování použít regulární výrazy? Tehdy se musí aplikovat plugin grok.  \n",
    "Výhodou groku je, že má v sobě pro nejčastější případu už určité patterny pro regulární výrazy předpřipravené - seznam i s definicí lze nalézt [zde](https://github.com/logstash-plugins/logstash-patterns-core/blob/main/patterns/ecs-v1/grok-patterns). Pokud bychom například chtěli zpracovat soubor o obsahu\n",
    "```\n",
    "USER_1234 127.0.0.1 120 some message 1\n",
    "USER_4567 127.0.0.1 485 some message 2\n",
    "USER_1472 127.0.0.1 723 some message 3\n",
    "```\n",
    "použili bychom následující filtr:\n",
    "```\n",
    "filter {\n",
    "    grok {\n",
    "       match => { \"message\" => \"%{USER:uzivatel} %{IP:adresa} %{INT:nejake_cislo} %{GREEDYDATA:nejaka_hlaska}\" }\n",
    "     }\n",
    "}\n",
    "```\n",
    "Zde se pole message skládá z hromady %{jméno_reguláru:jméno_nového_pole_na_výstupu} obklopených uvozovkami. Výstupem logstashe pro každý řádek je poté\n",
    "```\n",
    "{\n",
    "           \"adresa\" => \"127.0.0.1\",\n",
    "       \"@timestamp\" => 2021-12-09T10:22:49.128Z,\n",
    "         \"@version\" => \"1\",\n",
    "         \"uzivatel\" => \"USER_1234\",\n",
    "    \"nejaka_hlaska\" => \"some message 1\\r\",\n",
    "             \"host\" => \"NAMEOFTHELAPTOP\",\n",
    "             \"path\" => \"c:/programy/pokusy_logstash/pokus_grok1.txt\",\n",
    "     \"nejake_cislo\" => \"120\",\n",
    "          \"message\" => \"USER_1234 127.0.0.1 120 some message 1\\r\"\n",
    "}\n",
    "```\n",
    "Měli bychom zmínit, že pole mohou být oddělena nejen mezerou, ale třeba i čárkou. Oddělovači mohou být i další znaky, pokud však ale tyto znaky mají z hlediska regulárních výrazů speciální význam, musí být escapovány pomocí zpětného lomítka. Tj. pokud by ve zpracovávaném souboru byly řádky typu  \n",
    "```\n",
    "USER_1234 [127.0.0.1] 120, some message 1\n",
    "```\n",
    "musel by se ve filteru nacházet předpis\n",
    "```\n",
    "filter {\n",
    "    grok {\n",
    "       match => { \"message\" => \"%{USER:uzivatel} \\[%{IP:adresa}\\] %{INT:nejake_cislo}, %{GREEDYDATA:nejaka_hlaska}\" }\n",
    "     }\n",
    "}\n",
    "```\n",
    "Při snaze správně naparsovat zdrojový soubor se člověk často sekne a pak na výstupu smutně kouká na \"\\_grokparsefailure\". Přitom spuštění Logstashe nějakou chvíli trvá a tak je vcelku užitečné pro úvodní testování použít [Grok Debugger](http://grokdebug.herokuapp.com/?#). Poznamenejme, že v debugerru se má do odpovídajícího textového pole vložit grokovský pattern v následující podobě:\n",
    "```\n",
    "%{USER:uzivatel} \\[%{IP:adresa}\\] %{INT:nejake_cislo}, %{GREEDYDATA:nejaka_hlaska}\n",
    "```\n",
    "Co udělat, když se zkoumaný soubor skládá z více druhů řádků, na které sedí zcela odlišné patterny? Dejme tomu, že náš soubor vypadá takto:\n",
    "```\n",
    "USER_1234 [127.0.0.1] 120, some message 1\n",
    "USER_4567 [127.0.0.1] 485, some message 2\n",
    "123 USER_4567 some message 2.5\n",
    "USER_1472 [127.0.0.1] 723, some message 3\n",
    "789 USER_1472 some message 3.5\n",
    "```\n",
    "V takovém případě musíme v groku do pole message umístít nikoli textový řetězec-pattern, ale pole textových řetězců-patternů:\n",
    "```\n",
    "filter {\n",
    "    grok {\n",
    "       match => { \"message\" => [\n",
    "           \"%{USER:uzivatel} \\[%{IP:adresa}\\] %{INT:nejake_cislo}, %{GREEDYDATA:nejaka_hlaska}\",\n",
    "           \"%{INT:nejake_cislo} %{USER:uzivatel} %{GREEDYDATA:nejaka_hlaska}\"\n",
    "        ]}\n",
    "     }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mohou nastat situace, kdy předpřipravené regulární výrazy nebudou stačit a my si budeme chtít napsat svoje vlastní. V takovém případě použijeme zápis  \n",
    "```\n",
    "(?<jmeno_noveho_pole>pattern)\n",
    "```\n",
    "Konkrétní příklad:\n",
    "```\n",
    "filter {\n",
    "    grok {\n",
    "       match => { \"message\" => \"(?<jmeno_uzivatele>\\w+) (?<nejake_cele_cislo>\\d+) %{GREEDYDATA:nejaka_hlaska}\"}\n",
    "     }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
